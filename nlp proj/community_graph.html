<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 900px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 900px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#db8157", "id": "A* heuristic", "label": "A* heuristic", "shape": "dot", "size": 40}, {"color": "#dbd057", "id": "ADtree", "label": "ADtree", "shape": "dot", "size": 30}, {"color": "#dbd057", "id": "ADtree methods", "label": "ADtree methods", "shape": "dot", "size": 30}, {"color": "#dbd057", "id": "ADtrees", "label": "ADtrees", "shape": "dot", "size": 30}, {"color": "#db576c", "id": "ALCNR", "label": "ALCNR", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "ALCNR-knowledge bases", "label": "ALCNR-knowledge bases", "shape": "dot", "size": 20}, {"color": "#70db57", "id": "ANNs", "label": "ANNs", "shape": "dot", "size": 10}, {"color": "#dbd557", "id": "Abundant computing power", "label": "Abundant computing power", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Activate", "label": "Activate", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Activate only one unit at a time", "label": "Activate only one unit at a time", "shape": "dot", "size": 20}, {"color": "#badb57", "id": "Activities and resource allocations", "label": "Activities and resource allocations", "shape": "dot", "size": 30}, {"color": "#57dbb4", "id": "Algorithmic", "label": "Algorithmic", "shape": "dot", "size": 10}, {"color": "#8057db", "id": "Allen\u0027s interval algebra", "label": "Allen\u0027s interval algebra", "shape": "dot", "size": 50}, {"color": "#db5771", "id": "Allen\u0027s interval-based framework for representing temporal information", "label": "Allen\u0027s interval-based framework for representing temporal information", "shape": "dot", "size": 50}, {"color": "#dbd557", "id": "An algorithm that learns from a set of examples", "label": "An algorithm that learns from a set of examples", "shape": "dot", "size": 60}, {"color": "#dbd557", "id": "An initial population of knowledge-based neural networks", "label": "An initial population of knowledge-based neural networks", "shape": "dot", "size": 20}, {"color": "#5796db", "id": "Arbitrary lambda", "label": "Arbitrary lambda", "shape": "dot", "size": 30}, {"color": "#bfdb57", "id": "Artificial Intelligence", "label": "Artificial Intelligence", "shape": "dot", "size": 30}, {"color": "#badb57", "id": "Artificial economy", "label": "Artificial economy", "shape": "dot", "size": 110}, {"color": "#dbd057", "id": "Assumptions", "label": "Assumptions", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Asynchronous scheduler", "label": "Asynchronous scheduler", "shape": "dot", "size": 20}, {"color": "#575adb", "id": "Attribute-selection measures", "label": "Attribute-selection measures", "shape": "dot", "size": 10}, {"color": "#d3db57", "id": "Bayesian network", "label": "Bayesian network", "shape": "dot", "size": 70}, {"color": "#d3db57", "id": "Bayesian network inference", "label": "Bayesian network inference", "shape": "dot", "size": 70}, {"color": "#57b8db", "id": "Bayesian networks", "label": "Bayesian networks", "shape": "dot", "size": 30}, {"color": "#badb57", "id": "Behavior analysis", "label": "Behavior analysis", "shape": "dot", "size": 30}, {"color": "#dbd557", "id": "Better network topologies", "label": "Better network topologies", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Boltzman machines", "label": "Boltzman machines", "shape": "dot", "size": 20}, {"color": "#db6957", "id": "C4.5", "label": "C4.5", "shape": "dot", "size": 10}, {"color": "#9d57db", "id": "C4.5 and backpropagation", "label": "C4.5 and backpropagation", "shape": "dot", "size": 30}, {"color": "#57ccdb", "id": "CBP", "label": "CBP", "shape": "dot", "size": 90}, {"color": "#db5799", "id": "CLASSIC", "label": "CLASSIC", "shape": "dot", "size": 30}, {"color": "#db5799", "id": "CLASSIC descriptions", "label": "CLASSIC descriptions", "shape": "dot", "size": 30}, {"color": "#57db92", "id": "CNF conversion", "label": "CNF conversion", "shape": "dot", "size": 10}, {"color": "#d3db57", "id": "CPCS networks for medical diagnosis", "label": "CPCS networks for medical diagnosis", "shape": "dot", "size": 40}, {"color": "#57db8d", "id": "CSP", "label": "CSP", "shape": "dot", "size": 10}, {"color": "#57ccdb", "id": "Case library", "label": "Case library", "shape": "dot", "size": 20}, {"color": "#57ccdb", "id": "Case-Based Planning (CBP)", "label": "Case-Based Planning (CBP)", "shape": "dot", "size": 30}, {"color": "#b157db", "id": "Characteristic models", "label": "Characteristic models", "shape": "dot", "size": 30}, {"color": "#57d1db", "id": "Classification accuracy", "label": "Classification accuracy", "shape": "dot", "size": 40}, {"color": "#d457db", "id": "Clustering", "label": "Clustering", "shape": "dot", "size": 10}, {"color": "#7b57db", "id": "Clusters", "label": "Clusters", "shape": "dot", "size": 30}, {"color": "#badb57", "id": "Competitive equilibrium", "label": "Competitive equilibrium", "shape": "dot", "size": 110}, {"color": "#db578a", "id": "Complexity drawbacks", "label": "Complexity drawbacks", "shape": "dot", "size": 30}, {"color": "#badb57", "id": "Computational agents", "label": "Computational agents", "shape": "dot", "size": 30}, {"color": "#577ddb", "id": "Computational biology", "label": "Computational biology", "shape": "dot", "size": 20}, {"color": "#badb57", "id": "Computational market structures", "label": "Computational market structures", "shape": "dot", "size": 30}, {"color": "#57db8d", "id": "Constraint Satisfaction Problem (CSP)", "label": "Constraint Satisfaction Problem (CSP)", "shape": "dot", "size": 10}, {"color": "#dbae57", "id": "Continuous attribute domains", "label": "Continuous attribute domains", "shape": "dot", "size": 10}, {"color": "#db9557", "id": "Continuous field", "label": "Continuous field", "shape": "dot", "size": 30}, {"color": "#57d1db", "id": "Continuous input values", "label": "Continuous input values", "shape": "dot", "size": 40}, {"color": "#7657db", "id": "Control strategy", "label": "Control strategy", "shape": "dot", "size": 10}, {"color": "#db6457", "id": "Converge to a global minimum", "label": "Converge to a global minimum", "shape": "dot", "size": 20}, {"color": "#57dbd2", "id": "Correctly classifies", "label": "Correctly classifies", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Cycle-cutset scheme", "label": "Cycle-cutset scheme", "shape": "dot", "size": 20}, {"color": "#57ccdb", "id": "DERSNLP+EBL", "label": "DERSNLP+EBL", "shape": "dot", "size": 90}, {"color": "#b157db", "id": "Decision problem", "label": "Decision problem", "shape": "dot", "size": 30}, {"color": "#cf57db", "id": "Decision trees", "label": "Decision trees", "shape": "dot", "size": 30}, {"color": "#cf57db", "id": "Decision trees produced by C4.5", "label": "Decision trees produced by C4.5", "shape": "dot", "size": 30}, {"color": "#57dbd2", "id": "Deficient domain theory", "label": "Deficient domain theory", "shape": "dot", "size": 30}, {"color": "#5796db", "id": "Discounted sum of rewards", "label": "Discounted sum of rewards", "shape": "dot", "size": 30}, {"color": "#57d1db", "id": "Distance functions", "label": "Distance functions", "shape": "dot", "size": 40}, {"color": "#badb57", "id": "Distributed problem solving", "label": "Distributed problem solving", "shape": "dot", "size": 30}, {"color": "#db6457", "id": "Does not assume network is tree-like", "label": "Does not assume network is tree-like", "shape": "dot", "size": 10}, {"color": "#db6457", "id": "Does not exist for acyclic networks", "label": "Does not exist for acyclic networks", "shape": "dot", "size": 10}, {"color": "#db6457", "id": "Does not exist for cycles", "label": "Does not exist for cycles", "shape": "dot", "size": 10}, {"color": "#57dbd2", "id": "Domain theory", "label": "Domain theory", "shape": "dot", "size": 30}, {"color": "#57ccdb", "id": "Domain-independent planning", "label": "Domain-independent planning", "shape": "dot", "size": 30}, {"color": "#dbd557", "id": "Domain-specific knowledge", "label": "Domain-specific knowledge", "shape": "dot", "size": 20}, {"color": "#577ddb", "id": "Dynamic data structure", "label": "Dynamic data structure", "shape": "dot", "size": 20}, {"color": "#577ddb", "id": "Dynamic probabilistic reasoning", "label": "Dynamic probabilistic reasoning", "shape": "dot", "size": 20}, {"color": "#577ddb", "id": "Dynamic reasoning in probabilistic databases", "label": "Dynamic reasoning in probabilistic databases", "shape": "dot", "size": 20}, {"color": "#57db9c", "id": "EG2", "label": "EG2", "shape": "dot", "size": 10}, {"color": "#5d57db", "id": "Effective in reducing search-space size", "label": "Effective in reducing search-space size", "shape": "dot", "size": 30}, {"color": "#db578a", "id": "Efficiency", "label": "Efficiency", "shape": "dot", "size": 20}, {"color": "#badb57", "id": "Efficient distributed resource allocation", "label": "Efficient distributed resource allocation", "shape": "dot", "size": 30}, {"color": "#57bddb", "id": "Eight Puzzle", "label": "Eight Puzzle", "shape": "dot", "size": 20}, {"color": "#57bddb", "id": "Empirical learning of control rules", "label": "Empirical learning of control rules", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Energy minimization", "label": "Energy minimization", "shape": "dot", "size": 20}, {"color": "#57db74", "id": "English verbs", "label": "English verbs", "shape": "dot", "size": 10}, {"color": "#db9557", "id": "Equivalence classes and adjacency relations", "label": "Equivalence classes and adjacency relations", "shape": "dot", "size": 30}, {"color": "#7b57db", "id": "Escaping plateaus", "label": "Escaping plateaus", "shape": "dot", "size": 30}, {"color": "#db6457", "id": "Even in cyclic topologies", "label": "Even in cyclic topologies", "shape": "dot", "size": 20}, {"color": "#57dbd2", "id": "Examples", "label": "Examples", "shape": "dot", "size": 30}, {"color": "#db9557", "id": "Expert level performance", "label": "Expert level performance", "shape": "dot", "size": 30}, {"color": "#57bddb", "id": "Explanation-Based Learning (EBL)", "label": "Explanation-Based Learning (EBL)", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Exponential number of steps", "label": "Exponential number of steps", "shape": "dot", "size": 20}, {"color": "#9357db", "id": "FLARE", "label": "FLARE", "shape": "dot", "size": 50}, {"color": "#db9057", "id": "FLECS", "label": "FLECS", "shape": "dot", "size": 20}, {"color": "#db5767", "id": "FOIDL", "label": "FOIDL", "shape": "dot", "size": 60}, {"color": "#57db57", "id": "Faster learning times", "label": "Faster learning times", "shape": "dot", "size": 10}, {"color": "#db8657", "id": "First-order learning", "label": "First-order learning", "shape": "dot", "size": 10}, {"color": "#7adb57", "id": "Fisher\u0027s linear discriminant", "label": "Fisher\u0027s linear discriminant", "shape": "dot", "size": 20}, {"color": "#57dbd2", "id": "Flawed elements", "label": "Flawed elements", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "From any initial state of the system", "label": "From any initial state of the system", "shape": "dot", "size": 20}, {"color": "#75db57", "id": "Functional relations", "label": "Functional relations", "shape": "dot", "size": 10}, {"color": "#57db92", "id": "GSAT", "label": "GSAT", "shape": "dot", "size": 30}, {"color": "#57b8db", "id": "Gaussian Bayesian networks", "label": "Gaussian Bayesian networks", "shape": "dot", "size": 40}, {"color": "#db9557", "id": "Generic operators", "label": "Generic operators", "shape": "dot", "size": 30}, {"color": "#dbd557", "id": "Genetic operators of crossover and mutation (specifically designed for knowledge-based networks)", "label": "Genetic operators of crossover and mutation (specifically designed for knowledge-based networks)", "shape": "dot", "size": 20}, {"color": "#57b8db", "id": "Gibbs sampling", "label": "Gibbs sampling", "shape": "dot", "size": 30}, {"color": "#db6457", "id": "Global solution", "label": "Global solution", "shape": "dot", "size": 20}, {"color": "#57dbb4", "id": "Goal to achieve", "label": "Goal to achieve", "shape": "dot", "size": 20}, {"color": "#db9557", "id": "HIPAIR", "label": "HIPAIR", "shape": "dot", "size": 30}, {"color": "#db9557", "id": "High-level descriptions of structure, behavior, or control actions", "label": "High-level descriptions of structure, behavior, or control actions", "shape": "dot", "size": 30}, {"color": "#57c2db", "id": "Higher predictive accuracies", "label": "Higher predictive accuracies", "shape": "dot", "size": 10}, {"color": "#db5759", "id": "Higher predictive accuracy", "label": "Higher predictive accuracy", "shape": "dot", "size": 10}, {"color": "#db6457", "id": "Hopfield nets", "label": "Hopfield nets", "shape": "dot", "size": 20}, {"color": "#8057db", "id": "Horn DLRs", "label": "Horn DLRs", "shape": "dot", "size": 10}, {"color": "#db578a", "id": "Horn approximation", "label": "Horn approximation", "shape": "dot", "size": 110}, {"color": "#db578a", "id": "Horn core", "label": "Horn core", "shape": "dot", "size": 20}, {"color": "#db578a", "id": "Horn envelope", "label": "Horn envelope", "shape": "dot", "size": 20}, {"color": "#b157db", "id": "Horn expressions", "label": "Horn expressions", "shape": "dot", "size": 30}, {"color": "#b157db", "id": "Hypergraph transversal problem", "label": "Hypergraph transversal problem", "shape": "dot", "size": 30}, {"color": "#57db9c", "id": "ICET", "label": "ICET", "shape": "dot", "size": 50}, {"color": "#dbc157", "id": "IE discourse component", "label": "IE discourse component", "shape": "dot", "size": 80}, {"color": "#db6457", "id": "Identify tree-like subnetworks", "label": "Identify tree-like subnetworks", "shape": "dot", "size": 20}, {"color": "#db9557", "id": "Image-like analogue representations", "label": "Image-like analogue representations", "shape": "dot", "size": 30}, {"color": "#db9557", "id": "Imagistic reasoning", "label": "Imagistic reasoning", "shape": "dot", "size": 170}, {"color": "#db9557", "id": "Implemented problem solver", "label": "Implemented problem solver", "shape": "dot", "size": 170}, {"color": "#db6457", "id": "Improvement to standard local activation function", "label": "Improvement to standard local activation function", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Improves over activate", "label": "Improves over activate", "shape": "dot", "size": 20}, {"color": "#d957db", "id": "Inductive theorem provers", "label": "Inductive theorem provers", "shape": "dot", "size": 40}, {"color": "#db578a", "id": "Inductivity", "label": "Inductivity", "shape": "dot", "size": 30}, {"color": "#57d1db", "id": "Instance-based learning techniques", "label": "Instance-based learning techniques", "shape": "dot", "size": 40}, {"color": "#5782db", "id": "Instructo-Soar", "label": "Instructo-Soar", "shape": "dot", "size": 140}, {"color": "#5782db", "id": "Interactive tutorial instruction", "label": "Interactive tutorial instruction", "shape": "dot", "size": 30}, {"color": "#db9557", "id": "Intermediate representations", "label": "Intermediate representations", "shape": "dot", "size": 30}, {"color": "#57db97", "id": "Japanese information extraction system", "label": "Japanese information extraction system", "shape": "dot", "size": 10}, {"color": "#db9557", "id": "KAM", "label": "KAM", "shape": "dot", "size": 30}, {"color": "#5d57db", "id": "LCFR", "label": "LCFR", "shape": "dot", "size": 30}, {"color": "#db8157", "id": "LIFO prioritization", "label": "LIFO prioritization", "shape": "dot", "size": 40}, {"color": "#5796db", "id": "Lambda", "label": "Lambda", "shape": "dot", "size": 30}, {"color": "#5796db", "id": "Lambda \u0026gt 0", "label": "Lambda \u0026gt 0", "shape": "dot", "size": 30}, {"color": "#577ddb", "id": "Large probabilistic databases", "label": "Large probabilistic databases", "shape": "dot", "size": 20}, {"color": "#5d57db", "id": "Least-Cost Flaw Repair (LCFR)", "label": "Least-Cost Flaw Repair (LCFR)", "shape": "dot", "size": 30}, {"color": "#57db8d", "id": "Lexically ambiguous sentences", "label": "Lexically ambiguous sentences", "shape": "dot", "size": 10}, {"color": "#db6457", "id": "Linear time", "label": "Linear time", "shape": "dot", "size": 20}, {"color": "#db8157", "id": "Lisp code", "label": "Lisp code", "shape": "dot", "size": 50}, {"color": "#7b57db", "id": "Local minima", "label": "Local minima", "shape": "dot", "size": 60}, {"color": "#7b57db", "id": "Local search algorithms", "label": "Local search algorithms", "shape": "dot", "size": 60}, {"color": "#577ddb", "id": "Log N time", "label": "Log N time", "shape": "dot", "size": 10}, {"color": "#57db8d", "id": "Low-level information utilized by segmentation algorithms", "label": "Low-level information utilized by segmentation algorithms", "shape": "dot", "size": 10}, {"color": "#db578a", "id": "Lower Horn formula", "label": "Lower Horn formula", "shape": "dot", "size": 30}, {"color": "#db9557", "id": "MAPS", "label": "MAPS", "shape": "dot", "size": 30}, {"color": "#57db8d", "id": "MUSE CSP", "label": "MUSE CSP", "shape": "dot", "size": 80}, {"color": "#57db8d", "id": "MUSE arc consistency", "label": "MUSE arc consistency", "shape": "dot", "size": 10}, {"color": "#57db8d", "id": "MUSE node consistency", "label": "MUSE node consistency", "shape": "dot", "size": 10}, {"color": "#57bddb", "id": "Macro-operator learning", "label": "Macro-operator learning", "shape": "dot", "size": 20}, {"color": "#badb57", "id": "Market price systems", "label": "Market price systems", "shape": "dot", "size": 110}, {"color": "#dbc657", "id": "Markov decision theory", "label": "Markov decision theory", "shape": "dot", "size": 10}, {"color": "#badb57", "id": "Mechanisms for decentralized decision making", "label": "Mechanisms for decentralized decision making", "shape": "dot", "size": 30}, {"color": "#db578a", "id": "Minimum-change update", "label": "Minimum-change update", "shape": "dot", "size": 110}, {"color": "#57ccdb", "id": "Mis-retrieval problem", "label": "Mis-retrieval problem", "shape": "dot", "size": 20}, {"color": "#db578a", "id": "Model-based updates", "label": "Model-based updates", "shape": "dot", "size": 30}, {"color": "#cf57db", "id": "More complex decision trees", "label": "More complex decision trees", "shape": "dot", "size": 30}, {"color": "#57ccdb", "id": "Multi-goal problems", "label": "Multi-goal problems", "shape": "dot", "size": 20}, {"color": "#5796db", "id": "Multi-step prediction problems", "label": "Multi-step prediction problems", "shape": "dot", "size": 40}, {"color": "#badb57", "id": "Multicommodity flow problem", "label": "Multicommodity flow problem", "shape": "dot", "size": 30}, {"color": "#a757db", "id": "N individuals", "label": "N individuals", "shape": "dot", "size": 10}, {"color": "#db576c", "id": "NP-hard", "label": "NP-hard", "shape": "dot", "size": 20}, {"color": "#db9557", "id": "Neighborhood graph", "label": "Neighborhood graph", "shape": "dot", "size": 30}, {"color": "#577ddb", "id": "New evidence absorption", "label": "New evidence absorption", "shape": "dot", "size": 20}, {"color": "#57db5b", "id": "New version of C4.5", "label": "New version of C4.5", "shape": "dot", "size": 10}, {"color": "#57d1db", "id": "Nominal input attributes", "label": "Nominal input attributes", "shape": "dot", "size": 40}, {"color": "#57db92", "id": "Non-clausal formulas", "label": "Non-clausal formulas", "shape": "dot", "size": 10}, {"color": "#577ddb", "id": "O(1) time", "label": "O(1) time", "shape": "dot", "size": 20}, {"color": "#577ddb", "id": "O(N)", "label": "O(N)", "shape": "dot", "size": 10}, {"color": "#db57b2", "id": "OC1", "label": "OC1", "shape": "dot", "size": 40}, {"color": "#db575e", "id": "OPUS", "label": "OPUS", "shape": "dot", "size": 50}, {"color": "#cf57db", "id": "Occam\u0027s razor", "label": "Occam\u0027s razor", "shape": "dot", "size": 70}, {"color": "#57dbb4", "id": "Off-line plan-design process", "label": "Off-line plan-design process", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "Omegak", "label": "Omegak", "shape": "dot", "size": 20}, {"color": "#db9557", "id": "Optional objective functions", "label": "Optional objective functions", "shape": "dot", "size": 30}, {"color": "#7adb57", "id": "Othello", "label": "Othello", "shape": "dot", "size": 20}, {"color": "#7157db", "id": "POMDPs", "label": "POMDPs", "shape": "dot", "size": 40}, {"color": "#57dbd2", "id": "PTR", "label": "PTR", "shape": "dot", "size": 90}, {"color": "#dbda57", "id": "Paris", "label": "Paris", "shape": "dot", "size": 10}, {"color": "#57ccdb", "id": "Performance improvements over generative (from-scratch) planning", "label": "Performance improvements over generative (from-scratch) planning", "shape": "dot", "size": 20}, {"color": "#57db88", "id": "Performance task", "label": "Performance task", "shape": "dot", "size": 10}, {"color": "#57dbb4", "id": "Plan-design process", "label": "Plan-design process", "shape": "dot", "size": 60}, {"color": "#57dbb4", "id": "Planning while Learning", "label": "Planning while Learning", "shape": "dot", "size": 20}, {"color": "#7b57db", "id": "Plateau moves", "label": "Plateau moves", "shape": "dot", "size": 30}, {"color": "#7b57db", "id": "Plateaus with exits (benches)", "label": "Plateaus with exits (benches)", "shape": "dot", "size": 60}, {"color": "#cf57db", "id": "Post-processing decision trees", "label": "Post-processing decision trees", "shape": "dot", "size": 30}, {"color": "#badb57", "id": "Price equilibria", "label": "Price equilibria", "shape": "dot", "size": 30}, {"color": "#57dbd2", "id": "Probabilities", "label": "Probabilities", "shape": "dot", "size": 20}, {"color": "#57bddb", "id": "Problem solving with experience", "label": "Problem solving with experience", "shape": "dot", "size": 20}, {"color": "#57dbaf", "id": "Prolog selection rule", "label": "Prolog selection rule", "shape": "dot", "size": 10}, {"color": "#57dbd2", "id": "Propositional domain theories", "label": "Propositional domain theories", "shape": "dot", "size": 20}, {"color": "#57dbd2", "id": "Ptr", "label": "Ptr", "shape": "dot", "size": 90}, {"color": "#57d6db", "id": "Q-DAG evaluation algorithm", "label": "Q-DAG evaluation algorithm", "shape": "dot", "size": 30}, {"color": "#57d6db", "id": "Q-DAG generation algorithm", "label": "Q-DAG generation algorithm", "shape": "dot", "size": 30}, {"color": "#57d6db", "id": "Q-DAGs", "label": "Q-DAGs", "shape": "dot", "size": 80}, {"color": "#88db57", "id": "Quality of clustering", "label": "Quality of clustering", "shape": "dot", "size": 10}, {"color": "#577ddb", "id": "Queries", "label": "Queries", "shape": "dot", "size": 120}, {"color": "#db5a57", "id": "RCC-5", "label": "RCC-5", "shape": "dot", "size": 80}, {"color": "#dbd557", "id": "REGENT algorithm", "label": "REGENT algorithm", "shape": "dot", "size": 60}, {"color": "#57bddb", "id": "Random problems and their solutions", "label": "Random problems and their solutions", "shape": "dot", "size": 20}, {"color": "#577ddb", "id": "Real-time response", "label": "Real-time response", "shape": "dot", "size": 20}, {"color": "#5796db", "id": "Reinforcement learning algorithms", "label": "Reinforcement learning algorithms", "shape": "dot", "size": 100}, {"color": "#57ccdb", "id": "Replay framework", "label": "Replay framework", "shape": "dot", "size": 20}, {"color": "#dbbd57", "id": "Resampling-based pruning strategies", "label": "Resampling-based pruning strategies", "shape": "dot", "size": 10}, {"color": "#57dbb4", "id": "Role", "label": "Role", "shape": "dot", "size": 20}, {"color": "#57db83", "id": "SEQUITUR", "label": "SEQUITUR", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "STEAM", "label": "STEAM", "shape": "dot", "size": 150}, {"color": "#57dba1", "id": "STEAM\u0027s central hypothesis", "label": "STEAM\u0027s central hypothesis", "shape": "dot", "size": 150}, {"color": "#cf57db", "id": "Same class", "label": "Same class", "shape": "dot", "size": 30}, {"color": "#db9557", "id": "Scientific reasoning", "label": "Scientific reasoning", "shape": "dot", "size": 40}, {"color": "#57db8d", "id": "Set of CSPs", "label": "Set of CSPs", "shape": "dot", "size": 10}, {"color": "#db578a", "id": "Set of formulas represented by Horn approximation", "label": "Set of formulas represented by Horn approximation", "shape": "dot", "size": 20}, {"color": "#57db8d", "id": "Signal processing applications including computer vision, speech processing, and handwriting recognition", "label": "Signal processing applications including computer vision, speech processing, and handwriting recognition", "shape": "dot", "size": 10}, {"color": "#cf57db", "id": "Similar objects", "label": "Similar objects", "shape": "dot", "size": 30}, {"color": "#57ccdb", "id": "Similarity judgements", "label": "Similarity judgements", "shape": "dot", "size": 20}, {"color": "#577ddb", "id": "Singly connected Bayesian networks", "label": "Singly connected Bayesian networks", "shape": "dot", "size": 20}, {"color": "#5782db", "id": "Situated explanation-based learning", "label": "Situated explanation-based learning", "shape": "dot", "size": 30}, {"color": "#7b57db", "id": "Small size", "label": "Small size", "shape": "dot", "size": 30}, {"color": "#5769db", "id": "Smaller decision trees", "label": "Smaller decision trees", "shape": "dot", "size": 10}, {"color": "#db9557", "id": "Spatial aggregation", "label": "Spatial aggregation", "shape": "dot", "size": 170}, {"color": "#57bddb", "id": "Speedup learning", "label": "Speedup learning", "shape": "dot", "size": 80}, {"color": "#57bddb", "id": "Speedup learning framework", "label": "Speedup learning framework", "shape": "dot", "size": 80}, {"color": "#57bddb", "id": "Symbolic integration", "label": "Symbolic integration", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Symmetric networks", "label": "Symmetric networks", "shape": "dot", "size": 20}, {"color": "#5791db", "id": "T-R programs", "label": "T-R programs", "shape": "dot", "size": 80}, {"color": "#9357db", "id": "T-complete expansions", "label": "T-complete expansions", "shape": "dot", "size": 40}, {"color": "#9357db", "id": "T-implication", "label": "T-implication", "shape": "dot", "size": 150}, {"color": "#5796db", "id": "TD methods", "label": "TD methods", "shape": "dot", "size": 100}, {"color": "#5796db", "id": "TD(lambda)", "label": "TD(lambda)", "shape": "dot", "size": 40}, {"color": "#db576c", "id": "TKRS", "label": "TKRS", "shape": "dot", "size": 20}, {"color": "#5796db", "id": "TTD", "label": "TTD", "shape": "dot", "size": 100}, {"color": "#5796db", "id": "Temporal difference methods", "label": "Temporal difference methods", "shape": "dot", "size": 40}, {"color": "#db578f", "id": "Tests on continuous attributes", "label": "Tests on continuous attributes", "shape": "dot", "size": 10}, {"color": "#57dbd2", "id": "Theory revision problem", "label": "Theory revision problem", "shape": "dot", "size": 30}, {"color": "#db578a", "id": "Theory update and revision schemes", "label": "Theory update and revision schemes", "shape": "dot", "size": 30}, {"color": "#57aedb", "id": "Toast system", "label": "Toast system", "shape": "dot", "size": 60}, {"color": "#57dbb4", "id": "Tractability", "label": "Tractability", "shape": "dot", "size": 10}, {"color": "#577ddb", "id": "Traditional databases", "label": "Traditional databases", "shape": "dot", "size": 20}, {"color": "#db6457", "id": "Tree-like subnetworks", "label": "Tree-like subnetworks", "shape": "dot", "size": 20}, {"color": "#5796db", "id": "Truncated Temporal Differences (TTD)", "label": "Truncated Temporal Differences (TTD)", "shape": "dot", "size": 40}, {"color": "#db9557", "id": "Unified description of imagistic problem solvers", "label": "Unified description of imagistic problem solvers", "shape": "dot", "size": 30}, {"color": "#db6457", "id": "Uniform algorithm", "label": "Uniform algorithm", "shape": "dot", "size": 210}, {"color": "#dbc157", "id": "Unrestricted text", "label": "Unrestricted text", "shape": "dot", "size": 20}, {"color": "#db578a", "id": "Upper Horn formula", "label": "Upper Horn formula", "shape": "dot", "size": 30}, {"color": "#cf57db", "id": "Utility of Occam\u0027s razor", "label": "Utility of Occam\u0027s razor", "shape": "dot", "size": 70}, {"color": "#d3db57", "id": "VE algorithm", "label": "VE algorithm", "shape": "dot", "size": 70}, {"color": "#db9557", "id": "Visual thinking", "label": "Visual thinking", "shape": "dot", "size": 40}, {"color": "#dbc157", "id": "Wrap-Up", "label": "Wrap-Up", "shape": "dot", "size": 10}, {"color": "#5d57db", "id": "ZLIFO Strategy", "label": "ZLIFO Strategy", "shape": "dot", "size": 30}, {"color": "#dbb857", "id": "accuracy of individual trees", "label": "accuracy of individual trees", "shape": "dot", "size": 40}, {"color": "#dbc157", "id": "acquires knowledge for some of the higher level IE processing", "label": "acquires knowledge for some of the higher level IE processing", "shape": "dot", "size": 20}, {"color": "#db6d57", "id": "actions", "label": "actions", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "adaptive load balancing", "label": "adaptive load balancing", "shape": "dot", "size": 130}, {"color": "#57db6a", "id": "adaptive menus", "label": "adaptive menus", "shape": "dot", "size": 10}, {"color": "#a1db57", "id": "adaptive problem-solving solving", "label": "adaptive problem-solving solving", "shape": "dot", "size": 10}, {"color": "#db575e", "id": "admissible search", "label": "admissible search", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "agent", "label": "agent", "shape": "dot", "size": 80}, {"color": "#57aedb", "id": "agent/environment interactions", "label": "agent/environment interactions", "shape": "dot", "size": 60}, {"color": "#57db83", "id": "algorithm", "label": "algorithm", "shape": "dot", "size": 20}, {"color": "#db5799", "id": "algorithm that is incomplete with respect to", "label": "algorithm that is incomplete with respect to", "shape": "dot", "size": 20}, {"color": "#db5771", "id": "algorithms for determining whether the temporal information is consistent", "label": "algorithms for determining whether the temporal information is consistent", "shape": "dot", "size": 110}, {"color": "#db5771", "id": "applications", "label": "applications", "shape": "dot", "size": 40}, {"color": "#5782db", "id": "approach to learning from situated, interactive tutorial instruction", "label": "approach to learning from situated, interactive tutorial instruction", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "approximate measure of closeness", "label": "approximate measure of closeness", "shape": "dot", "size": 140}, {"color": "#db5a57", "id": "approximately four billion", "label": "approximately four billion", "shape": "dot", "size": 20}, {"color": "#7157db", "id": "approximation scheme", "label": "approximation scheme", "shape": "dot", "size": 20}, {"color": "#db57c0", "id": "artificial intelligence", "label": "artificial intelligence", "shape": "dot", "size": 10}, {"color": "#bb57db", "id": "as hard as learning boolean DNF", "label": "as hard as learning boolean DNF", "shape": "dot", "size": 20}, {"color": "#dbcb57", "id": "automatically construct classification models", "label": "automatically construct classification models", "shape": "dot", "size": 20}, {"color": "#c057db", "id": "automatically synthesized domain independent planners", "label": "automatically synthesized domain independent planners", "shape": "dot", "size": 20}, {"color": "#5791db", "id": "autonomous agents", "label": "autonomous agents", "shape": "dot", "size": 80}, {"color": "#c557db", "id": "background knowledge", "label": "background knowledge", "shape": "dot", "size": 150}, {"color": "#575fdb", "id": "backtrack points", "label": "backtrack points", "shape": "dot", "size": 10}, {"color": "#db5771", "id": "backtracking algorithm", "label": "backtracking algorithm", "shape": "dot", "size": 110}, {"color": "#db5771", "id": "backtracking search problem", "label": "backtracking search problem", "shape": "dot", "size": 50}, {"color": "#57a9db", "id": "base program", "label": "base program", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "basic adaptive behavior parameters", "label": "basic adaptive behavior parameters", "shape": "dot", "size": 30}, {"color": "#57d6db", "id": "belief networks", "label": "belief networks", "shape": "dot", "size": 80}, {"color": "#db57bb", "id": "better symbolic models", "label": "better symbolic models", "shape": "dot", "size": 10}, {"color": "#57dbdb", "id": "bidirectional heuristic search", "label": "bidirectional heuristic search", "shape": "dot", "size": 60}, {"color": "#9d57db", "id": "binary concept learning algorithms", "label": "binary concept learning algorithms", "shape": "dot", "size": 30}, {"color": "#57db79", "id": "bounded optimality", "label": "bounded optimality", "shape": "dot", "size": 10}, {"color": "#c4db57", "id": "branching rate", "label": "branching rate", "shape": "dot", "size": 10}, {"color": "#db576c", "id": "calculus", "label": "calculus", "shape": "dot", "size": 20}, {"color": "#57a9db", "id": "candidate base program", "label": "candidate base program", "shape": "dot", "size": 20}, {"color": "#dba957", "id": "canonical form", "label": "canonical form", "shape": "dot", "size": 60}, {"color": "#db5776", "id": "case-based planning", "label": "case-based planning", "shape": "dot", "size": 20}, {"color": "#b0db57", "id": "category measure", "label": "category measure", "shape": "dot", "size": 10}, {"color": "#dba957", "id": "causal assertions", "label": "causal assertions", "shape": "dot", "size": 20}, {"color": "#d3db57", "id": "causal independence", "label": "causal independence", "shape": "dot", "size": 70}, {"color": "#dba957", "id": "causal relationships", "label": "causal relationships", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "central coordination", "label": "central coordination", "shape": "dot", "size": 30}, {"color": "#9d57db", "id": "changes in training sample size", "label": "changes in training sample size", "shape": "dot", "size": 30}, {"color": "#db576c", "id": "class", "label": "class", "shape": "dot", "size": 30}, {"color": "#579fdb", "id": "class definition", "label": "class definition", "shape": "dot", "size": 10}, {"color": "#9357db", "id": "classical AI", "label": "classical AI", "shape": "dot", "size": 40}, {"color": "#578cdb", "id": "classical AI planners", "label": "classical AI planners", "shape": "dot", "size": 10}, {"color": "#db579e", "id": "classical complexity theory", "label": "classical complexity theory", "shape": "dot", "size": 10}, {"color": "#6c57db", "id": "classification of handwritten digits", "label": "classification of handwritten digits", "shape": "dot", "size": 20}, {"color": "#9357db", "id": "clausal representation of knowledge", "label": "clausal representation of knowledge", "shape": "dot", "size": 40}, {"color": "#9357db", "id": "clauses", "label": "clauses", "shape": "dot", "size": 30}, {"color": "#57a9db", "id": "clauses containing cut", "label": "clauses containing cut", "shape": "dot", "size": 20}, {"color": "#57c7db", "id": "coarse domain theory", "label": "coarse domain theory", "shape": "dot", "size": 20}, {"color": "#db7c57", "id": "collection of geometric bodies", "label": "collection of geometric bodies", "shape": "dot", "size": 10}, {"color": "#db57cf", "id": "combinatorial search", "label": "combinatorial search", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "communication", "label": "communication", "shape": "dot", "size": 70}, {"color": "#5791db", "id": "compact circuitry", "label": "compact circuitry", "shape": "dot", "size": 40}, {"color": "#66db57", "id": "compact, easily interpretable solutions", "label": "compact, easily interpretable solutions", "shape": "dot", "size": 30}, {"color": "#5764db", "id": "competition between decrease in number of solutions and increased pruning", "label": "competition between decrease in number of solutions and increased pruning", "shape": "dot", "size": 20}, {"color": "#ca57db", "id": "competitive ratio", "label": "competitive ratio", "shape": "dot", "size": 10}, {"color": "#db5776", "id": "completeness", "label": "completeness", "shape": "dot", "size": 10}, {"color": "#db575e", "id": "complex learning tasks", "label": "complex learning tasks", "shape": "dot", "size": 10}, {"color": "#57c7db", "id": "complex structural alterations that may be required", "label": "complex structural alterations that may be required", "shape": "dot", "size": 30}, {"color": "#57dba1", "id": "complex, dynamic multi-agent domains", "label": "complex, dynamic multi-agent domains", "shape": "dot", "size": 40}, {"color": "#57dbaf", "id": "computational mechanisms used to process negated atoms", "label": "computational mechanisms used to process negated atoms", "shape": "dot", "size": 10}, {"color": "#57aedb", "id": "computational simplification of activity", "label": "computational simplification of activity", "shape": "dot", "size": 40}, {"color": "#5782db", "id": "computer", "label": "computer", "shape": "dot", "size": 30}, {"color": "#d957db", "id": "computer program", "label": "computer program", "shape": "dot", "size": 80}, {"color": "#9357db", "id": "computer science perspective", "label": "computer science perspective", "shape": "dot", "size": 10}, {"color": "#db576c", "id": "concept language", "label": "concept language", "shape": "dot", "size": 20}, {"color": "#b5db57", "id": "concrete", "label": "concrete", "shape": "dot", "size": 10}, {"color": "#d3db57", "id": "conditional probability", "label": "conditional probability", "shape": "dot", "size": 50}, {"color": "#dbd057", "id": "conjunctive queries", "label": "conjunctive queries", "shape": "dot", "size": 30}, {"color": "#db57ad", "id": "connectionist networks", "label": "connectionist networks", "shape": "dot", "size": 30}, {"color": "#bfdb57", "id": "consequences", "label": "consequences", "shape": "dot", "size": 30}, {"color": "#bfdb57", "id": "conservative", "label": "conservative", "shape": "dot", "size": 30}, {"color": "#57a9db", "id": "consistency", "label": "consistency", "shape": "dot", "size": 20}, {"color": "#dbb857", "id": "consistent decision trees", "label": "consistent decision trees", "shape": "dot", "size": 20}, {"color": "#ac57db", "id": "consistent instantiation", "label": "consistent instantiation", "shape": "dot", "size": 20}, {"color": "#83db57", "id": "constants and unary predicates", "label": "constants and unary predicates", "shape": "dot", "size": 10}, {"color": "#57db83", "id": "constraint", "label": "constraint", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "constraint systems", "label": "constraint systems", "shape": "dot", "size": 20}, {"color": "#dbd057", "id": "constructing contingency tables", "label": "constructing contingency tables", "shape": "dot", "size": 20}, {"color": "#5782db", "id": "contextually guided responses to incomplete explanations", "label": "contextually guided responses to incomplete explanations", "shape": "dot", "size": 20}, {"color": "#5791db", "id": "continuous computation", "label": "continuous computation", "shape": "dot", "size": 50}, {"color": "#57aedb", "id": "control structures", "label": "control structures", "shape": "dot", "size": 40}, {"color": "#57db60", "id": "controllable agent", "label": "controllable agent", "shape": "dot", "size": 60}, {"color": "#57dba5", "id": "conventional methods used in many similar systems", "label": "conventional methods used in many similar systems", "shape": "dot", "size": 20}, {"color": "#57aedb", "id": "conventions and invariants", "label": "conventions and invariants", "shape": "dot", "size": 60}, {"color": "#57db9c", "id": "cost-sensitive classification", "label": "cost-sensitive classification", "shape": "dot", "size": 10}, {"color": "#dba957", "id": "counterfactual reasoning", "label": "counterfactual reasoning", "shape": "dot", "size": 10}, {"color": "#dbd057", "id": "counting the number of records", "label": "counting the number of records", "shape": "dot", "size": 30}, {"color": "#d957db", "id": "critic", "label": "critic", "shape": "dot", "size": 80}, {"color": "#bb57db", "id": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "label": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "shape": "dot", "size": 50}, {"color": "#dbcb57", "id": "cue phrases may be used", "label": "cue phrases may be used", "shape": "dot", "size": 20}, {"color": "#5782db", "id": "custom, button-box user interface", "label": "custom, button-box user interface", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "data", "label": "data", "shape": "dot", "size": 130}, {"color": "#db57ad", "id": "data-driven learning", "label": "data-driven learning", "shape": "dot", "size": 30}, {"color": "#c557db", "id": "database", "label": "database", "shape": "dot", "size": 130}, {"color": "#57db9c", "id": "decision tree", "label": "decision tree", "shape": "dot", "size": 10}, {"color": "#57db6f", "id": "decision-making procedures", "label": "decision-making procedures", "shape": "dot", "size": 10}, {"color": "#dba957", "id": "decision-theoretic primitives", "label": "decision-theoretic primitives", "shape": "dot", "size": 20}, {"color": "#57dbc3", "id": "decision-tree learning algorithms", "label": "decision-tree learning algorithms", "shape": "dot", "size": 10}, {"color": "#57b8db", "id": "decomposable dependency models", "label": "decomposable dependency models", "shape": "dot", "size": 20}, {"color": "#db57ad", "id": "deeply structured symbolic analysis", "label": "deeply structured symbolic analysis", "shape": "dot", "size": 30}, {"color": "#5778db", "id": "default reasoning", "label": "default reasoning", "shape": "dot", "size": 10}, {"color": "#dba457", "id": "degrees of freedom analysis", "label": "degrees of freedom analysis", "shape": "dot", "size": 10}, {"color": "#576edb", "id": "delayed reinforcement", "label": "delayed reinforcement", "shape": "dot", "size": 10}, {"color": "#db9057", "id": "delayed-commitment", "label": "delayed-commitment", "shape": "dot", "size": 100}, {"color": "#57db65", "id": "dependency-directed backtracking", "label": "dependency-directed backtracking", "shape": "dot", "size": 10}, {"color": "#db5799", "id": "description graphs", "label": "description graphs", "shape": "dot", "size": 70}, {"color": "#db5799", "id": "description logics", "label": "description logics", "shape": "dot", "size": 30}, {"color": "#57db60", "id": "designer", "label": "designer", "shape": "dot", "size": 60}, {"color": "#db576c", "id": "desirable TKRS-deduction services", "label": "desirable TKRS-deduction services", "shape": "dot", "size": 20}, {"color": "#db9f57", "id": "deterministic efficient optimal strategy", "label": "deterministic efficient optimal strategy", "shape": "dot", "size": 10}, {"color": "#d957db", "id": "difference matching", "label": "difference matching", "shape": "dot", "size": 40}, {"color": "#d957db", "id": "differences", "label": "differences", "shape": "dot", "size": 40}, {"color": "#57dba1", "id": "differing, incomplete, and possibly inconsistent views of their environment", "label": "differing, incomplete, and possibly inconsistent views of their environment", "shape": "dot", "size": 40}, {"color": "#db9057", "id": "difficult goal interactions", "label": "difficult goal interactions", "shape": "dot", "size": 20}, {"color": "#db7757", "id": "difficult problem instances", "label": "difficult problem instances", "shape": "dot", "size": 10}, {"color": "#9cdb57", "id": "difficult real-time constraints imposed by moving vehicle applications", "label": "difficult real-time constraints imposed by moving vehicle applications", "shape": "dot", "size": 10}, {"color": "#9d57db", "id": "direct application of multiclass algorithms", "label": "direct application of multiclass algorithms", "shape": "dot", "size": 30}, {"color": "#dba957", "id": "directed acyclic graphs", "label": "directed acyclic graphs", "shape": "dot", "size": 20}, {"color": "#57b8db", "id": "directed graphs representing a Markov chain", "label": "directed graphs representing a Markov chain", "shape": "dot", "size": 30}, {"color": "#dbcb57", "id": "discourse sense", "label": "discourse sense", "shape": "dot", "size": 60}, {"color": "#c557db", "id": "discovering knowledge in structural data", "label": "discovering knowledge in structural data", "shape": "dot", "size": 140}, {"color": "#57db83", "id": "discrete symbols", "label": "discrete symbols", "shape": "dot", "size": 20}, {"color": "#9cdb57", "id": "distorted template", "label": "distorted template", "shape": "dot", "size": 20}, {"color": "#9d57db", "id": "distributed output representation", "label": "distributed output representation", "shape": "dot", "size": 140}, {"color": "#9d57db", "id": "distributed output representations", "label": "distributed output representations", "shape": "dot", "size": 40}, {"color": "#57dba1", "id": "distributed system", "label": "distributed system", "shape": "dot", "size": 30}, {"color": "#d957db", "id": "diverging proof attempts", "label": "diverging proof attempts", "shape": "dot", "size": 80}, {"color": "#c057db", "id": "domain dependent approaches", "label": "domain dependent approaches", "shape": "dot", "size": 10}, {"color": "#c057db", "id": "domain independent approaches", "label": "domain independent approaches", "shape": "dot", "size": 10}, {"color": "#61db57", "id": "domain theory", "label": "domain theory", "shape": "dot", "size": 20}, {"color": "#db8157", "id": "domain-independent techniques", "label": "domain-independent techniques", "shape": "dot", "size": 50}, {"color": "#db57b2", "id": "domains in which the attributes are numeric", "label": "domains in which the attributes are numeric", "shape": "dot", "size": 20}, {"color": "#5791db", "id": "dynamic environments", "label": "dynamic environments", "shape": "dot", "size": 80}, {"color": "#57dba5", "id": "dynamic shift intervals of inaccurate data", "label": "dynamic shift intervals of inaccurate data", "shape": "dot", "size": 20}, {"color": "#db9057", "id": "eager-commitment", "label": "eager-commitment", "shape": "dot", "size": 10}, {"color": "#db9057", "id": "eager-commitment planners", "label": "eager-commitment planners", "shape": "dot", "size": 20}, {"color": "#5764db", "id": "easy-hard-easy pattern", "label": "easy-hard-easy pattern", "shape": "dot", "size": 50}, {"color": "#db57d9", "id": "efficient and accurate", "label": "efficient and accurate", "shape": "dot", "size": 20}, {"color": "#db9057", "id": "efficient planning strategies", "label": "efficient planning strategies", "shape": "dot", "size": 20}, {"color": "#9857db", "id": "efficient stochastic policy", "label": "efficient stochastic policy", "shape": "dot", "size": 10}, {"color": "#8057db", "id": "eight new maximal tractable subclasses of Allen\u0027s interval algebra", "label": "eight new maximal tractable subclasses of Allen\u0027s interval algebra", "shape": "dot", "size": 10}, {"color": "#57db6a", "id": "electronic organizer", "label": "electronic organizer", "shape": "dot", "size": 50}, {"color": "#db5771", "id": "empirical analysis", "label": "empirical analysis", "shape": "dot", "size": 40}, {"color": "#6bdb57", "id": "empirical models", "label": "empirical models", "shape": "dot", "size": 10}, {"color": "#db57b7", "id": "entropy", "label": "entropy", "shape": "dot", "size": 10}, {"color": "#db5794", "id": "ergodicity", "label": "ergodicity", "shape": "dot", "size": 10}, {"color": "#9d57db", "id": "error-correcting codes", "label": "error-correcting codes", "shape": "dot", "size": 30}, {"color": "#9d57db", "id": "error-correcting output codes", "label": "error-correcting output codes", "shape": "dot", "size": 40}, {"color": "#57d6db", "id": "evidence symbols", "label": "evidence symbols", "shape": "dot", "size": 30}, {"color": "#db575e", "id": "exact learning biases", "label": "exact learning biases", "shape": "dot", "size": 10}, {"color": "#db57c5", "id": "existing backtracking methods", "label": "existing backtracking methods", "shape": "dot", "size": 10}, {"color": "#ac57db", "id": "existing solutions", "label": "existing solutions", "shape": "dot", "size": 20}, {"color": "#9357db", "id": "expansions", "label": "expansions", "shape": "dot", "size": 40}, {"color": "#57b8db", "id": "expectation maximization algorithm", "label": "expectation maximization algorithm", "shape": "dot", "size": 30}, {"color": "#9cdb57", "id": "expectation-driven low-level image segmentation", "label": "expectation-driven low-level image segmentation", "shape": "dot", "size": 20}, {"color": "#57db60", "id": "expected utility maximizer", "label": "expected utility maximizer", "shape": "dot", "size": 40}, {"color": "#db8157", "id": "experiments based on modifications of UCPOP", "label": "experiments based on modifications of UCPOP", "shape": "dot", "size": 40}, {"color": "#db9a57", "id": "explicit decision-steps", "label": "explicit decision-steps", "shape": "dot", "size": 10}, {"color": "#db5767", "id": "explicit negative examples", "label": "explicit negative examples", "shape": "dot", "size": 30}, {"color": "#dbcb57", "id": "explicitly signal discourse structure", "label": "explicitly signal discourse structure", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "exploration vs. exploitation", "label": "exploration vs. exploitation", "shape": "dot", "size": 20}, {"color": "#57a9db", "id": "extensional evaluation method", "label": "extensional evaluation method", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "failed to fulfill responsibilities or discovered unexpected opportunities", "label": "failed to fulfill responsibilities or discovered unexpected opportunities", "shape": "dot", "size": 40}, {"color": "#57b8db", "id": "feed-forward networks", "label": "feed-forward networks", "shape": "dot", "size": 30}, {"color": "#db57d9", "id": "feedforward neural networks", "label": "feedforward neural networks", "shape": "dot", "size": 10}, {"color": "#57c7db", "id": "fine-tuned theory", "label": "fine-tuned theory", "shape": "dot", "size": 110}, {"color": "#c557db", "id": "finite set of clauses containing at least one non-tautologous function-free clause (among other, not necessarily function-free clauses)", "label": "finite set of clauses containing at least one non-tautologous function-free clause (among other, not necessarily function-free clauses)", "shape": "dot", "size": 10}, {"color": "#579bdb", "id": "first step", "label": "first step", "shape": "dot", "size": 110}, {"color": "#db5767", "id": "first-order decision lists", "label": "first-order decision lists", "shape": "dot", "size": 60}, {"color": "#57db9c", "id": "five real-world medical datasets", "label": "five real-world medical datasets", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "flexibility", "label": "flexibility", "shape": "dot", "size": 40}, {"color": "#5782db", "id": "flexible paradigm for teaching tasks", "label": "flexible paradigm for teaching tasks", "shape": "dot", "size": 30}, {"color": "#5782db", "id": "form of explanation-based learning", "label": "form of explanation-based learning", "shape": "dot", "size": 30}, {"color": "#5791db", "id": "formalism", "label": "formalism", "shape": "dot", "size": 80}, {"color": "#a6db57", "id": "formula Phi", "label": "formula Phi", "shape": "dot", "size": 10}, {"color": "#bfdb57", "id": "formulae", "label": "formulae", "shape": "dot", "size": 80}, {"color": "#bfdb57", "id": "formulae preserving truth-value", "label": "formulae preserving truth-value", "shape": "dot", "size": 30}, {"color": "#db5a57", "id": "four in total", "label": "four in total", "shape": "dot", "size": 20}, {"color": "#db5763", "id": "full knowledge of the conditions under which the plan will be executed", "label": "full knowledge of the conditions under which the plan will be executed", "shape": "dot", "size": 10}, {"color": "#ac57db", "id": "functional CSPs", "label": "functional CSPs", "shape": "dot", "size": 60}, {"color": "#ac57db", "id": "functional constraints", "label": "functional constraints", "shape": "dot", "size": 30}, {"color": "#7adb57", "id": "game-tree search", "label": "game-tree search", "shape": "dot", "size": 70}, {"color": "#db576c", "id": "general concepts", "label": "general concepts", "shape": "dot", "size": 10}, {"color": "#9357db", "id": "generalization", "label": "generalization", "shape": "dot", "size": 30}, {"color": "#92db57", "id": "generalization and hierarchy", "label": "generalization and hierarchy", "shape": "dot", "size": 10}, {"color": "#d957db", "id": "generalizations", "label": "generalizations", "shape": "dot", "size": 40}, {"color": "#57db9c", "id": "genetic algorithm", "label": "genetic algorithm", "shape": "dot", "size": 10}, {"color": "#db57a3", "id": "geometric bodies", "label": "geometric bodies", "shape": "dot", "size": 10}, {"color": "#db57d9", "id": "good performance", "label": "good performance", "shape": "dot", "size": 20}, {"color": "#57dbc8", "id": "gradient", "label": "gradient", "shape": "dot", "size": 10}, {"color": "#57db83", "id": "grammatical", "label": "grammatical", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "graph", "label": "graph", "shape": "dot", "size": 130}, {"color": "#c557db", "id": "graph match", "label": "graph match", "shape": "dot", "size": 130}, {"color": "#db5776", "id": "graph of partial plans", "label": "graph of partial plans", "shape": "dot", "size": 10}, {"color": "#57b8db", "id": "graphical framework", "label": "graphical framework", "shape": "dot", "size": 120}, {"color": "#57b8db", "id": "graphical models", "label": "graphical models", "shape": "dot", "size": 130}, {"color": "#57b8db", "id": "graphical specification", "label": "graphical specification", "shape": "dot", "size": 120}, {"color": "#c557db", "id": "greatest specialization", "label": "greatest specialization", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "guides the search towards more appropriate substructures", "label": "guides the search towards more appropriate substructures", "shape": "dot", "size": 140}, {"color": "#db57ad", "id": "hand-coded symbolic grammar or symbolic semantic component", "label": "hand-coded symbolic grammar or symbolic semantic component", "shape": "dot", "size": 50}, {"color": "#57db6a", "id": "handwriting recognition", "label": "handwriting recognition", "shape": "dot", "size": 10}, {"color": "#db8157", "id": "hardest problems", "label": "hardest problems", "shape": "dot", "size": 40}, {"color": "#d7db57", "id": "head-to-head", "label": "head-to-head", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "heterogeneous populations", "label": "heterogeneous populations", "shape": "dot", "size": 130}, {"color": "#57dbcd", "id": "hidden state", "label": "hidden state", "shape": "dot", "size": 10}, {"color": "#57db83", "id": "hierarchical", "label": "hierarchical", "shape": "dot", "size": 10}, {"color": "#c557db", "id": "hierarchical description", "label": "hierarchical description", "shape": "dot", "size": 140}, {"color": "#db576c", "id": "hierarchy", "label": "hierarchy", "shape": "dot", "size": 30}, {"color": "#579bdb", "id": "high level of system performance", "label": "high level of system performance", "shape": "dot", "size": 110}, {"color": "#dbc157", "id": "higher level IE processing", "label": "higher level IE processing", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "highly expressive terminological language", "label": "highly expressive terminological language", "shape": "dot", "size": 20}, {"color": "#db5771", "id": "highly optimized implementation", "label": "highly optimized implementation", "shape": "dot", "size": 40}, {"color": "#db5780", "id": "hill-climbing", "label": "hill-climbing", "shape": "dot", "size": 10}, {"color": "#8957db", "id": "hill-climbing phase", "label": "hill-climbing phase", "shape": "dot", "size": 10}, {"color": "#579bdb", "id": "human performance", "label": "human performance", "shape": "dot", "size": 110}, {"color": "#57dba5", "id": "identifying inaccurate data", "label": "identifying inaccurate data", "shape": "dot", "size": 40}, {"color": "#9357db", "id": "implication", "label": "implication", "shape": "dot", "size": 30}, {"color": "#57c7db", "id": "improved theory", "label": "improved theory", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "inclusion statements", "label": "inclusion statements", "shape": "dot", "size": 120}, {"color": "#57b8db", "id": "independence relationships", "label": "independence relationships", "shape": "dot", "size": 10}, {"color": "#dbd057", "id": "independent of the number of records", "label": "independent of the number of records", "shape": "dot", "size": 130}, {"color": "#57dba1", "id": "individual agents", "label": "individual agents", "shape": "dot", "size": 30}, {"color": "#57dba1", "id": "individual members\u0027", "label": "individual members\u0027", "shape": "dot", "size": 40}, {"color": "#db5799", "id": "individuals", "label": "individuals", "shape": "dot", "size": 30}, {"color": "#66db57", "id": "induced solutions", "label": "induced solutions", "shape": "dot", "size": 20}, {"color": "#9357db", "id": "induction", "label": "induction", "shape": "dot", "size": 40}, {"color": "#66db57", "id": "induction method", "label": "induction method", "shape": "dot", "size": 30}, {"color": "#9357db", "id": "inductive learning", "label": "inductive learning", "shape": "dot", "size": 180}, {"color": "#9357db", "id": "inductive learning systems", "label": "inductive learning systems", "shape": "dot", "size": 150}, {"color": "#c557db", "id": "inexact graph match", "label": "inexact graph match", "shape": "dot", "size": 90}, {"color": "#dba957", "id": "influence diagrams", "label": "influence diagrams", "shape": "dot", "size": 10}, {"color": "#579bdb", "id": "information", "label": "information", "shape": "dot", "size": 110}, {"color": "#579bdb", "id": "information extraction", "label": "information extraction", "shape": "dot", "size": 110}, {"color": "#dbc157", "id": "information extraction (IE) processing", "label": "information extraction (IE) processing", "shape": "dot", "size": 20}, {"color": "#db8157", "id": "initial and goal conditions", "label": "initial and goal conditions", "shape": "dot", "size": 40}, {"color": "#57c7db", "id": "initial theory", "label": "initial theory", "shape": "dot", "size": 110}, {"color": "#57db83", "id": "input", "label": "input", "shape": "dot", "size": 20}, {"color": "#9cdb57", "id": "input image", "label": "input image", "shape": "dot", "size": 20}, {"color": "#5782db", "id": "instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions)", "label": "instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions)", "shape": "dot", "size": 20}, {"color": "#9357db", "id": "intelligence", "label": "intelligence", "shape": "dot", "size": 50}, {"color": "#57b3db", "id": "intelligent systems", "label": "intelligent systems", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.", "label": "intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.", "shape": "dot", "size": 40}, {"color": "#db5767", "id": "intensional background knowledge", "label": "intensional background knowledge", "shape": "dot", "size": 30}, {"color": "#5782db", "id": "interactive tutorial instruction", "label": "interactive tutorial instruction", "shape": "dot", "size": 30}, {"color": "#579bdb", "id": "interest", "label": "interest", "shape": "dot", "size": 110}, {"color": "#5791db", "id": "intuitive and easy to write", "label": "intuitive and easy to write", "shape": "dot", "size": 40}, {"color": "#8557db", "id": "ion", "label": "ion", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "joint intentions", "label": "joint intentions", "shape": "dot", "size": 150}, {"color": "#d3db57", "id": "joint probability", "label": "joint probability", "shape": "dot", "size": 40}, {"color": "#9d57db", "id": "k classes", "label": "k classes", "shape": "dot", "size": 140}, {"color": "#579bdb", "id": "key word search", "label": "key word search", "shape": "dot", "size": 110}, {"color": "#db576c", "id": "knowledge base", "label": "knowledge base", "shape": "dot", "size": 90}, {"color": "#5782db", "id": "known or unknown commands", "label": "known or unknown commands", "shape": "dot", "size": 20}, {"color": "#9357db", "id": "learning", "label": "learning", "shape": "dot", "size": 60}, {"color": "#57b8db", "id": "learning Gaussian and discrete Bayesian networks from data", "label": "learning Gaussian and discrete Bayesian networks from data", "shape": "dot", "size": 40}, {"color": "#bb57db", "id": "learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause", "label": "learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause", "shape": "dot", "size": 20}, {"color": "#db5767", "id": "learning a new class of concepts", "label": "learning a new class of concepts", "shape": "dot", "size": 60}, {"color": "#cedb57", "id": "learning approaches based on continuous optimization", "label": "learning approaches based on continuous optimization", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "learning each class of knowledge it uses to perform tasks", "label": "learning each class of knowledge it uses to perform tasks", "shape": "dot", "size": 30}, {"color": "#5782db", "id": "learning from situated, interactive tutorial instruction", "label": "learning from situated, interactive tutorial instruction", "shape": "dot", "size": 30}, {"color": "#5782db", "id": "learning hierarchies of new tasks and other domain knowledge from interactive natural language instructions", "label": "learning hierarchies of new tasks and other domain knowledge from interactive natural language instructions", "shape": "dot", "size": 20}, {"color": "#57a9db", "id": "learning programs", "label": "learning programs", "shape": "dot", "size": 60}, {"color": "#9357db", "id": "learning recursive clauses", "label": "learning recursive clauses", "shape": "dot", "size": 40}, {"color": "#57dbb9", "id": "learning system", "label": "learning system", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "learning-apprentice software-agent", "label": "learning-apprentice software-agent", "shape": "dot", "size": 30}, {"color": "#c557db", "id": "least generalization", "label": "least generalization", "shape": "dot", "size": 40}, {"color": "#db9057", "id": "least-commitment planners", "label": "least-commitment planners", "shape": "dot", "size": 20}, {"color": "#dbb357", "id": "legal reasoning example", "label": "legal reasoning example", "shape": "dot", "size": 10}, {"color": "#d957db", "id": "lemmas", "label": "lemmas", "shape": "dot", "size": 40}, {"color": "#57aedb", "id": "lifeworld", "label": "lifeworld", "shape": "dot", "size": 60}, {"color": "#57aedb", "id": "lifeworlds", "label": "lifeworlds", "shape": "dot", "size": 40}, {"color": "#6c57db", "id": "likelihood of evidence", "label": "likelihood of evidence", "shape": "dot", "size": 20}, {"color": "#5778db", "id": "likelihood ordering on worlds", "label": "likelihood ordering on worlds", "shape": "dot", "size": 10}, {"color": "#57b8db", "id": "linear regression", "label": "linear regression", "shape": "dot", "size": 30}, {"color": "#57dba1", "id": "load balancing", "label": "load balancing", "shape": "dot", "size": 30}, {"color": "#ac57db", "id": "local consistency", "label": "local consistency", "shape": "dot", "size": 20}, {"color": "#db57d9", "id": "locally weighted regression", "label": "locally weighted regression", "shape": "dot", "size": 10}, {"color": "#5778db", "id": "logic of relative likelihood", "label": "logic of relative likelihood", "shape": "dot", "size": 20}, {"color": "#57dbaa", "id": "logic programs", "label": "logic programs", "shape": "dot", "size": 10}, {"color": "#57a9db", "id": "logic programs with cut", "label": "logic programs with cut", "shape": "dot", "size": 10}, {"color": "#61db57", "id": "logical domain theories", "label": "logical domain theories", "shape": "dot", "size": 50}, {"color": "#9357db", "id": "logical implication", "label": "logical implication", "shape": "dot", "size": 30}, {"color": "#7adb57", "id": "logistic regression", "label": "logistic regression", "shape": "dot", "size": 70}, {"color": "#dbd057", "id": "loglinear in the number of non-zero entries", "label": "loglinear in the number of non-zero entries", "shape": "dot", "size": 20}, {"color": "#db5785", "id": "long-run optimality", "label": "long-run optimality", "shape": "dot", "size": 10}, {"color": "#57dbaf", "id": "low-acceptable program", "label": "low-acceptable program", "shape": "dot", "size": 20}, {"color": "#db57a8", "id": "low-level membership values", "label": "low-level membership values", "shape": "dot", "size": 10}, {"color": "#5773db", "id": "machine architectures", "label": "machine architectures", "shape": "dot", "size": 10}, {"color": "#9357db", "id": "machine learning", "label": "machine learning", "shape": "dot", "size": 110}, {"color": "#db57d9", "id": "machine learning algorithms", "label": "machine learning algorithms", "shape": "dot", "size": 20}, {"color": "#db575e", "id": "machine learning community", "label": "machine learning community", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "machine learning component", "label": "machine learning component", "shape": "dot", "size": 20}, {"color": "#dbd057", "id": "machine learning datasets", "label": "machine learning datasets", "shape": "dot", "size": 20}, {"color": "#66db57", "id": "machine learning method", "label": "machine learning method", "shape": "dot", "size": 90}, {"color": "#dbcb57", "id": "manually derived classification models already in the literature", "label": "manually derived classification models already in the literature", "shape": "dot", "size": 20}, {"color": "#9cdb57", "id": "massively parallel SIMD architectures capable of handling hierarchical data structures", "label": "massively parallel SIMD architectures capable of handling hierarchical data structures", "shape": "dot", "size": 20}, {"color": "#db57d4", "id": "maximal generality", "label": "maximal generality", "shape": "dot", "size": 20}, {"color": "#db5a57", "id": "maximal tractable subalgebras", "label": "maximal tractable subalgebras", "shape": "dot", "size": 20}, {"color": "#8057db", "id": "maximal tractable subclasses of Allen\u0027s interval algebra", "label": "maximal tractable subclasses of Allen\u0027s interval algebra", "shape": "dot", "size": 10}, {"color": "#6c57db", "id": "mean field theory", "label": "mean field theory", "shape": "dot", "size": 40}, {"color": "#5764db", "id": "median search cost", "label": "median search cost", "shape": "dot", "size": 20}, {"color": "#dbd057", "id": "merits", "label": "merits", "shape": "dot", "size": 30}, {"color": "#dbd057", "id": "minimize memory use", "label": "minimize memory use", "shape": "dot", "size": 30}, {"color": "#9cdb57", "id": "minimize system production and operational costs", "label": "minimize system production and operational costs", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "minimum k", "label": "minimum k", "shape": "dot", "size": 20}, {"color": "#57dbdb", "id": "misconception", "label": "misconception", "shape": "dot", "size": 20}, {"color": "#57dbdb", "id": "misunderstanding about the reasons behind it", "label": "misunderstanding about the reasons behind it", "shape": "dot", "size": 10}, {"color": "#db57d9", "id": "mixtures of Gaussians", "label": "mixtures of Gaussians", "shape": "dot", "size": 10}, {"color": "#db57d9", "id": "mixtures of Gaussians and locally weighted regression", "label": "mixtures of Gaussians and locally weighted regression", "shape": "dot", "size": 20}, {"color": "#57c7db", "id": "more accurate theory", "label": "more accurate theory", "shape": "dot", "size": 30}, {"color": "#57dbbe", "id": "muALCQ", "label": "muALCQ", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "multi-agent reinforcement learning", "label": "multi-agent reinforcement learning", "shape": "dot", "size": 30}, {"color": "#57db60", "id": "multi-agent system", "label": "multi-agent system", "shape": "dot", "size": 40}, {"color": "#9d57db", "id": "multiclass learning problems", "label": "multiclass learning problems", "shape": "dot", "size": 140}, {"color": "#9d57db", "id": "multiclass problems", "label": "multiclass problems", "shape": "dot", "size": 40}, {"color": "#66db57", "id": "multiple input variables", "label": "multiple input variables", "shape": "dot", "size": 20}, {"color": "#9cdb57", "id": "multiresolution stretching process", "label": "multiresolution stretching process", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "naive use of communication", "label": "naive use of communication", "shape": "dot", "size": 30}, {"color": "#57d6db", "id": "network queries", "label": "network queries", "shape": "dot", "size": 30}, {"color": "#57dbdb", "id": "new generic approach", "label": "new generic approach", "shape": "dot", "size": 10}, {"color": "#57dbaf", "id": "non-monotonic reasoning", "label": "non-monotonic reasoning", "shape": "dot", "size": 10}, {"color": "#9357db", "id": "non-tautological clauses", "label": "non-tautological clauses", "shape": "dot", "size": 40}, {"color": "#7157db", "id": "nondeterministic effects of actions, incomplete observability of state", "label": "nondeterministic effects of actions, incomplete observability of state", "shape": "dot", "size": 20}, {"color": "#bfdb57", "id": "nonmonotonicity", "label": "nonmonotonicity", "shape": "dot", "size": 80}, {"color": "#5782db", "id": "note taking", "label": "note taking", "shape": "dot", "size": 30}, {"color": "#5782db", "id": "note taking agent", "label": "note taking agent", "shape": "dot", "size": 20}, {"color": "#5764db", "id": "number of solutions", "label": "number of solutions", "shape": "dot", "size": 20}, {"color": "#57d6db", "id": "numeric operations", "label": "numeric operations", "shape": "dot", "size": 30}, {"color": "#db57b2", "id": "oblique decision tree methods", "label": "oblique decision tree methods", "shape": "dot", "size": 20}, {"color": "#db57b2", "id": "oblique split (in the form of a hyperplane)", "label": "oblique split (in the form of a hyperplane)", "shape": "dot", "size": 10}, {"color": "#57d6db", "id": "on-line, real-world applications", "label": "on-line, real-world applications", "shape": "dot", "size": 30}, {"color": "#db8157", "id": "operator parameter domains", "label": "operator parameter domains", "shape": "dot", "size": 170}, {"color": "#db57d9", "id": "optimal data selection techniques", "label": "optimal data selection techniques", "shape": "dot", "size": 20}, {"color": "#db57d9", "id": "optimal way to select training data", "label": "optimal way to select training data", "shape": "dot", "size": 20}, {"color": "#7157db", "id": "oracle", "label": "oracle", "shape": "dot", "size": 20}, {"color": "#66db57", "id": "ordered disjunctive normal form (DNF)", "label": "ordered disjunctive normal form (DNF)", "shape": "dot", "size": 90}, {"color": "#c557db", "id": "original data", "label": "original data", "shape": "dot", "size": 130}, {"color": "#57c7db", "id": "original representation", "label": "original representation", "shape": "dot", "size": 30}, {"color": "#9cdb57", "id": "original template", "label": "original template", "shape": "dot", "size": 20}, {"color": "#9d57db", "id": "overfitting avoidance techniques", "label": "overfitting avoidance techniques", "shape": "dot", "size": 40}, {"color": "#db57d4", "id": "pac-learnability", "label": "pac-learnability", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "partial SharedPlans", "label": "partial SharedPlans", "shape": "dot", "size": 40}, {"color": "#8ddb57", "id": "partial-order planning", "label": "partial-order planning", "shape": "dot", "size": 10}, {"color": "#57db60", "id": "partially controlled multi-agent system", "label": "partially controlled multi-agent system", "shape": "dot", "size": 60}, {"color": "#dbc157", "id": "partially trainable discourse module", "label": "partially trainable discourse module", "shape": "dot", "size": 10}, {"color": "#9d57db", "id": "particular classes", "label": "particular classes", "shape": "dot", "size": 40}, {"color": "#db5771", "id": "path consistency algorithm", "label": "path consistency algorithm", "shape": "dot", "size": 110}, {"color": "#57db97", "id": "pattern matcher and discourse processor", "label": "pattern matcher and discourse processor", "shape": "dot", "size": 10}, {"color": "#8e57db", "id": "perfect monitoring case", "label": "perfect monitoring case", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "performance system", "label": "performance system", "shape": "dot", "size": 80}, {"color": "#57db6a", "id": "person\u0027s address", "label": "person\u0027s address", "shape": "dot", "size": 10}, {"color": "#57db6a", "id": "person\u0027s name", "label": "person\u0027s name", "shape": "dot", "size": 10}, {"color": "#57db83", "id": "phrases", "label": "phrases", "shape": "dot", "size": 20}, {"color": "#579bdb", "id": "pieces of information", "label": "pieces of information", "shape": "dot", "size": 110}, {"color": "#db5776", "id": "plan adaptation", "label": "plan adaptation", "shape": "dot", "size": 60}, {"color": "#57a4db", "id": "plan fragments", "label": "plan fragments", "shape": "dot", "size": 10}, {"color": "#db5776", "id": "plan refinement operators", "label": "plan refinement operators", "shape": "dot", "size": 10}, {"color": "#db9057", "id": "planning algorithm", "label": "planning algorithm", "shape": "dot", "size": 20}, {"color": "#db9057", "id": "planning domains and problems", "label": "planning domains and problems", "shape": "dot", "size": 20}, {"color": "#db9057", "id": "planning problems", "label": "planning problems", "shape": "dot", "size": 20}, {"color": "#db9057", "id": "planning strategy", "label": "planning strategy", "shape": "dot", "size": 10}, {"color": "#5cdb57", "id": "plateau search", "label": "plateau search", "shape": "dot", "size": 10}, {"color": "#57b8db", "id": "plates", "label": "plates", "shape": "dot", "size": 30}, {"color": "#7adb57", "id": "playing strengths", "label": "playing strengths", "shape": "dot", "size": 30}, {"color": "#db5a57", "id": "polynomial or NP-complete", "label": "polynomial or NP-complete", "shape": "dot", "size": 20}, {"color": "#5787db", "id": "practical utility", "label": "practical utility", "shape": "dot", "size": 10}, {"color": "#db8157", "id": "practicality of well-founded partial-order planners", "label": "practicality of well-founded partial-order planners", "shape": "dot", "size": 50}, {"color": "#66db57", "id": "predicting the value of a real-valued function", "label": "predicting the value of a real-valued function", "shape": "dot", "size": 20}, {"color": "#57db6a", "id": "predictive fillin", "label": "predictive fillin", "shape": "dot", "size": 10}, {"color": "#bfdb57", "id": "preferential logics", "label": "preferential logics", "shape": "dot", "size": 80}, {"color": "#db8157", "id": "preferring zero commitment plan refinements", "label": "preferring zero commitment plan refinements", "shape": "dot", "size": 170}, {"color": "#57c7db", "id": "previous theory-guided systems", "label": "previous theory-guided systems", "shape": "dot", "size": 30}, {"color": "#db5771", "id": "previously suggested reformulation", "label": "previously suggested reformulation", "shape": "dot", "size": 50}, {"color": "#db5771", "id": "problems in molecular biology", "label": "problems in molecular biology", "shape": "dot", "size": 40}, {"color": "#57db83", "id": "produces", "label": "produces", "shape": "dot", "size": 10}, {"color": "#bb57db", "id": "programs with an unbounded number of constant-depth linear recursive clauses", "label": "programs with an unbounded number of constant-depth linear recursive clauses", "shape": "dot", "size": 10}, {"color": "#bb57db", "id": "programs with one constant-depth determinate clause containing an unbounded number of recursive calls", "label": "programs with one constant-depth determinate clause containing an unbounded number of recursive calls", "shape": "dot", "size": 10}, {"color": "#bb57db", "id": "programs with one linear recursive clause of constant locality", "label": "programs with one linear recursive clause of constant locality", "shape": "dot", "size": 10}, {"color": "#d957db", "id": "proof attempt", "label": "proof attempt", "shape": "dot", "size": 80}, {"color": "#61db57", "id": "propositional and first-order domain theories", "label": "propositional and first-order domain theories", "shape": "dot", "size": 20}, {"color": "#db8157", "id": "pruning nonviable operator instances", "label": "pruning nonviable operator instances", "shape": "dot", "size": 50}, {"color": "#db8157", "id": "pruning search", "label": "pruning search", "shape": "dot", "size": 40}, {"color": "#57dba1", "id": "purely local information", "label": "purely local information", "shape": "dot", "size": 30}, {"color": "#7adb57", "id": "quadratic discriminant function", "label": "quadratic discriminant function", "shape": "dot", "size": 20}, {"color": "#57dba5", "id": "qualitative correlations among related data", "label": "qualitative correlations among related data", "shape": "dot", "size": 40}, {"color": "#5857db", "id": "quantum algorithm", "label": "quantum algorithm", "shape": "dot", "size": 10}, {"color": "#db5f57", "id": "quantum parallelism", "label": "quantum parallelism", "shape": "dot", "size": 10}, {"color": "#dbd057", "id": "quick counting", "label": "quick counting", "shape": "dot", "size": 130}, {"color": "#57dba5", "id": "real spectra", "label": "real spectra", "shape": "dot", "size": 20}, {"color": "#db7257", "id": "real-time constraints", "label": "real-time constraints", "shape": "dot", "size": 10}, {"color": "#9cdb57", "id": "real-time constraints imposed by moving vehicle applications", "label": "real-time constraints imposed by moving vehicle applications", "shape": "dot", "size": 10}, {"color": "#9357db", "id": "reasoning", "label": "reasoning", "shape": "dot", "size": 50}, {"color": "#9357db", "id": "recursive clauses", "label": "recursive clauses", "shape": "dot", "size": 40}, {"color": "#db57d4", "id": "recursive constant-depth determinate clause", "label": "recursive constant-depth determinate clause", "shape": "dot", "size": 20}, {"color": "#57db83", "id": "reduces", "label": "reduces", "shape": "dot", "size": 20}, {"color": "#7157db", "id": "region observable POMDP", "label": "region observable POMDP", "shape": "dot", "size": 40}, {"color": "#db577b", "id": "reinforcement", "label": "reinforcement", "shape": "dot", "size": 10}, {"color": "#57db60", "id": "reinforcement learner", "label": "reinforcement learner", "shape": "dot", "size": 40}, {"color": "#57db7e", "id": "reinforcement learning", "label": "reinforcement learning", "shape": "dot", "size": 10}, {"color": "#9d57db", "id": "reliable class probability estimates", "label": "reliable class probability estimates", "shape": "dot", "size": 30}, {"color": "#57dba1", "id": "reorganizing the team", "label": "reorganizing the team", "shape": "dot", "size": 50}, {"color": "#57db83", "id": "repeated", "label": "repeated", "shape": "dot", "size": 20}, {"color": "#57dbd7", "id": "repeated game", "label": "repeated game", "shape": "dot", "size": 10}, {"color": "#c557db", "id": "representing structural concepts", "label": "representing structural concepts", "shape": "dot", "size": 140}, {"color": "#57dba1", "id": "reusability", "label": "reusability", "shape": "dot", "size": 40}, {"color": "#9d57db", "id": "robustness", "label": "robustness", "shape": "dot", "size": 40}, {"color": "#ac57db", "id": "root set", "label": "root set", "shape": "dot", "size": 60}, {"color": "#57db83", "id": "rule", "label": "rule", "shape": "dot", "size": 20}, {"color": "#66db57", "id": "rule-based decision model", "label": "rule-based decision model", "shape": "dot", "size": 20}, {"color": "#5791db", "id": "run time construction", "label": "run time construction", "shape": "dot", "size": 40}, {"color": "#bfdb57", "id": "safely added formulae", "label": "safely added formulae", "shape": "dot", "size": 30}, {"color": "#db5a57", "id": "satisfiability problem", "label": "satisfiability problem", "shape": "dot", "size": 10}, {"color": "#db5a57", "id": "satisfiability problem for all subclasses", "label": "satisfiability problem for all subclasses", "shape": "dot", "size": 20}, {"color": "#579bdb", "id": "scattered throughout the text", "label": "scattered throughout the text", "shape": "dot", "size": 110}, {"color": "#db57ca", "id": "scheduling problems", "label": "scheduling problems", "shape": "dot", "size": 10}, {"color": "#a257db", "id": "scheduling satellite communications", "label": "scheduling satellite communications", "shape": "dot", "size": 10}, {"color": "#7fdb57", "id": "score", "label": "score", "shape": "dot", "size": 10}, {"color": "#db57ad", "id": "screening approach", "label": "screening approach", "shape": "dot", "size": 50}, {"color": "#db8157", "id": "search control", "label": "search control", "shape": "dot", "size": 170}, {"color": "#5764db", "id": "search cost", "label": "search cost", "shape": "dot", "size": 50}, {"color": "#66db57", "id": "search for similar cases", "label": "search for similar cases", "shape": "dot", "size": 30}, {"color": "#57dbdb", "id": "search frontiers passing each other", "label": "search frontiers passing each other", "shape": "dot", "size": 20}, {"color": "#5764db", "id": "search method", "label": "search method", "shape": "dot", "size": 20}, {"color": "#579bdb", "id": "second step", "label": "second step", "shape": "dot", "size": 110}, {"color": "#ac57db", "id": "semantic properties", "label": "semantic properties", "shape": "dot", "size": 30}, {"color": "#dbcb57", "id": "semantic rather than structural information", "label": "semantic rather than structural information", "shape": "dot", "size": 20}, {"color": "#dbcb57", "id": "sentential sense", "label": "sentential sense", "shape": "dot", "size": 60}, {"color": "#57db83", "id": "sequence", "label": "sequence", "shape": "dot", "size": 20}, {"color": "#8057db", "id": "sequentiality between intervals", "label": "sequentiality between intervals", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "sets of clauses in each of the six ordered languages", "label": "sets of clauses in each of the six ordered languages", "shape": "dot", "size": 20}, {"color": "#6c57db", "id": "sigmoid belief networks", "label": "sigmoid belief networks", "shape": "dot", "size": 40}, {"color": "#db5767", "id": "significantly fewer examples", "label": "significantly fewer examples", "shape": "dot", "size": 30}, {"color": "#66db57", "id": "similar cases", "label": "similar cases", "shape": "dot", "size": 30}, {"color": "#c557db", "id": "similar instances of a substructure", "label": "similar instances of a substructure", "shape": "dot", "size": 140}, {"color": "#579bdb", "id": "simple pattern search", "label": "simple pattern search", "shape": "dot", "size": 110}, {"color": "#db57d4", "id": "single k-ary recursive constant-depth determinate clause", "label": "single k-ary recursive constant-depth determinate clause", "shape": "dot", "size": 50}, {"color": "#5782db", "id": "situated explanation", "label": "situated explanation", "shape": "dot", "size": 140}, {"color": "#57c7db", "id": "small, local changes to a theory", "label": "small, local changes to a theory", "shape": "dot", "size": 30}, {"color": "#db57b2", "id": "smaller and more accurate than their axis-parallel counterparts", "label": "smaller and more accurate than their axis-parallel counterparts", "shape": "dot", "size": 10}, {"color": "#dbb857", "id": "smaller consistent decision trees", "label": "smaller consistent decision trees", "shape": "dot", "size": 10}, {"color": "#61db57", "id": "soundness and completeness", "label": "soundness and completeness", "shape": "dot", "size": 20}, {"color": "#db5a57", "id": "spatial algebra", "label": "spatial algebra", "shape": "dot", "size": 10}, {"color": "#9cdb57", "id": "special-purpose massively parallel system", "label": "special-purpose massively parallel system", "shape": "dot", "size": 20}, {"color": "#db8157", "id": "speedups", "label": "speedups", "shape": "dot", "size": 170}, {"color": "#db57ad", "id": "spontaneously spoken language", "label": "spontaneously spoken language", "shape": "dot", "size": 50}, {"color": "#db8157", "id": "spurious clobbering threats", "label": "spurious clobbering threats", "shape": "dot", "size": 50}, {"color": "#61db57", "id": "stability", "label": "stability", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "stable models", "label": "stable models", "shape": "dot", "size": 70}, {"color": "#57d6db", "id": "standard algorithms for exact inference", "label": "standard algorithms for exact inference", "shape": "dot", "size": 80}, {"color": "#db5799", "id": "standard, model-theoretic semantics for description logics", "label": "standard, model-theoretic semantics for description logics", "shape": "dot", "size": 70}, {"color": "#6257db", "id": "state selection strategy of Nature", "label": "state selection strategy of Nature", "shape": "dot", "size": 10}, {"color": "#db57d9", "id": "statistically optimal way to select training data", "label": "statistically optimal way to select training data", "shape": "dot", "size": 90}, {"color": "#57dba1", "id": "stochastic nature", "label": "stochastic nature", "shape": "dot", "size": 20}, {"color": "#db576c", "id": "stratified knowledge base", "label": "stratified knowledge base", "shape": "dot", "size": 20}, {"color": "#57db83", "id": "structure", "label": "structure", "shape": "dot", "size": 140}, {"color": "#db5a57", "id": "subclasses of RCC-5", "label": "subclasses of RCC-5", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "substructure discovery", "label": "substructure discovery", "shape": "dot", "size": 140}, {"color": "#db5799", "id": "subsumption algorithm", "label": "subsumption algorithm", "shape": "dot", "size": 20}, {"color": "#db5767", "id": "symbolic/connectionist debate", "label": "symbolic/connectionist debate", "shape": "dot", "size": 30}, {"color": "#57db83", "id": "symbols", "label": "symbols", "shape": "dot", "size": 20}, {"color": "#57dba1", "id": "system efficiency", "label": "system efficiency", "shape": "dot", "size": 30}, {"color": "#db5776", "id": "systematicity", "label": "systematicity", "shape": "dot", "size": 10}, {"color": "#6757db", "id": "task environment", "label": "task environment", "shape": "dot", "size": 10}, {"color": "#57dba1", "id": "team members", "label": "team members", "shape": "dot", "size": 150}, {"color": "#57dba1", "id": "team members\u0027", "label": "team members\u0027", "shape": "dot", "size": 50}, {"color": "#57dba1", "id": "teamwork", "label": "teamwork", "shape": "dot", "size": 40}, {"color": "#db8157", "id": "techniques and test problems", "label": "techniques and test problems", "shape": "dot", "size": 50}, {"color": "#5791db", "id": "teleo-reactive (T-R) programs", "label": "teleo-reactive (T-R) programs", "shape": "dot", "size": 50}, {"color": "#db5771", "id": "temporal reasoning component", "label": "temporal reasoning component", "shape": "dot", "size": 110}, {"color": "#db5771", "id": "temporal reasoning system", "label": "temporal reasoning system", "shape": "dot", "size": 50}, {"color": "#57dbaf", "id": "termination of general logic programs", "label": "termination of general logic programs", "shape": "dot", "size": 50}, {"color": "#db576c", "id": "terminological cycles", "label": "terminological cycles", "shape": "dot", "size": 10}, {"color": "#db576c", "id": "terminological language", "label": "terminological language", "shape": "dot", "size": 20}, {"color": "#dbb857", "id": "test data", "label": "test data", "shape": "dot", "size": 10}, {"color": "#bfdb57", "id": "theorem provers", "label": "theorem provers", "shape": "dot", "size": 30}, {"color": "#61db57", "id": "theory patching", "label": "theory patching", "shape": "dot", "size": 50}, {"color": "#57c7db", "id": "theory revision", "label": "theory revision", "shape": "dot", "size": 30}, {"color": "#57c7db", "id": "theory-guided constructive induction", "label": "theory-guided constructive induction", "shape": "dot", "size": 30}, {"color": "#9357db", "id": "theta-subsumption", "label": "theta-subsumption", "shape": "dot", "size": 30}, {"color": "#b657db", "id": "topology", "label": "topology", "shape": "dot", "size": 10}, {"color": "#6c57db", "id": "tractable approximation", "label": "tractable approximation", "shape": "dot", "size": 20}, {"color": "#abdb57", "id": "trading off exploration and exploitation", "label": "trading off exploration and exploitation", "shape": "dot", "size": 10}, {"color": "#57dbdb", "id": "traditional approaches", "label": "traditional approaches", "shape": "dot", "size": 10}, {"color": "#dbd057", "id": "traditional direct counting approaches", "label": "traditional direct counting approaches", "shape": "dot", "size": 30}, {"color": "#dbb857", "id": "training data", "label": "training data", "shape": "dot", "size": 20}, {"color": "#db5776", "id": "transformational planning", "label": "transformational planning", "shape": "dot", "size": 20}, {"color": "#c9db57", "id": "transition probability matrices", "label": "transition probability matrices", "shape": "dot", "size": 10}, {"color": "#db575e", "id": "truth maintenance", "label": "truth maintenance", "shape": "dot", "size": 10}, {"color": "#8057db", "id": "two algebras", "label": "two algebras", "shape": "dot", "size": 20}, {"color": "#c557db", "id": "two substructures", "label": "two substructures", "shape": "dot", "size": 140}, {"color": "#db57d4", "id": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "label": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "shape": "dot", "size": 50}, {"color": "#db57d4", "id": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause", "label": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause", "shape": "dot", "size": 20}, {"color": "#579bdb", "id": "unconstrained text", "label": "unconstrained text", "shape": "dot", "size": 110}, {"color": "#57db60", "id": "uncontrollable agent", "label": "uncontrollable agent", "shape": "dot", "size": 60}, {"color": "#57b8db", "id": "undirected networks representing a Markov field", "label": "undirected networks representing a Markov field", "shape": "dot", "size": 30}, {"color": "#57dbaf", "id": "up-acceptable program", "label": "up-acceptable program", "shape": "dot", "size": 20}, {"color": "#5782db", "id": "user interface", "label": "user interface", "shape": "dot", "size": 80}, {"color": "#d3db57", "id": "variable", "label": "variable", "shape": "dot", "size": 50}, {"color": "#dbc157", "id": "vast amounts of", "label": "vast amounts of", "shape": "dot", "size": 20}, {"color": "#57dbdb", "id": "viability of bidirectional heuristic search", "label": "viability of bidirectional heuristic search", "shape": "dot", "size": 10}, {"color": "#9cdb57", "id": "vision-based road detection system", "label": "vision-based road detection system", "shape": "dot", "size": 100}, {"color": "#97db57", "id": "well-founded conclusions", "label": "well-founded conclusions", "shape": "dot", "size": 10}, {"color": "#db8157", "id": "well-founded partial-order planners", "label": "well-founded partial-order planners", "shape": "dot", "size": 40}, {"color": "#db8b57", "id": "well-founded semantics", "label": "well-founded semantics", "shape": "dot", "size": 10}, {"color": "#7adb57", "id": "well-known statistical methods", "label": "well-known statistical methods", "shape": "dot", "size": 20}, {"color": "#7adb57", "id": "world-class Othello program", "label": "world-class Othello program", "shape": "dot", "size": 30}, {"color": "#db8157", "id": "zero commitment plan refinements", "label": "zero commitment plan refinements", "shape": "dot", "size": 40}, {"color": "#70db57", "id": "SPA", "label": "SPA", "shape": "dot", "size": 10}, {"color": "#575adb", "id": "Decision-tree induction", "label": "Decision-tree induction", "shape": "dot", "size": 10}, {"color": "#db6957", "id": "Modifications to address weakness in continuous attribute domains", "label": "Modifications to address weakness in continuous attribute domains", "shape": "dot", "size": 10}, {"color": "#d457db", "id": "Structure in data", "label": "Structure in data", "shape": "dot", "size": 10}, {"color": "#dbae57", "id": "A reported weakness of C4.5 in domains with continuous attributes", "label": "A reported weakness of C4.5 in domains with continuous attributes", "shape": "dot", "size": 10}, {"color": "#7657db", "id": "Iterative optimization", "label": "Iterative optimization", "shape": "dot", "size": 10}, {"color": "#57db74", "id": "past tense", "label": "past tense", "shape": "dot", "size": 10}, {"color": "#57db57", "id": "Restriction", "label": "Restriction", "shape": "dot", "size": 10}, {"color": "#db8657", "id": "Finding a clause-form definition of a relation", "label": "Finding a clause-form definition of a relation", "shape": "dot", "size": 10}, {"color": "#75db57", "id": "Findings definitions", "label": "Findings definitions", "shape": "dot", "size": 10}, {"color": "#57db92", "id": "propositional satisfiability", "label": "propositional satisfiability", "shape": "dot", "size": 10}, {"color": "#57c2db", "id": "Empirical trials show that the modifications lead to smaller decision trees with higher predictive accuracies.", "label": "Empirical trials show that the modifications lead to smaller decision trees with higher predictive accuracies.", "shape": "dot", "size": 10}, {"color": "#db5759", "id": "Definitions", "label": "Definitions", "shape": "dot", "size": 10}, {"color": "#dbc657", "id": "establishing the foundations of the field", "label": "establishing the foundations of the field", "shape": "dot", "size": 10}, {"color": "#a757db", "id": "all possible worlds with domain {1,...,N}", "label": "all possible worlds with domain {1,...,N}", "shape": "dot", "size": 10}, {"color": "#57db5b", "id": "Results also confirm that a new version of C4.5 incorporating these changes is superior to recent approaches that use global discretization and that construct small trees with multi-interval splits.", "label": "Results also confirm that a new version of C4.5 incorporating these changes is superior to recent approaches that use global discretization and that construct small trees with multi-interval splits.", "shape": "dot", "size": 10}, {"color": "#dbda57", "id": "classical hierarchical planning", "label": "classical hierarchical planning", "shape": "dot", "size": 10}, {"color": "#57db88", "id": "Pattern completion", "label": "Pattern completion", "shape": "dot", "size": 10}, {"color": "#88db57", "id": "Evaluation objective function", "label": "Evaluation objective function", "shape": "dot", "size": 10}, {"color": "#dbbd57", "id": "Simplifying hierarchical clusterings", "label": "Simplifying hierarchical clusterings", "shape": "dot", "size": 10}, {"color": "#5769db", "id": "Empirical trials show that the modifications lead to smaller decision trees", "label": "Empirical trials show that the modifications lead to smaller decision trees", "shape": "dot", "size": 10}, {"color": "#db578f", "id": "The modifications apply an MDL-inspired penalty to such tests, eliminating some of them from consideration and altering the relative desirability of all tests.", "label": "The modifications apply an MDL-inspired penalty to such tests, eliminating some of them from consideration and altering the relative desirability of all tests.", "shape": "dot", "size": 10}, {"color": "#db6d57", "id": "set of operations or transformations that can be performed on geometric bodies", "label": "set of operations or transformations that can be performed on geometric bodies", "shape": "dot", "size": 10}, {"color": "#a1db57", "id": "domain specific knowledge", "label": "domain specific knowledge", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "Bayesian", "label": "Bayesian", "shape": "dot", "size": 10}, {"color": "#5782db", "id": "program", "label": "program", "shape": "dot", "size": 10}, {"color": "#db57c0", "id": "perfect rationality", "label": "perfect rationality", "shape": "dot", "size": 10}, {"color": "#575fdb", "id": "deeper in the search space", "label": "deeper in the search space", "shape": "dot", "size": 10}, {"color": "#db57bb", "id": "ANN models", "label": "ANN models", "shape": "dot", "size": 10}, {"color": "#57db79", "id": "property proposed instead of perfect rationality", "label": "property proposed instead of perfect rationality", "shape": "dot", "size": 10}, {"color": "#c4db57", "id": "mean branching rate", "label": "mean branching rate", "shape": "dot", "size": 10}, {"color": "#b0db57", "id": "membership function", "label": "membership function", "shape": "dot", "size": 10}, {"color": "#579fdb", "id": "recursive definitions", "label": "recursive definitions", "shape": "dot", "size": 10}, {"color": "#578cdb", "id": "Cassandra", "label": "Cassandra", "shape": "dot", "size": 10}, {"color": "#db579e", "id": "asymptotic bounded optimality (ABO)", "label": "asymptotic bounded optimality (ABO)", "shape": "dot", "size": 10}, {"color": "#db7c57", "id": "configuration of a collection of geometric bodies", "label": "configuration of a collection of geometric bodies", "shape": "dot", "size": 10}, {"color": "#db57cf", "id": "quantum computers", "label": "quantum computers", "shape": "dot", "size": 10}, {"color": "#ca57db", "id": "optimality criterion", "label": "optimality criterion", "shape": "dot", "size": 10}, {"color": "#b5db57", "id": "abstract", "label": "abstract", "shape": "dot", "size": 10}, {"color": "#83db57", "id": "vocabulary underlying Phi and KB", "label": "vocabulary underlying Phi and KB", "shape": "dot", "size": 10}, {"color": "#57db6f", "id": "different decision-making procedures", "label": "different decision-making procedures", "shape": "dot", "size": 10}, {"color": "#57dbc3", "id": "default strategy", "label": "default strategy", "shape": "dot", "size": 10}, {"color": "#dba457", "id": "efficiently solving the problem of finding the configuration of a collection of geometric bodies to satisfy given constraints by symbolically reasoning about geometry", "label": "efficiently solving the problem of finding the configuration of a collection of geometric bodies to satisfy given constraints by symbolically reasoning about geometry", "shape": "dot", "size": 10}, {"color": "#576edb", "id": "learning from delayed reinforcement", "label": "learning from delayed reinforcement", "shape": "dot", "size": 10}, {"color": "#57db65", "id": "useful control information", "label": "useful control information", "shape": "dot", "size": 10}, {"color": "#db9f57", "id": "maxmin criterion", "label": "maxmin criterion", "shape": "dot", "size": 10}, {"color": "#db7757", "id": "underconstrained/overconstrained problems", "label": "underconstrained/overconstrained problems", "shape": "dot", "size": 10}, {"color": "#9857db", "id": "optimal policy", "label": "optimal policy", "shape": "dot", "size": 10}, {"color": "#6bdb57", "id": "accelerating learning", "label": "accelerating learning", "shape": "dot", "size": 10}, {"color": "#db57b7", "id": "each world", "label": "each world", "shape": "dot", "size": 10}, {"color": "#db5794", "id": "Markovian models", "label": "Markovian models", "shape": "dot", "size": 10}, {"color": "#db57c5", "id": "meaningful progress toward solving a search problem", "label": "meaningful progress toward solving a search problem", "shape": "dot", "size": 10}, {"color": "#db9a57", "id": "action outcome predictability", "label": "action outcome predictability", "shape": "dot", "size": 10}, {"color": "#a6db57", "id": "knowledge base KB", "label": "knowledge base KB", "shape": "dot", "size": 10}, {"color": "#db5763", "id": "uncertainty in the world", "label": "uncertainty in the world", "shape": "dot", "size": 10}, {"color": "#92db57", "id": "making use of generalization and hierarchy", "label": "making use of generalization and hierarchy", "shape": "dot", "size": 10}, {"color": "#db57a3", "id": "collection of geometric shapes or objects", "label": "collection of geometric shapes or objects", "shape": "dot", "size": 10}, {"color": "#57dbc8", "id": "average gradient", "label": "average gradient", "shape": "dot", "size": 10}, {"color": "#d7db57", "id": "comparisons", "label": "comparisons", "shape": "dot", "size": 10}, {"color": "#57dbcd", "id": "coping with hidden state", "label": "coping with hidden state", "shape": "dot", "size": 10}, {"color": "#db5780", "id": "greedy", "label": "greedy", "shape": "dot", "size": 10}, {"color": "#8957db", "id": "rapid hill-climbing", "label": "rapid hill-climbing", "shape": "dot", "size": 10}, {"color": "#57b3db", "id": "desired property", "label": "desired property", "shape": "dot", "size": 10}, {"color": "#8557db", "id": "abstraction by dropping sentences", "label": "abstraction by dropping sentences", "shape": "dot", "size": 10}, {"color": "#9357db", "id": "acquisition", "label": "acquisition", "shape": "dot", "size": 10}, {"color": "#cedb57", "id": "gradient descent and the Baum-Welch algorithm", "label": "gradient descent and the Baum-Welch algorithm", "shape": "dot", "size": 10}, {"color": "#57dbb9", "id": "space of possible heuristic methods", "label": "space of possible heuristic methods", "shape": "dot", "size": 10}, {"color": "#dbb357", "id": "usefulness of the approach", "label": "usefulness of the approach", "shape": "dot", "size": 10}, {"color": "#57dbaa", "id": "two types of negation", "label": "two types of negation", "shape": "dot", "size": 10}, {"color": "#db5785", "id": "qualitative", "label": "qualitative", "shape": "dot", "size": 10}, {"color": "#db57a8", "id": "Gruff recognition system", "label": "Gruff recognition system", "shape": "dot", "size": 10}, {"color": "#5773db", "id": "construct agents with bounded optimality", "label": "construct agents with bounded optimality", "shape": "dot", "size": 10}, {"color": "#57dbbe", "id": "modal mu-calculus", "label": "modal mu-calculus", "shape": "dot", "size": 10}, {"color": "#8ddb57", "id": "total-order planning", "label": "total-order planning", "shape": "dot", "size": 10}, {"color": "#8e57db", "id": "imperfect monitoring case", "label": "imperfect monitoring case", "shape": "dot", "size": 10}, {"color": "#57a4db", "id": "specialized routines used in degrees of freedom analysis to change the configuration of a set of bodies to satisfy new constraints while preserving existing constraints", "label": "specialized routines used in degrees of freedom analysis to change the configuration of a set of bodies to satisfy new constraints while preserving existing constraints", "shape": "dot", "size": 10}, {"color": "#5cdb57", "id": "long plateau search", "label": "long plateau search", "shape": "dot", "size": 10}, {"color": "#5787db", "id": "assessment of practical utility", "label": "assessment of practical utility", "shape": "dot", "size": 10}, {"color": "#5857db", "id": "classical backtrack methods", "label": "classical backtrack methods", "shape": "dot", "size": 10}, {"color": "#db5f57", "id": "unproductive search choices", "label": "unproductive search choices", "shape": "dot", "size": 10}, {"color": "#db7257", "id": "universal ABO programs", "label": "universal ABO programs", "shape": "dot", "size": 10}, {"color": "#db577b", "id": "resemblance to work in psychology", "label": "resemblance to work in psychology", "shape": "dot", "size": 10}, {"color": "#57db7e", "id": "learning through trial-and-error interactions with a dynamic environment", "label": "learning through trial-and-error interactions with a dynamic environment", "shape": "dot", "size": 10}, {"color": "#57dbd7", "id": "Nature", "label": "Nature", "shape": "dot", "size": 10}, {"color": "#db57ca", "id": "domain specific techniques", "label": "domain specific techniques", "shape": "dot", "size": 10}, {"color": "#a257db", "id": "problem distributions based on actual mission requirements", "label": "problem distributions based on actual mission requirements", "shape": "dot", "size": 10}, {"color": "#7fdb57", "id": "mean number of satisfied clauses", "label": "mean number of satisfied clauses", "shape": "dot", "size": 10}, {"color": "#6257db", "id": "unknown", "label": "unknown", "shape": "dot", "size": 10}, {"color": "#6757db", "id": "constrained optimization problem", "label": "constrained optimization problem", "shape": "dot", "size": 10}, {"color": "#b657db", "id": "study of the properties that are preserved under continuous transformations (such as bending, stretching, or crumpling) while preserving the connectivity of a space", "label": "study of the properties that are preserved under continuous transformations (such as bending, stretching, or crumpling) while preserving the connectivity of a space", "shape": "dot", "size": 10}, {"color": "#abdb57", "id": "central issues of reinforcement learning", "label": "central issues of reinforcement learning", "shape": "dot", "size": 10}, {"color": "#c9db57", "id": "sparse or deterministic transition probability matrices", "label": "sparse or deterministic transition probability matrices", "shape": "dot", "size": 10}, {"color": "#97db57", "id": "prioritized logic programs", "label": "prioritized logic programs", "shape": "dot", "size": 10}, {"color": "#db8b57", "id": "preferences between rules", "label": "preferences between rules", "shape": "dot", "size": 10}]);
                  edges = new vis.DataSet([{"from": "A* heuristic", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "A* heuristic", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "A* heuristic", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "A* heuristic", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "ADtree", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "ADtree", "title": "We provide a very sparse data structure, the ADtree, to minimize memory use.", "to": "minimize memory use", "value": 1.0}, {"from": "ADtree", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "ADtree methods", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "ADtree methods", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "ADtree methods", "title": "We show how the ADtree can be used to accelerate Bayes net structure finding algorithms, rule learning algorithms, and feature selection algorithms, and we provide a number of empirical results comparing ADtree methods against traditional direct counting approaches.", "to": "traditional direct counting approaches", "value": 1.0}, {"from": "ADtrees", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "ADtrees", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "ADtrees", "title": "We also discuss the possible uses of ADtrees in other machine learning methods, and discuss the merits of ADtrees in comparison with alternative representations such as kd-trees, R-trees and Frequent Sets.", "to": "merits", "value": 1.0}, {"from": "ALCNR", "title": "The capabilities of this TKRS go beyond those of presently available ones because it uses a highly expressive terminological language called ALCNR, which includes general complements of concepts, number restrictions, and role conjunction.", "to": "highly expressive terminological language", "value": 1.0}, {"from": "ALCNR", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "ALCNR-knowledge bases", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "ALCNR-knowledge bases", "title": "A number of desirable TKRS-deduction services, like satisfiability, subsumption, and instance checking, are decidable for reasoning in ALCNR-knowledge bases.", "to": "desirable TKRS-deduction services", "value": 1.0}, {"from": "ANNs", "title": "Several artificial neural networks (ANNs) have been implemented, and a challenge for better symbolic models has been posed. In this paper, we present a general-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree learning algorithm ID3.", "to": "SPA", "value": 1.0}, {"from": "Abundant computing power", "title": "The ability to exploit abundant computing power improves the algorithm\u0027s ability to generalize.,contextual proximity", "to": "An algorithm that learns from a set of examples", "value": 1.5}, {"from": "Abundant computing power", "title": "contextual proximity", "to": "REGENT algorithm", "value": 0.75}, {"from": "Activate", "title": "We propose an improvement to the standard local activation function used for such networks.", "to": "Improvement to standard local activation function", "value": 1.0}, {"from": "Activate", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Activate only one unit at a time", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Activate only one unit at a time", "title": "An asynchronous scheduler can activate only one unit at a time while a synchronous scheduler can activate any number of units in a single time step.", "to": "Asynchronous scheduler", "value": 1.0}, {"from": "Activities and resource allocations", "title": "contextual proximity", "to": "Artificial economy", "value": 0.5}, {"from": "Activities and resource allocations", "title": "By computing the competitive equilibrium of an artificial economy, we can derive the activities and resource allocations for a set of computational agents.,contextual proximity", "to": "Competitive equilibrium", "value": 1.5}, {"from": "Activities and resource allocations", "title": "contextual proximity", "to": "Market price systems", "value": 2.25}, {"from": "Algorithmic", "title": "Showing that finding a plan algorithmically is intractable even for simple classes of systems.,contextual proximity", "to": "Plan-design process", "value": 1.5}, {"from": "Allen\u0027s interval algebra", "title": "contextual proximity", "to": "Horn DLRs", "value": 0.75}, {"from": "Allen\u0027s interval algebra", "title": "contextual proximity", "to": "eight new maximal tractable subclasses of Allen\u0027s interval algebra", "value": 0.75}, {"from": "Allen\u0027s interval algebra", "title": "contextual proximity", "to": "maximal tractable subclasses of Allen\u0027s interval algebra", "value": 0.75}, {"from": "Allen\u0027s interval algebra", "title": "contextual proximity", "to": "sequentiality between intervals", "value": 0.75}, {"from": "Allen\u0027s interval algebra", "title": "contextual proximity", "to": "two algebras", "value": 0.75}, {"from": "Allen\u0027s interval-based framework for representing temporal information", "title": "contextual proximity", "to": "algorithms for determining whether the temporal information is consistent", "value": 0.5}, {"from": "Allen\u0027s interval-based framework for representing temporal information", "title": "contextual proximity", "to": "backtracking algorithm", "value": 0.5}, {"from": "Allen\u0027s interval-based framework for representing temporal information", "title": "contextual proximity", "to": "path consistency algorithm", "value": 0.5}, {"from": "Allen\u0027s interval-based framework for representing temporal information", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "Allen\u0027s interval-based framework for representing temporal information", "title": "based on", "to": "temporal reasoning system", "value": 1.0}, {"from": "An algorithm that learns from a set of examples", "title": "contextual proximity", "to": "An initial population of knowledge-based neural networks", "value": 0.5}, {"from": "An algorithm that learns from a set of examples", "title": "contextual proximity", "to": "Better network topologies", "value": 0.5}, {"from": "An algorithm that learns from a set of examples", "title": "contextual proximity", "to": "Domain-specific knowledge", "value": 0.5}, {"from": "An algorithm that learns from a set of examples", "title": "contextual proximity", "to": "Genetic operators of crossover and mutation (specifically designed for knowledge-based networks)", "value": 0.5}, {"from": "An algorithm that learns from a set of examples", "title": "contextual proximity", "to": "REGENT algorithm", "value": 1.5}, {"from": "An initial population of knowledge-based neural networks", "title": "The REGENT algorithm uses domain-specific knowledge to create an initial population of knowledge-based neural networks.,contextual proximity", "to": "REGENT algorithm", "value": 1.75}, {"from": "Arbitrary lambda", "title": "contextual proximity", "to": "Reinforcement learning algorithms", "value": 0.5}, {"from": "Arbitrary lambda", "title": "contextual proximity", "to": "TD methods", "value": 0.5}, {"from": "Arbitrary lambda", "title": "The TTD procedure can be used with arbitrary function representation methods and requires very little computation per action.,contextual proximity", "to": "TTD", "value": 1.5}, {"from": "Artificial Intelligence", "title": "contextual proximity", "to": "formulae", "value": 0.5}, {"from": "Artificial Intelligence", "title": "Nonmonotonic logic is a characteristic of many logics used in Artificial Intelligence.,contextual proximity", "to": "nonmonotonicity", "value": 1.5}, {"from": "Artificial Intelligence", "title": "contextual proximity", "to": "preferential logics", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Behavior analysis", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Competitive equilibrium", "value": 1.0}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Computational agents", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Computational market structures", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Distributed problem solving", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Efficient distributed resource allocation", "value": 0.5}, {"from": "Artificial economy", "title": "We compute the competitive equilibrium of an artificial economy to derive the activities and resource allocations for a set of computational agents in market-oriented programming approach.,contextual proximity", "to": "Market price systems", "value": 5.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Mechanisms for decentralized decision making", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Multicommodity flow problem", "value": 0.5}, {"from": "Artificial economy", "title": "contextual proximity", "to": "Price equilibria", "value": 0.5}, {"from": "Assumptions", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "Assumptions", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "Asynchronous scheduler", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Attribute-selection measures", "title": "Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate and simplicity dimensions.", "to": "Decision-tree induction", "value": 1.0}, {"from": "Bayesian network", "title": "contextual proximity", "to": "Bayesian network inference", "value": 1.0}, {"from": "Bayesian network", "title": "contextual proximity", "to": "CPCS networks for medical diagnosis", "value": 0.5}, {"from": "Bayesian network", "title": "contextual proximity", "to": "VE algorithm", "value": 1.0}, {"from": "Bayesian network", "title": "enables one to further factorize the conditional probabilities into smaller factors,contextual proximity", "to": "causal independence", "value": 2.0}, {"from": "Bayesian network", "title": "contextual proximity", "to": "conditional probability", "value": 0.5}, {"from": "Bayesian network", "title": "contextual proximity", "to": "joint probability", "value": 0.5}, {"from": "Bayesian network", "title": "contextual proximity", "to": "variable", "value": 0.5}, {"from": "Bayesian network inference", "title": "empirical studies based on these networks show that the proposed method is more efficient than previous methods and allows for inference in larger networks than previous algorithms,contextual proximity", "to": "CPCS networks for medical diagnosis", "value": 1.5}, {"from": "Bayesian network inference", "title": "uses the factorization to find the posterior distribution of the query,contextual proximity", "to": "VE algorithm", "value": 2.0}, {"from": "Bayesian network inference", "title": "contextual proximity", "to": "causal independence", "value": 1.0}, {"from": "Bayesian network inference", "title": "contextual proximity", "to": "conditional probability", "value": 0.5}, {"from": "Bayesian network inference", "title": "contextual proximity", "to": "joint probability", "value": 0.5}, {"from": "Bayesian network inference", "title": "contextual proximity", "to": "variable", "value": 0.5}, {"from": "Bayesian networks", "title": "contextual proximity", "to": "graphical framework", "value": 0.5}, {"from": "Bayesian networks", "title": "Graphical models include Bayesian networks, which are directed graphs representing a Markov chain.,contextual proximity", "to": "graphical models", "value": 2.0}, {"from": "Bayesian networks", "title": "contextual proximity", "to": "graphical specification", "value": 0.5}, {"from": "Behavior analysis", "title": "contextual proximity", "to": "Competitive equilibrium", "value": 0.5}, {"from": "Behavior analysis", "title": "The behavior of the system can be meaningfully analyzed in economic terms.,contextual proximity", "to": "Market price systems", "value": 3.25}, {"from": "Better network topologies", "title": "By using genetic operators, the REGENT algorithm is able to refine the topology of the neural networks it produces, which helps improve generalization, especially when given impoverished domain theories.,contextual proximity", "to": "REGENT algorithm", "value": 1.75}, {"from": "Boltzman machines", "title": "Are examples of symmetric networks designed for energy minimization.", "to": "Hopfield nets", "value": 1.0}, {"from": "Boltzman machines", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "C4.5", "title": "A reported weakness of C4.5 in domains with continuous attributes is addressed by modifying the formation and evaluation of tests on continuous attributes.", "to": "Modifications to address weakness in continuous attribute domains", "value": 1.0}, {"from": "C4.5 and backpropagation", "title": "contextual proximity", "to": "distributed output representation", "value": 0.5}, {"from": "C4.5 and backpropagation", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "C4.5 and backpropagation", "title": "contextual proximity", "to": "multiclass learning problems", "value": 1.0}, {"from": "CBP", "title": "contextual proximity", "to": "Case library", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "Case-Based Planning (CBP)", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "DERSNLP+EBL", "value": 2.0}, {"from": "CBP", "title": "contextual proximity", "to": "Domain-independent planning", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "Mis-retrieval problem", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "Multi-goal problems", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "Performance improvements over generative (from-scratch) planning", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "Replay framework", "value": 0.5}, {"from": "CBP", "title": "contextual proximity", "to": "Similarity judgements", "value": 0.5}, {"from": "CLASSIC", "title": "contextual proximity", "to": "description graphs", "value": 0.5}, {"from": "CLASSIC", "title": "contextual proximity", "to": "standard, model-theoretic semantics for description logics", "value": 0.5}, {"from": "CLASSIC", "title": "CLASSIC is a description logic-based knowledge representation system that is being used in practical applications.", "to": "description logics", "value": 1.0}, {"from": "CLASSIC descriptions", "title": "contextual proximity", "to": "description graphs", "value": 0.5}, {"from": "CLASSIC descriptions", "title": "contextual proximity", "to": "standard, model-theoretic semantics for description logics", "value": 0.5}, {"from": "CLASSIC descriptions", "title": "In order to deal efficiently with individuals in CLASSIC descriptions, the developers have had to use an algorithm that is incomplete with respect to the standard, model-theoretic semantics for description logics.", "to": "individuals", "value": 1.0}, {"from": "CNF conversion", "title": "In this paper, we propose a way to modify GSAT to apply it to non-clausal formulas by using a particular \u0027score\u0027 function that calculates the number of false clauses in the CNF conversion of a formula under a given truth assignment. This value is computed in linear time without constructing the entire CNF conversion.,contextual proximity", "to": "GSAT", "value": 1.5}, {"from": "CPCS networks for medical diagnosis", "title": "contextual proximity", "to": "VE algorithm", "value": 0.5}, {"from": "CPCS networks for medical diagnosis", "title": "contextual proximity", "to": "causal independence", "value": 0.5}, {"from": "CSP", "title": "contextual proximity", "to": "MUSE CSP", "value": 2.0}, {"from": "Case library", "title": "DERSNLP+EBL extends current CBP methodology by incorporating explanation-based learning techniques that allow it to explain and learn from the retrieval failures it encounters.,contextual proximity", "to": "DERSNLP+EBL", "value": 2.0}, {"from": "Case-Based Planning (CBP)", "title": "contextual proximity", "to": "DERSNLP+EBL", "value": 1.0}, {"from": "Case-Based Planning (CBP)", "title": "CBP is a way of scaling up domain-independent planning to solve large problems in complex domains.", "to": "Domain-independent planning", "value": 1.0}, {"from": "Characteristic models", "title": "contextual proximity", "to": "Decision problem", "value": 0.75}, {"from": "Characteristic models", "title": "Translation questions arise between these representations, and translating is equivalent to deciding whether a given set of models is the set of characteristic models for a given Horn expression.,contextual proximity", "to": "Horn expressions", "value": 4.0}, {"from": "Characteristic models", "title": "contextual proximity", "to": "Hypergraph transversal problem", "value": 1.5}, {"from": "Classification accuracy", "title": "contextual proximity", "to": "Continuous input values", "value": 0.5}, {"from": "Classification accuracy", "title": "contextual proximity", "to": "Instance-based learning techniques", "value": 0.5}, {"from": "Classification accuracy", "title": "contextual proximity", "to": "Nominal input attributes", "value": 0.5}, {"from": "Classification accuracy", "title": "In experiments on 48 applications, the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.", "to": "Distance functions", "value": 1.0}, {"from": "Clustering", "title": "Clustering is often used for discovering structure in data.", "to": "Structure in data", "value": 1.0}, {"from": "Clusters", "title": "contextual proximity", "to": "Local minima", "value": 0.5}, {"from": "Clusters", "title": "contextual proximity", "to": "Local search algorithms", "value": 0.5}, {"from": "Clusters", "title": "The solutions of randomly generated problem instances form clusters that behave similarly to local minima.,contextual proximity", "to": "Plateaus with exits (benches)", "value": 1.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Computational agents", "value": 0.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Computational market structures", "value": 0.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Distributed problem solving", "value": 0.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Efficient distributed resource allocation", "value": 0.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Market price systems", "value": 4.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Mechanisms for decentralized decision making", "value": 0.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Multicommodity flow problem", "value": 0.5}, {"from": "Competitive equilibrium", "title": "contextual proximity", "to": "Price equilibria", "value": 0.5}, {"from": "Complexity drawbacks", "title": "contextual proximity", "to": "Horn approximation", "value": 0.5}, {"from": "Complexity drawbacks", "title": "contextual proximity", "to": "Minimum-change update", "value": 0.5}, {"from": "Complexity drawbacks", "title": "Represents the relationship between complexity drawbacks and theory update and revision schemes. This can be seen as an illustration of how these schemes suffer from serious complexity-theoretic impediments.", "to": "Theory update and revision schemes", "value": 1.0}, {"from": "Computational agents", "title": "In a market-oriented programming approach, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy.,contextual proximity", "to": "Market price systems", "value": 3.25}, {"from": "Computational biology", "title": "We briefly discuss a potential application of dynamic probabilistic reasoning in computational biology.", "to": "Dynamic probabilistic reasoning", "value": 1.0}, {"from": "Computational biology", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "Computational market structures", "title": "WALRAS provides basic constructs for defining computational market structures.,contextual proximity", "to": "Market price systems", "value": 3.25}, {"from": "Constraint Satisfaction Problem (CSP)", "title": "Extension of CSP called MUSE CSP is especially useful for problems that segment into multiple sets of partially shared variables, arising naturally in signal processing applications including computer vision, speech processing, and handwriting recognition.,contextual proximity", "to": "MUSE CSP", "value": 3.0}, {"from": "Continuous attribute domains", "title": "", "to": "A reported weakness of C4.5 in domains with continuous attributes", "value": 1.0}, {"from": "Continuous field", "title": "contextual proximity", "to": "Imagistic reasoning", "value": 0.5}, {"from": "Continuous field", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "Continuous field", "title": "A program written in this paradigm takes a continuous field as input.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "Continuous input values", "title": "contextual proximity", "to": "Distance functions", "value": 0.5}, {"from": "Continuous input values", "title": "These new distance functions (HVDM, IVDM, WVDM) are designed to handle applications with continuous attributes.,contextual proximity", "to": "Instance-based learning techniques", "value": 2.0}, {"from": "Continuous input values", "title": "The paper proposes three new heterogeneous distance functions (HVDM, IVDM, WVDM) that are designed to handle applications with nominal attributes, continuous attributes, or both.,contextual proximity", "to": "Nominal input attributes", "value": 2.0}, {"from": "Control strategy", "title": "Each of which repeatedly modifies an initial clustering in search of a better one. One of these methods appears novel as an iterative optimization strategy in clustering contexts.", "to": "Iterative optimization", "value": 1.0}, {"from": "Converge to a global minimum", "title": "For acyclic networks, the algorithm is guaranteed to converge to a global minimum from any initial state of the system (self-stabilization).", "to": "From any initial state of the system", "value": 1.0}, {"from": "Converge to a global minimum", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Correctly classifies", "title": "contextual proximity", "to": "PTR", "value": 0.5}, {"from": "Correctly classifies", "title": "PTR converges to a theory that correctly classifies all examples.,contextual proximity", "to": "Ptr", "value": 1.5}, {"from": "Cycle-cutset scheme", "title": "Finally, we show how the algorithm can be improved using the cycle-cutset scheme. The general algorithm, called activate-with-cutset, improves over activate and has some performance guarantees that are related to the size of the network\u0027s cycle-cutset.", "to": "Improves over activate", "value": 1.0}, {"from": "Cycle-cutset scheme", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "DERSNLP+EBL", "title": "contextual proximity", "to": "Domain-independent planning", "value": 1.0}, {"from": "DERSNLP+EBL", "title": "contextual proximity", "to": "Mis-retrieval problem", "value": 1.0}, {"from": "DERSNLP+EBL", "title": "contextual proximity", "to": "Multi-goal problems", "value": 1.0}, {"from": "DERSNLP+EBL", "title": "contextual proximity", "to": "Performance improvements over generative (from-scratch) planning", "value": 1.0}, {"from": "DERSNLP+EBL", "title": "contextual proximity", "to": "Replay framework", "value": 1.0}, {"from": "DERSNLP+EBL", "title": "contextual proximity", "to": "Similarity judgements", "value": 1.0}, {"from": "Decision problem", "title": "contextual proximity", "to": "Horn expressions", "value": 1.0}, {"from": "Decision problem", "title": "contextual proximity", "to": "Hypergraph transversal problem", "value": 0.5}, {"from": "Decision trees", "title": "The resulting more complex decision trees are demonstrated to have, on average, for a variety of common learning tasks, higher predictive accuracy than the less complex original decision trees.", "to": "More complex decision trees", "value": 1.0}, {"from": "Decision trees", "title": "contextual proximity", "to": "Occam\u0027s razor", "value": 0.5}, {"from": "Decision trees", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 0.5}, {"from": "Decision trees produced by C4.5", "title": "contextual proximity", "to": "Occam\u0027s razor", "value": 0.5}, {"from": "Decision trees produced by C4.5", "title": "A systematic procedure is presented for post-processing decision trees produced by C4.5.", "to": "Post-processing decision trees", "value": 1.0}, {"from": "Decision trees produced by C4.5", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 0.5}, {"from": "Deficient domain theory", "title": "Examples expose inaccuracies in the domain theory, leading to the need for revision.", "to": "Examples", "value": 1.0}, {"from": "Deficient domain theory", "title": "contextual proximity", "to": "PTR", "value": 0.5}, {"from": "Deficient domain theory", "title": "contextual proximity", "to": "Ptr", "value": 0.5}, {"from": "Discounted sum of rewards", "title": "TD methods are used to learn predictions in reinforcement learning algorithms optimizing the discounted sum of rewards.,contextual proximity", "to": "Reinforcement learning algorithms", "value": 1.5}, {"from": "Discounted sum of rewards", "title": "contextual proximity", "to": "TD methods", "value": 0.5}, {"from": "Discounted sum of rewards", "title": "contextual proximity", "to": "TTD", "value": 0.5}, {"from": "Distance functions", "title": "contextual proximity", "to": "Instance-based learning techniques", "value": 0.5}, {"from": "Distance functions", "title": "contextual proximity", "to": "Nominal input attributes", "value": 0.5}, {"from": "Distributed problem solving", "title": "In a market-oriented programming approach to distributed problem solving, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy.,contextual proximity", "to": "Market price systems", "value": 3.25}, {"from": "Does not assume network is tree-like", "title": "The improved algorithm, called activate, is uniform and does not assume that the network is tree-like.,contextual proximity", "to": "Uniform algorithm", "value": 1.75}, {"from": "Does not exist for acyclic networks", "title": "No uniform algorithm exists to optimize even acyclic networks when the scheduler is synchronous.,contextual proximity", "to": "Uniform algorithm", "value": 1.75}, {"from": "Does not exist for cycles", "title": "In the presence of cycles, no uniform algorithm exists that guarantees optimality even under a sequential asynchronous scheduler.,contextual proximity", "to": "Uniform algorithm", "value": 1.75}, {"from": "Domain theory", "title": "contextual proximity", "to": "PTR", "value": 0.5}, {"from": "Domain theory", "title": "contextual proximity", "to": "Ptr", "value": 0.5}, {"from": "Domain theory", "title": "Theory revision problem involves modifying a domain theory to address its deficiencies as revealed by examples.", "to": "Theory revision problem", "value": 1.0}, {"from": "Domain-specific knowledge", "title": "contextual proximity", "to": "REGENT algorithm", "value": 0.75}, {"from": "Dynamic data structure", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "Dynamic data structure", "title": "We propose a dynamic data structure that supports efficient algorithms for updating and querying singly connected Bayesian networks.", "to": "Singly connected Bayesian networks", "value": 1.0}, {"from": "Dynamic probabilistic reasoning", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "Dynamic reasoning in probabilistic databases", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "Dynamic reasoning in probabilistic databases", "title": "Our goal is to take a first step toward dynamic reasoning in probabilistic databases with comparable efficiency as traditional databases commonly support efficient query and update procedures that operate in time which is sublinear in the size of the database.", "to": "Traditional databases", "value": 1.0}, {"from": "EG2", "title": "contextual proximity", "to": "ICET", "value": 1.25}, {"from": "Effective in reducing search-space size", "title": "contextual proximity", "to": "LCFR", "value": 0.5}, {"from": "Effective in reducing search-space size", "title": "For many problems, combining least-cost flaw selection with delaying separable threats leads to an effective strategy for reducing search-space size without excessive computational overhead. Although this strategy provides a good default, its effectiveness may be reduced by certain domain characteristics.,For many problems, combining least-cost flaw selection with delaying separable threats leads to an effective strategy for reducing search-space size without excessive computational overhead. Although this strategy provides a good default, its effectiveness may be reduced by certain domain characteristics.,contextual proximity", "to": "Least-Cost Flaw Repair (LCFR)", "value": 2.5}, {"from": "Effective in reducing search-space size", "title": "contextual proximity", "to": "ZLIFO Strategy", "value": 0.5}, {"from": "Efficiency", "title": "contextual proximity", "to": "Horn approximation", "value": 0.5}, {"from": "Efficiency", "title": "contextual proximity", "to": "Minimum-change update", "value": 0.5}, {"from": "Efficient distributed resource allocation", "title": "We see that careful construction of the decision process according to economic principles can lead to efficient distributed resource allocation.,contextual proximity", "to": "Market price systems", "value": 3.25}, {"from": "Eight Puzzle", "title": "contextual proximity", "to": "Speedup learning", "value": 0.5}, {"from": "Eight Puzzle", "title": "contextual proximity", "to": "Speedup learning framework", "value": 1.25}, {"from": "Empirical learning of control rules", "title": "contextual proximity", "to": "Speedup learning", "value": 0.5}, {"from": "Empirical learning of control rules", "title": "contextual proximity", "to": "Speedup learning framework", "value": 1.25}, {"from": "Energy minimization", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Energy minimization", "title": "Such networks are frequently investigated for use in optimization, constraint satisfaction and approximation of NP-hard problems.", "to": "Symmetric networks", "value": 1.0}, {"from": "English verbs", "title": "The past tense of English verbs is a topic for testing the adequacy of cognitive modeling.", "to": "past tense", "value": 1.0}, {"from": "Equivalence classes and adjacency relations", "title": "contextual proximity", "to": "Imagistic reasoning", "value": 0.5}, {"from": "Equivalence classes and adjacency relations", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "Equivalence classes and adjacency relations", "title": "A program written in this paradigm forms equivalence classes and adjacency relations to compute spatial aggregates.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "Escaping plateaus", "title": "contextual proximity", "to": "Local minima", "value": 0.5}, {"from": "Escaping plateaus", "title": "Escaping local minima without unsatisfying a large number of clauses can be computationally expensive if the local minimum is large.,contextual proximity", "to": "Local search algorithms", "value": 1.5}, {"from": "Escaping plateaus", "title": "contextual proximity", "to": "Plateaus with exits (benches)", "value": 0.5}, {"from": "Even in cyclic topologies", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Even in cyclic topologies", "title": "The algorithm can identify tree-like subnetworks even in cyclic topologies (arbitrary networks).", "to": "Identify tree-like subnetworks", "value": 1.0}, {"from": "Examples", "title": "contextual proximity", "to": "PTR", "value": 0.5}, {"from": "Examples", "title": "contextual proximity", "to": "Ptr", "value": 0.5}, {"from": "Expert level performance", "title": "Programs incorporating imagistic reasoning can perform at an expert level in domains that defy current analytic or numerical methods, as demonstrated by the research mentioned in the context.,contextual proximity", "to": "Imagistic reasoning", "value": 1.5}, {"from": "Expert level performance", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "Expert level performance", "title": "contextual proximity", "to": "Spatial aggregation", "value": 2.0}, {"from": "Explanation-Based Learning (EBL)", "title": "contextual proximity", "to": "Speedup learning", "value": 0.5}, {"from": "Explanation-Based Learning (EBL)", "title": "contextual proximity", "to": "Speedup learning framework", "value": 1.25}, {"from": "Exponential number of steps", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Exponential number of steps", "title": "Finding a global solution in such networks may take an exponential number of steps and even a local solution is not guaranteed.", "to": "Global solution", "value": 1.0}, {"from": "FLARE", "title": "contextual proximity", "to": "classical AI", "value": 0.5}, {"from": "FLARE", "title": "contextual proximity", "to": "intelligence", "value": 1.0}, {"from": "FLARE", "title": "contextual proximity", "to": "learning", "value": 1.5}, {"from": "FLARE", "title": "contextual proximity", "to": "machine learning", "value": 0.5}, {"from": "FLARE", "title": "contextual proximity", "to": "reasoning", "value": 1.5}, {"from": "FLECS", "title": "contextual proximity", "to": "delayed-commitment", "value": 0.5}, {"from": "FLECS", "title": "Introducing this new planning algorithm, FLECS, which uses a FLExible Commitment Strategy with respect to plan-step orderings.", "to": "planning algorithm", "value": 1.0}, {"from": "FOIDL", "title": "contextual proximity", "to": "explicit negative examples", "value": 1.0}, {"from": "FOIDL", "title": "contextual proximity", "to": "first-order decision lists", "value": 2.0}, {"from": "FOIDL", "title": "contextual proximity", "to": "intensional background knowledge", "value": 1.0}, {"from": "FOIDL", "title": "contextual proximity", "to": "learning a new class of concepts", "value": 2.0}, {"from": "FOIDL", "title": "contextual proximity", "to": "significantly fewer examples", "value": 1.0}, {"from": "FOIDL", "title": "contextual proximity", "to": "symbolic/connectionist debate", "value": 1.0}, {"from": "Faster learning times", "title": "Leads to", "to": "Restriction", "value": 1.0}, {"from": "First-order learning", "title": "Involves", "to": "Finding a clause-form definition of a relation", "value": 1.0}, {"from": "Fisher\u0027s linear discriminant", "title": "contextual proximity", "to": "game-tree search", "value": 1.0}, {"from": "Fisher\u0027s linear discriminant", "title": "contextual proximity", "to": "logistic regression", "value": 0.5}, {"from": "Flawed elements", "title": "contextual proximity", "to": "PTR", "value": 0.5}, {"from": "Flawed elements", "title": "PTR efficiently locates and repairs flawed elements of the theory.,contextual proximity", "to": "Ptr", "value": 1.5}, {"from": "From any initial state of the system", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Functional relations", "title": "Customization for", "to": "Findings definitions", "value": 1.0}, {"from": "GSAT", "title": "contextual proximity", "to": "Non-clausal formulas", "value": 0.5}, {"from": "GSAT", "title": "GSAT is an approximation procedure for propositional satisfiability.", "to": "propositional satisfiability", "value": 1.0}, {"from": "Gaussian Bayesian networks", "title": "contextual proximity", "to": "graphical framework", "value": 0.5}, {"from": "Gaussian Bayesian networks", "title": "contextual proximity", "to": "graphical models", "value": 1.0}, {"from": "Gaussian Bayesian networks", "title": "contextual proximity", "to": "graphical specification", "value": 0.5}, {"from": "Gaussian Bayesian networks", "title": "Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification, including learning Gaussian and discrete Bayesian networks from data.", "to": "learning Gaussian and discrete Bayesian networks from data", "value": 1.0}, {"from": "Generic operators", "title": "contextual proximity", "to": "Imagistic reasoning", "value": 0.5}, {"from": "Generic operators", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "Generic operators", "title": "A program written in this paradigm employs a small set of generic operators such as aggregation, classification, and localization to perform bidirectional mapping between the information-rich field and successively more abstract spatial aggregates.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "Genetic operators of crossover and mutation (specifically designed for knowledge-based networks)", "title": "The REGENT algorithm uses genetic operators to continually search for better network topologies.,contextual proximity", "to": "REGENT algorithm", "value": 1.75}, {"from": "Gibbs sampling", "title": "contextual proximity", "to": "graphical framework", "value": 0.5}, {"from": "Gibbs sampling", "title": "contextual proximity", "to": "graphical models", "value": 1.0}, {"from": "Gibbs sampling", "title": "contextual proximity", "to": "graphical specification", "value": 0.5}, {"from": "Global solution", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Goal to achieve", "title": "contextual proximity", "to": "Plan-design process", "value": 0.5}, {"from": "Goal to achieve", "title": "In a partially known environment, the agent learns and adapts its plans to achieve the given goal.", "to": "Planning while Learning", "value": 1.0}, {"from": "HIPAIR", "title": "contextual proximity", "to": "Imagistic reasoning", "value": 0.5}, {"from": "HIPAIR", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "HIPAIR", "title": "contextual proximity", "to": "Spatial aggregation", "value": 2.0}, {"from": "High-level descriptions of structure, behavior, or control actions", "title": "contextual proximity", "to": "Imagistic reasoning", "value": 0.5}, {"from": "High-level descriptions of structure, behavior, or control actions", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "High-level descriptions of structure, behavior, or control actions", "title": "A program written in this paradigm produces high-level descriptions of structure, behavior, or control actions.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "Higher predictive accuracies", "title": "", "to": "Empirical trials show that the modifications lead to smaller decision trees with higher predictive accuracies.", "value": 1.0}, {"from": "Higher predictive accuracy", "title": "In some cases, result of", "to": "Definitions", "value": 1.0}, {"from": "Hopfield nets", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Horn core", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Horn envelope", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Inductivity", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Lower Horn formula", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Minimum-change update", "value": 1.0}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Model-based updates", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Set of formulas represented by Horn approximation", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Theory update and revision schemes", "value": 0.5}, {"from": "Horn approximation", "title": "contextual proximity", "to": "Upper Horn formula", "value": 0.5}, {"from": "Horn core", "title": "contextual proximity", "to": "Minimum-change update", "value": 0.5}, {"from": "Horn envelope", "title": "contextual proximity", "to": "Minimum-change update", "value": 0.5}, {"from": "Horn expressions", "title": "The translation problems are equivalent to the hypergraph transversal problem in a special case.,contextual proximity", "to": "Hypergraph transversal problem", "value": 3.0}, {"from": "ICET", "title": "contextual proximity", "to": "cost-sensitive classification", "value": 1.25}, {"from": "ICET", "title": "contextual proximity", "to": "decision tree", "value": 1.25}, {"from": "ICET", "title": "contextual proximity", "to": "five real-world medical datasets", "value": 1.25}, {"from": "ICET", "title": "contextual proximity", "to": "genetic algorithm", "value": 1.25}, {"from": "IE discourse component", "title": "contextual proximity", "to": "Unrestricted text", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "Wrap-Up", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "acquires knowledge for some of the higher level IE processing", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "higher level IE processing", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "information extraction (IE) processing", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "machine learning", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "partially trainable discourse module", "value": 0.5}, {"from": "IE discourse component", "title": "contextual proximity", "to": "vast amounts of", "value": 0.5}, {"from": "Identify tree-like subnetworks", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Image-like analogue representations", "title": "Imagistic reasoning organizes computations around image-like, analogue representations as identified through research on automating diverse reasoning tasks.,contextual proximity", "to": "Imagistic reasoning", "value": 1.5}, {"from": "Image-like analogue representations", "title": "contextual proximity", "to": "Implemented problem solver", "value": 0.75}, {"from": "Image-like analogue representations", "title": "contextual proximity", "to": "Spatial aggregation", "value": 2.0}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Implemented problem solver", "value": 1.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Intermediate representations", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "KAM", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "MAPS", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Neighborhood graph", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Optional objective functions", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Scientific reasoning", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Spatial aggregation", "value": 4.0}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Unified description of imagistic problem solvers", "value": 0.5}, {"from": "Imagistic reasoning", "title": "contextual proximity", "to": "Visual thinking", "value": 0.5}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Intermediate representations", "value": 0.75}, {"from": "Implemented problem solver", "title": "The given context mentions KAM, an implemented problem solver.,contextual proximity", "to": "KAM", "value": 1.75}, {"from": "Implemented problem solver", "title": "The given context mentions MAPS, an implemented problem solver.,contextual proximity", "to": "MAPS", "value": 1.75}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Neighborhood graph", "value": 0.75}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Optional objective functions", "value": 0.75}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Scientific reasoning", "value": 0.75}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Spatial aggregation", "value": 6.0}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Unified description of imagistic problem solvers", "value": 0.75}, {"from": "Implemented problem solver", "title": "contextual proximity", "to": "Visual thinking", "value": 0.75}, {"from": "Improvement to standard local activation function", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Improves over activate", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Inductive theorem provers", "title": "contextual proximity", "to": "computer program", "value": 0.75}, {"from": "Inductive theorem provers", "title": "contextual proximity", "to": "critic", "value": 1.25}, {"from": "Inductive theorem provers", "title": "often,contextual proximity", "to": "diverging proof attempts", "value": 1.5}, {"from": "Inductive theorem provers", "title": "contextual proximity", "to": "proof attempt", "value": 0.75}, {"from": "Inductivity", "title": "contextual proximity", "to": "Minimum-change update", "value": 0.5}, {"from": "Inductivity", "title": "Represents the relationship between inductivity and model-based updates. This can be seen as an illustration of how this scheme preserves positive properties of the represented sets of formulas during updates.", "to": "Model-based updates", "value": 1.0}, {"from": "Instance-based learning techniques", "title": "contextual proximity", "to": "Nominal input attributes", "value": 1.0}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "Interactive tutorial instruction", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "Situated explanation-based learning", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "agent", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "approach to learning from situated, interactive tutorial instruction", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "contextually guided responses to incomplete explanations", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "flexible paradigm for teaching tasks", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "form of explanation-based learning", "value": 0.75}, {"from": "Instructo-Soar", "title": ",contextual proximity", "to": "instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions)", "value": 1.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "interactive tutorial instruction", "value": 0.75}, {"from": "Instructo-Soar", "title": "can take at any instruction point,contextual proximity", "to": "known or unknown commands", "value": 1.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "learning each class of knowledge it uses to perform tasks", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "learning from situated, interactive tutorial instruction", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "learning hierarchies of new tasks and other domain knowledge from interactive natural language instructions", "value": 0.75}, {"from": "Instructo-Soar", "title": "contextual proximity", "to": "situated explanation", "value": 1.5}, {"from": "Interactive tutorial instruction", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "Interactive tutorial instruction", "title": "", "to": "learning each class of knowledge it uses to perform tasks", "value": 1.0}, {"from": "Intermediate representations", "title": "A program written in this paradigm computes a multi-layer of intermediate representations called spatial aggregates.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "Japanese information extraction system", "title": "contextual proximity", "to": "pattern matcher and discourse processor", "value": 0.5}, {"from": "KAM", "title": "contextual proximity", "to": "Spatial aggregation", "value": 2.0}, {"from": "LCFR", "title": "contextual proximity", "to": "Least-Cost Flaw Repair (LCFR)", "value": 0.5}, {"from": "LCFR", "title": "contextual proximity", "to": "ZLIFO Strategy", "value": 0.5}, {"from": "LIFO prioritization", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "LIFO prioritization", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "LIFO prioritization", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "LIFO prioritization", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "Lambda", "title": "contextual proximity", "to": "Reinforcement learning algorithms", "value": 0.5}, {"from": "Lambda", "title": "contextual proximity", "to": "TD methods", "value": 0.5}, {"from": "Lambda", "title": "contextual proximity", "to": "TTD", "value": 0.5}, {"from": "Lambda \u0026gt 0", "title": "contextual proximity", "to": "Reinforcement learning algorithms", "value": 0.5}, {"from": "Lambda \u0026gt 0", "title": "contextual proximity", "to": "TD methods", "value": 0.5}, {"from": "Lambda \u0026gt 0", "title": "contextual proximity", "to": "TTD", "value": 0.5}, {"from": "Large probabilistic databases", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "Large probabilistic databases", "title": "The usefulness of sub-linear processing time manifests itself in applications requiring (near) real-time response over large probabilistic databases.", "to": "Real-time response", "value": 1.0}, {"from": "Least-Cost Flaw Repair (LCFR)", "title": "contextual proximity", "to": "ZLIFO Strategy", "value": 0.5}, {"from": "Lexically ambiguous sentences", "title": "contextual proximity", "to": "MUSE CSP", "value": 2.0}, {"from": "Linear time", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Linear time", "title": "Our proposed algorithm guarantees that a global minimum is found in linear time for tree-like subnetworks.", "to": "Tree-like subnetworks", "value": 1.0}, {"from": "Lisp code", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "Lisp code", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "Lisp code", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "Lisp code", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "Lisp code", "title": "The author provides the Lisp code for their techniques and for the test problems in on-line appendices.", "to": "techniques and test problems", "value": 1.0}, {"from": "Local minima", "title": "contextual proximity", "to": "Local search algorithms", "value": 1.0}, {"from": "Local minima", "title": "contextual proximity", "to": "Plateau moves", "value": 0.5}, {"from": "Local minima", "title": "contextual proximity", "to": "Plateaus with exits (benches)", "value": 1.0}, {"from": "Local minima", "title": "contextual proximity", "to": "Small size", "value": 0.5}, {"from": "Local search algorithms", "title": "contextual proximity", "to": "Plateau moves", "value": 0.5}, {"from": "Local search algorithms", "title": "contextual proximity", "to": "Plateaus with exits (benches)", "value": 1.0}, {"from": "Local search algorithms", "title": "contextual proximity", "to": "Small size", "value": 0.5}, {"from": "Log N time", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "Low-level information utilized by segmentation algorithms", "title": "Such problems often have difficulty segmenting data in only one way given the low-level information.,contextual proximity", "to": "MUSE CSP", "value": 3.0}, {"from": "Lower Horn formula", "title": "contextual proximity", "to": "Minimum-change update", "value": 0.5}, {"from": "Lower Horn formula", "title": "Represents the relationship between an upper and lower Horn formula, which together constitute a Horn approximation. This can be seen as an illustration of how these formulas work in tandem to provide an efficient representation of the underlying set of formulas.", "to": "Upper Horn formula", "value": 1.0}, {"from": "MAPS", "title": "contextual proximity", "to": "Spatial aggregation", "value": 2.0}, {"from": "MUSE CSP", "title": "Algorithms provided for MUSE arc and path consistency.,contextual proximity", "to": "MUSE arc consistency", "value": 3.0}, {"from": "MUSE CSP", "title": "Introduced concepts for MUSE node consistency, MUSE arc consistency, and MUSE path consistency.,contextual proximity", "to": "MUSE node consistency", "value": 3.0}, {"from": "MUSE CSP", "title": "Discussed how to create a MUSE CSP from a set of CSPs labeled to indicate when the same variable is shared by more than a single CSP.,contextual proximity", "to": "Set of CSPs", "value": 3.0}, {"from": "MUSE CSP", "title": "contextual proximity", "to": "Signal processing applications including computer vision, speech processing, and handwriting recognition", "value": 2.0}, {"from": "Macro-operator learning", "title": "contextual proximity", "to": "Speedup learning", "value": 0.5}, {"from": "Macro-operator learning", "title": "contextual proximity", "to": "Speedup learning framework", "value": 1.25}, {"from": "Market price systems", "title": "contextual proximity", "to": "Mechanisms for decentralized decision making", "value": 2.25}, {"from": "Market price systems", "title": "contextual proximity", "to": "Multicommodity flow problem", "value": 2.25}, {"from": "Market price systems", "title": "contextual proximity", "to": "Price equilibria", "value": 2.25}, {"from": "Markov decision theory", "title": "the central issues of reinforcement learning, including establishing the foundations of the field via Markov decision theory, are discussed in this paper.", "to": "establishing the foundations of the field", "value": 1.0}, {"from": "Minimum-change update", "title": "contextual proximity", "to": "Model-based updates", "value": 0.5}, {"from": "Minimum-change update", "title": "contextual proximity", "to": "Set of formulas represented by Horn approximation", "value": 0.5}, {"from": "Minimum-change update", "title": "contextual proximity", "to": "Theory update and revision schemes", "value": 0.5}, {"from": "Minimum-change update", "title": "contextual proximity", "to": "Upper Horn formula", "value": 0.5}, {"from": "More complex decision trees", "title": "contextual proximity", "to": "Occam\u0027s razor", "value": 0.5}, {"from": "More complex decision trees", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 0.5}, {"from": "Multi-step prediction problems", "title": "contextual proximity", "to": "Reinforcement learning algorithms", "value": 0.5}, {"from": "Multi-step prediction problems", "title": "contextual proximity", "to": "TD methods", "value": 0.5}, {"from": "Multi-step prediction problems", "title": "contextual proximity", "to": "TTD", "value": 0.5}, {"from": "Multi-step prediction problems", "title": "TD methods are used to learn predictions in multi-step prediction problems.", "to": "Temporal difference methods", "value": 1.0}, {"from": "N individuals", "title": "instantiation relationship, as all possible worlds are considered for computing the degree of belief given KB and N", "to": "all possible worlds with domain {1,...,N}", "value": 1.0}, {"from": "NP-hard", "title": "Unfortunately, it is NP-hard.,contextual proximity", "to": "knowledge base", "value": 2.0}, {"from": "NP-hard", "title": "contextual proximity", "to": "stable models", "value": 0.5}, {"from": "Neighborhood graph", "title": "A program written in this paradigm uses a data structure called the neighborhood graph as a common interface to modularize computations.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "New evidence absorption", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "New evidence absorption", "title": "In the conventional algorithm, new evidence is absorbed in O(1) time.", "to": "O(1) time", "value": 1.0}, {"from": "New version of C4.5", "title": "", "to": "Results also confirm that a new version of C4.5 incorporating these changes is superior to recent approaches that use global discretization and that construct small trees with multi-interval splits.", "value": 1.0}, {"from": "O(1) time", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "O(N)", "title": "contextual proximity", "to": "Queries", "value": 0.5}, {"from": "OC1", "title": "contextual proximity", "to": "domains in which the attributes are numeric", "value": 0.5}, {"from": "OC1", "title": "contextual proximity", "to": "oblique decision tree methods", "value": 0.5}, {"from": "OC1", "title": "contextual proximity", "to": "oblique split (in the form of a hyperplane)", "value": 0.5}, {"from": "OC1", "title": "contextual proximity", "to": "smaller and more accurate than their axis-parallel counterparts", "value": 0.5}, {"from": "OPUS", "title": "contextual proximity", "to": "admissible search", "value": 1.25}, {"from": "OPUS", "title": "contextual proximity", "to": "complex learning tasks", "value": 1.25}, {"from": "OPUS", "title": "contextual proximity", "to": "exact learning biases", "value": 1.25}, {"from": "OPUS", "title": "contextual proximity", "to": "machine learning community", "value": 1.25}, {"from": "OPUS", "title": "contextual proximity", "to": "truth maintenance", "value": 1.25}, {"from": "Occam\u0027s razor", "title": "contextual proximity", "to": "Post-processing decision trees", "value": 0.5}, {"from": "Occam\u0027s razor", "title": "contextual proximity", "to": "Same class", "value": 0.5}, {"from": "Occam\u0027s razor", "title": "contextual proximity", "to": "Similar objects", "value": 0.5}, {"from": "Occam\u0027s razor", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 1.0}, {"from": "Off-line plan-design process", "title": "contextual proximity", "to": "Plan-design process", "value": 0.5}, {"from": "Off-line plan-design process", "title": "Emphasizing the importance and efficiency of off-line plan-design processes, especially during verification or projection in most natural cases.", "to": "Role", "value": 1.0}, {"from": "Omegak", "title": "contextual proximity", "to": "knowledge base", "value": 1.0}, {"from": "Omegak", "title": "If a knowledge base Pi is in Omega_k, then Pi has at most k stable models, and all of them may be found in time O(lnk).,contextual proximity", "to": "stable models", "value": 1.5}, {"from": "Optional objective functions", "title": "A program written in this paradigm may take optional objective functions as input.,contextual proximity", "to": "Spatial aggregation", "value": 3.0}, {"from": "Othello", "title": "contextual proximity", "to": "game-tree search", "value": 1.0}, {"from": "Othello", "title": "contextual proximity", "to": "logistic regression", "value": 0.5}, {"from": "POMDPs", "title": "contextual proximity", "to": "approximation scheme", "value": 0.75}, {"from": "POMDPs", "title": "contextual proximity", "to": "nondeterministic effects of actions, incomplete observability of state", "value": 0.75}, {"from": "POMDPs", "title": "contextual proximity", "to": "oracle", "value": 0.75}, {"from": "POMDPs", "title": "contextual proximity", "to": "region observable POMDP", "value": 1.5}, {"from": "PTR", "title": "contextual proximity", "to": "Probabilities", "value": 0.5}, {"from": "PTR", "title": "PTR is an approach to theory revision for propositional domain theories.,contextual proximity", "to": "Propositional domain theories", "value": 1.5}, {"from": "PTR", "title": "contextual proximity", "to": "Ptr", "value": 1.0}, {"from": "PTR", "title": "contextual proximity", "to": "Theory revision problem", "value": 0.5}, {"from": "Paris", "title": "An empirical study in the domain of process planning in mechanical engineering shows significant advantages of reasoning from abstract cases using Paris over classical hierarchical planning.", "to": "classical hierarchical planning", "value": 1.0}, {"from": "Performance task", "title": "Several authors have abstracted these criteria and posited a generic performance task akin to pattern completion, where the error rate over completed patterns is used to `externally\u0027 judge clustering utility.", "to": "Pattern completion", "value": 1.0}, {"from": "Plan-design process", "title": "contextual proximity", "to": "Planning while Learning", "value": 0.5}, {"from": "Plan-design process", "title": "contextual proximity", "to": "Role", "value": 0.5}, {"from": "Plan-design process", "title": "contextual proximity", "to": "Tractability", "value": 0.5}, {"from": "Plateau moves", "title": "contextual proximity", "to": "Plateaus with exits (benches)", "value": 0.5}, {"from": "Plateaus with exits (benches)", "title": "contextual proximity", "to": "Small size", "value": 0.5}, {"from": "Post-processing decision trees", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 0.5}, {"from": "Probabilities", "title": "contextual proximity", "to": "Ptr", "value": 0.5}, {"from": "Problem solving with experience", "title": "Seeks to improve computational efficiency,contextual proximity", "to": "Speedup learning", "value": 1.5}, {"from": "Problem solving with experience", "title": "contextual proximity", "to": "Speedup learning framework", "value": 1.25}, {"from": "Prolog selection rule", "title": "The methodology for proving termination of general logic programs is introduced in relation to the Prolog selection rule.,contextual proximity", "to": "termination of general logic programs", "value": 1.75}, {"from": "Propositional domain theories", "title": "contextual proximity", "to": "Ptr", "value": 0.5}, {"from": "Ptr", "title": "contextual proximity", "to": "Theory revision problem", "value": 0.5}, {"from": "Q-DAG evaluation algorithm", "title": "contextual proximity", "to": "Q-DAGs", "value": 0.75}, {"from": "Q-DAG evaluation algorithm", "title": "contextual proximity", "to": "belief networks", "value": 0.75}, {"from": "Q-DAG evaluation algorithm", "title": "time and space complexity is linear in the size of the Q-DAG, standard evaluation of arithmetic expression,contextual proximity", "to": "standard algorithms for exact inference", "value": 1.5}, {"from": "Q-DAG generation algorithm", "title": "contextual proximity", "to": "Q-DAGs", "value": 0.75}, {"from": "Q-DAG generation algorithm", "title": "contextual proximity", "to": "belief networks", "value": 0.75}, {"from": "Q-DAG generation algorithm", "title": "can be generated using clustering and conditioning algorithms, time complexity is no worse than the time complexity of the inference algorithm,contextual proximity", "to": "standard algorithms for exact inference", "value": 1.5}, {"from": "Q-DAGs", "title": "new paradigm for implementing inference, consists of two steps: compilation and evaluation,contextual proximity", "to": "belief networks", "value": 3.25}, {"from": "Q-DAGs", "title": "contextual proximity", "to": "evidence symbols", "value": 0.75}, {"from": "Q-DAGs", "title": "contextual proximity", "to": "network queries", "value": 0.75}, {"from": "Q-DAGs", "title": "contextual proximity", "to": "numeric operations", "value": 0.75}, {"from": "Q-DAGs", "title": "contextual proximity", "to": "on-line, real-world applications", "value": 0.75}, {"from": "Q-DAGs", "title": "contextual proximity", "to": "standard algorithms for exact inference", "value": 1.5}, {"from": "Quality of clustering", "title": "Ideally, the search strategy should consistently construct clusterings of high quality, but be computationally inexpensive as well. In general, we cannot have it both ways, but we can partition the search so that a system inexpensively constructs a `tentative\u0027 clustering for initial examination, followed by iterative optimization, which continues to search in background for improved clusterings.", "to": "Evaluation objective function", "value": 1.0}, {"from": "Queries", "title": "contextual proximity", "to": "Real-time response", "value": 0.5}, {"from": "Queries", "title": "contextual proximity", "to": "Singly connected Bayesian networks", "value": 0.5}, {"from": "Queries", "title": "contextual proximity", "to": "Traditional databases", "value": 0.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "approximately four billion", "value": 0.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "four in total", "value": 0.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "maximal tractable subalgebras", "value": 0.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "polynomial or NP-complete", "value": 0.5}, {"from": "RCC-5", "title": "The satisfiability problem for RCC-5 is a computational property that has been shown to be NP-complete.,contextual proximity", "to": "satisfiability problem", "value": 1.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "satisfiability problem for all subclasses", "value": 0.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "spatial algebra", "value": 0.5}, {"from": "RCC-5", "title": "contextual proximity", "to": "subclasses of RCC-5", "value": 0.5}, {"from": "Random problems and their solutions", "title": "Applies to two different representations of learned knowledge: control rules and macro-operators, and proves theorems that identify sufficient conditions for learning in each representation,contextual proximity", "to": "Speedup learning", "value": 1.5}, {"from": "Random problems and their solutions", "title": "contextual proximity", "to": "Speedup learning framework", "value": 1.25}, {"from": "Reinforcement learning algorithms", "title": "Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learning.,contextual proximity", "to": "TD methods", "value": 2.0}, {"from": "Reinforcement learning algorithms", "title": "contextual proximity", "to": "TD(lambda)", "value": 0.5}, {"from": "Reinforcement learning algorithms", "title": "contextual proximity", "to": "TTD", "value": 1.0}, {"from": "Reinforcement learning algorithms", "title": "contextual proximity", "to": "Temporal difference methods", "value": 0.5}, {"from": "Reinforcement learning algorithms", "title": "contextual proximity", "to": "Truncated Temporal Differences (TTD)", "value": 0.5}, {"from": "Resampling-based pruning strategies", "title": "Given this performance task, we adapt resampling-based pruning strategies used by supervised learning systems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis.", "to": "Simplifying hierarchical clusterings", "value": 1.0}, {"from": "SEQUITUR", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "SEQUITUR", "title": "SEQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively.", "to": "algorithm", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "STEAM\u0027s central hypothesis", "value": 2.0}, {"from": "STEAM", "title": "Finally, decision-theoretic communication selectivity in STEAM ensures reduction in communication overheads of teamwork, with appropriate sensitivity to the environmental conditions.,contextual proximity", "to": "communication", "value": 2.0}, {"from": "STEAM", "title": "contextual proximity", "to": "complex, dynamic multi-agent domains", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "differing, incomplete, and possibly inconsistent views of their environment", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "failed to fulfill responsibilities or discovered unexpected opportunities", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "flexibility", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "individual members\u0027", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "joint intentions", "value": 3.0}, {"from": "STEAM", "title": "contextual proximity", "to": "partial SharedPlans", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "reorganizing the team", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "reusability", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "team members", "value": 3.0}, {"from": "STEAM", "title": "contextual proximity", "to": "team members\u0027", "value": 1.0}, {"from": "STEAM", "title": "contextual proximity", "to": "teamwork", "value": 1.0}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "communication", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "complex, dynamic multi-agent domains", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "differing, incomplete, and possibly inconsistent views of their environment", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "failed to fulfill responsibilities or discovered unexpected opportunities", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "Our central hypothesis is that the key to such flexibility and reusability is providing agents with general models of teamwork.,contextual proximity", "to": "flexibility", "value": 1.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "individual members\u0027", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "joint intentions", "value": 1.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "partial SharedPlans", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "reorganizing the team", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "Our central hypothesis is that the key to such flexibility and reusability is providing agents with general models of teamwork.,contextual proximity", "to": "reusability", "value": 1.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "team members", "value": 1.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "team members\u0027", "value": 0.5}, {"from": "STEAM\u0027s central hypothesis", "title": "contextual proximity", "to": "teamwork", "value": 0.5}, {"from": "Same class", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 0.5}, {"from": "Same class", "title": "This procedure was derived by rejecting Occam\u0027s razor and instead attending to the assumption that similar objects are likely to belong to the same class.", "to": "Similar objects", "value": 1.0}, {"from": "Scientific reasoning", "title": "contextual proximity", "to": "Spatial aggregation", "value": 2.0}, {"from": "Scientific reasoning", "title": "The given context highlights the importance of visual thinking in scientific reasoning.", "to": "Visual thinking", "value": 1.0}, {"from": "Similar objects", "title": "contextual proximity", "to": "Utility of Occam\u0027s razor", "value": 0.5}, {"from": "Situated explanation-based learning", "title": "that is situated for each instruction", "to": "form of explanation-based learning", "value": 1.0}, {"from": "Situated explanation-based learning", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "Smaller decision trees", "title": "", "to": "Empirical trials show that the modifications lead to smaller decision trees", "value": 1.0}, {"from": "Spatial aggregation", "title": "contextual proximity", "to": "Unified description of imagistic problem solvers", "value": 2.0}, {"from": "Spatial aggregation", "title": "contextual proximity", "to": "Visual thinking", "value": 2.0}, {"from": "Speedup learning", "title": "contextual proximity", "to": "Speedup learning framework", "value": 2.5}, {"from": "Speedup learning", "title": "contextual proximity", "to": "Symbolic integration", "value": 0.5}, {"from": "Speedup learning framework", "title": "Illustrates framework with implementation in two domains: symbolic integration and Eight Puzzle,contextual proximity", "to": "Symbolic integration", "value": 2.25}, {"from": "Symmetric networks", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "T-R programs", "title": "contextual proximity", "to": "autonomous agents", "value": 1.5}, {"from": "T-R programs", "title": "contextual proximity", "to": "compact circuitry", "value": 0.75}, {"from": "T-R programs", "title": "contextual proximity", "to": "continuous computation", "value": 0.75}, {"from": "T-R programs", "title": "contextual proximity", "to": "dynamic environments", "value": 1.5}, {"from": "T-R programs", "title": "contextual proximity", "to": "formalism", "value": 1.5}, {"from": "T-R programs", "title": "contextual proximity", "to": "intuitive and easy to write", "value": 0.75}, {"from": "T-R programs", "title": "contextual proximity", "to": "run time construction", "value": 0.75}, {"from": "T-R programs", "title": "contextual proximity", "to": "teleo-reactive (T-R) programs", "value": 0.75}, {"from": "T-complete expansions", "title": "contextual proximity", "to": "T-implication", "value": 0.5}, {"from": "T-complete expansions", "title": "contextual proximity", "to": "inductive learning", "value": 0.75}, {"from": "T-complete expansions", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "T-complete expansions", "title": "For every non-tautological clause there exists a T-complete expansion, which means that every generalization under T-implication of the clause is reduced to a generalization under theta-subsumption of the expansion", "to": "non-tautological clauses", "value": 1.0}, {"from": "T-implication", "title": "contextual proximity", "to": "clausal representation of knowledge", "value": 0.5}, {"from": "T-implication", "title": "For every finite set of clauses there exists a least general generalization under T-implication,contextual proximity", "to": "clauses", "value": 1.5}, {"from": "T-implication", "title": "contextual proximity", "to": "expansions", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "generalization", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "implication", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "induction", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "inductive learning", "value": 1.5}, {"from": "T-implication", "title": "contextual proximity", "to": "inductive learning systems", "value": 1.0}, {"from": "T-implication", "title": "contextual proximity", "to": "learning recursive clauses", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "logical implication", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "machine learning", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "non-tautological clauses", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "recursive clauses", "value": 0.5}, {"from": "T-implication", "title": "contextual proximity", "to": "theta-subsumption", "value": 0.5}, {"from": "TD methods", "title": "contextual proximity", "to": "TD(lambda)", "value": 0.5}, {"from": "TD methods", "title": "contextual proximity", "to": "TTD", "value": 1.0}, {"from": "TD methods", "title": "contextual proximity", "to": "Temporal difference methods", "value": 0.5}, {"from": "TD methods", "title": "contextual proximity", "to": "Truncated Temporal Differences (TTD)", "value": 0.5}, {"from": "TD(lambda)", "title": "contextual proximity", "to": "TTD", "value": 0.5}, {"from": "TD(lambda)", "title": "The TTD procedure is proposed as an alternative to the traditional approach, based on eligibility traces, that suffers from both inefficiency and lack of generality.", "to": "Truncated Temporal Differences (TTD)", "value": 1.0}, {"from": "TKRS", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "TKRS", "title": "A TKRS is a tool used for designing and using knowledge bases.", "to": "knowledge base", "value": 1.0}, {"from": "TTD", "title": "contextual proximity", "to": "Temporal difference methods", "value": 0.5}, {"from": "TTD", "title": "contextual proximity", "to": "Truncated Temporal Differences (TTD)", "value": 0.5}, {"from": "Tests on continuous attributes", "title": "", "to": "The modifications apply an MDL-inspired penalty to such tests, eliminating some of them from consideration and altering the relative desirability of all tests.", "value": 1.0}, {"from": "Toast system", "title": "contextual proximity", "to": "agent/environment interactions", "value": 1.0}, {"from": "Toast system", "title": "contextual proximity", "to": "computational simplification of activity", "value": 0.5}, {"from": "Toast system", "title": "contextual proximity", "to": "control structures", "value": 0.5}, {"from": "Toast system", "title": "contextual proximity", "to": "conventions and invariants", "value": 1.0}, {"from": "Toast system", "title": "contextual proximity", "to": "lifeworld", "value": 1.5}, {"from": "Toast system", "title": "contextual proximity", "to": "lifeworlds", "value": 0.5}, {"from": "Tree-like subnetworks", "title": "contextual proximity", "to": "Uniform algorithm", "value": 0.75}, {"from": "Unrestricted text", "title": "associated with", "to": "vast amounts of", "value": 1.0}, {"from": "VE algorithm", "title": "extends VE algorithm to exploit causal independence,contextual proximity", "to": "causal independence", "value": 2.0}, {"from": "VE algorithm", "title": "contextual proximity", "to": "conditional probability", "value": 0.5}, {"from": "VE algorithm", "title": "contextual proximity", "to": "joint probability", "value": 0.5}, {"from": "VE algorithm", "title": "contextual proximity", "to": "variable", "value": 0.5}, {"from": "accuracy of individual trees", "title": "contextual proximity", "to": "consistent decision trees", "value": 0.5}, {"from": "accuracy of individual trees", "title": "for many of the problems investigated, smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees.,contextual proximity", "to": "smaller consistent decision trees", "value": 1.5}, {"from": "accuracy of individual trees", "title": "contextual proximity", "to": "test data", "value": 0.5}, {"from": "accuracy of individual trees", "title": "contextual proximity", "to": "training data", "value": 0.5}, {"from": "acquires knowledge for some of the higher level IE processing", "title": "used to acquire knowledge", "to": "machine learning", "value": 1.0}, {"from": "actions", "title": "first principles about geometric bodies and actions are used to automatically synthesize plan fragments.", "to": "set of operations or transformations that can be performed on geometric bodies", "value": 1.0}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "basic adaptive behavior parameters", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "central coordination", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "communication", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "distributed system", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "exploration vs. exploitation", "value": 0.5}, {"from": "adaptive load balancing", "title": "We then investigate the properties of adaptive load balancing in heterogeneous populations,,contextual proximity", "to": "heterogeneous populations", "value": 2.0}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "individual agents", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "load balancing", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "multi-agent reinforcement learning", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "naive use of communication", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "purely local information", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "stochastic nature", "value": 0.5}, {"from": "adaptive load balancing", "title": "contextual proximity", "to": "system efficiency", "value": 0.5}, {"from": "adaptive menus", "title": "contextual proximity", "to": "electronic organizer", "value": 1.25}, {"from": "adaptive problem-solving solving", "title": "In adaptive problem-solving solving, domain specific knowledge is acquired automatically for a general problem solver with a flexible control architecture.", "to": "domain specific knowledge", "value": 1.0}, {"from": "agent", "title": "In a model of an agent-environment interaction, the agent is not Bayesian and does not form a prior probability on his reward function.", "to": "Bayesian", "value": 1.0}, {"from": "agent", "title": "The text refers to the note taking agent as a learning-apprentice software-agent, suggesting that there is a connection between the two terms.", "to": "learning-apprentice software-agent", "value": 1.0}, {"from": "agent", "title": "contextual proximity", "to": "performance system", "value": 0.5}, {"from": "agent", "title": "Agent\u0027s program is a solution to the constrained optimization problem presented by its architecture and task environment", "to": "program", "value": 1.0}, {"from": "agent", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "agent", "title": "contextual proximity", "to": "user interface", "value": 0.75}, {"from": "agent", "title": "within an ongoing", "to": "learning from situated, interactive tutorial instruction", "value": 1.0}, {"from": "agent/environment interactions", "title": "contextual proximity", "to": "computational simplification of activity", "value": 0.5}, {"from": "agent/environment interactions", "title": "contextual proximity", "to": "control structures", "value": 0.5}, {"from": "agent/environment interactions", "title": "contextual proximity", "to": "conventions and invariants", "value": 1.0}, {"from": "agent/environment interactions", "title": "The analysis of agent/environment interactions should be extended to include the conventions and invariants maintained by agents throughout their activity. This thicker notion of environment is referred to as a lifeworld.,contextual proximity", "to": "lifeworld", "value": 2.5}, {"from": "agent/environment interactions", "title": "contextual proximity", "to": "lifeworlds", "value": 0.5}, {"from": "algorithm", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "algorithm that is incomplete with respect to", "title": "contextual proximity", "to": "description graphs", "value": 0.5}, {"from": "algorithm that is incomplete with respect to", "title": "The developers had to use an algorithm that is incomplete with respect to the standard, model-theoretic semantics for description logics.,contextual proximity", "to": "standard, model-theoretic semantics for description logics", "value": 1.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "applications", "value": 0.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "part of,contextual proximity", "to": "backtracking algorithm", "value": 2.0}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "backtracking search problem", "value": 0.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "empirical analysis", "value": 0.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "highly optimized implementation", "value": 0.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "part of,contextual proximity", "to": "path consistency algorithm", "value": 2.0}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "previously suggested reformulation", "value": 0.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "problems in molecular biology", "value": 0.5}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "temporal reasoning component", "value": 1.0}, {"from": "algorithms for determining whether the temporal information is consistent", "title": "contextual proximity", "to": "temporal reasoning system", "value": 0.5}, {"from": "applications", "title": "contextual proximity", "to": "backtracking algorithm", "value": 0.5}, {"from": "applications", "title": "contextual proximity", "to": "path consistency algorithm", "value": 0.5}, {"from": "applications", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "approach to learning from situated, interactive tutorial instruction", "title": "achieves such learning through a combination of analytic and inductive techniques.,contextual proximity", "to": "situated explanation", "value": 1.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "background knowledge", "value": 1.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "data", "value": 0.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "database", "value": 0.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "discovering knowledge in structural data", "value": 1.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "graph", "value": 0.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "graph match", "value": 0.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 1.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "hierarchical description", "value": 1.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "inexact graph match", "value": 0.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "representing structural concepts", "value": 1.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 1.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "substructure discovery", "value": 3.0}, {"from": "approximate measure of closeness", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "approximately four billion", "title": "RCC-5 has approximately four billion subclasses, but not much is known about their computational properties.", "to": "subclasses of RCC-5", "value": 1.0}, {"from": "approximation scheme", "title": "contextual proximity", "to": "region observable POMDP", "value": 0.5}, {"from": "artificial intelligence", "title": "Theoretical foundation of artificial intelligence centered around perfect rationality", "to": "perfect rationality", "value": 1.0}, {"from": "as hard as learning boolean DNF", "title": "contextual proximity", "to": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "value": 0.75}, {"from": "as hard as learning boolean DNF", "title": "Learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause is as hard as learning boolean DNF.", "to": "learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause", "value": 1.0}, {"from": "automatically construct classification models", "title": "makes it easier to comparatively analyze the utility of alternative feature representations of the data,contextual proximity", "to": "discourse sense", "value": 1.75}, {"from": "automatically construct classification models", "title": "contextual proximity", "to": "sentential sense", "value": 0.5}, {"from": "automatically synthesized domain independent planners", "title": "in this paper, we investigate the feasibility of using existing automated software synthesis tools to support such synthesis. Specifically, we describe an architecture called CLAY in which the Kestrel Interactive Development System (KIDS) is used to derive a domain-customized planner through a semi-automatic combination of a declarative theory of planning, and the declarative control knowledge specific to a given domain, to semi-automatically combine them to derive domain-customized planners. Our experiments show that the synthesized planners can outperform classical refinement planners (implemented as instantiations of UCP, Kambhampati \u0026 Srivastava, 1995), using the same control knowledge.,contextual proximity", "to": "domain dependent approaches", "value": 1.5}, {"from": "automatically synthesized domain independent planners", "title": "Existing plan synthesis approaches in artificial intelligence fall into two categories -- domain independent and domain dependent. The domain independent approaches are applicable across a variety of domains, but may not be very efficient in any one given domain.,contextual proximity", "to": "domain independent approaches", "value": 1.5}, {"from": "autonomous agents", "title": "contextual proximity", "to": "compact circuitry", "value": 0.5}, {"from": "autonomous agents", "title": "contextual proximity", "to": "continuous computation", "value": 0.5}, {"from": "autonomous agents", "title": "A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments.,contextual proximity", "to": "dynamic environments", "value": 2.0}, {"from": "autonomous agents", "title": "contextual proximity", "to": "formalism", "value": 1.0}, {"from": "autonomous agents", "title": "contextual proximity", "to": "intuitive and easy to write", "value": 0.5}, {"from": "autonomous agents", "title": "contextual proximity", "to": "run time construction", "value": 0.5}, {"from": "autonomous agents", "title": "contextual proximity", "to": "teleo-reactive (T-R) programs", "value": 0.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "data", "value": 0.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "database", "value": 0.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "discovering knowledge in structural data", "value": 1.0}, {"from": "background knowledge", "title": "contextual proximity", "to": "graph", "value": 0.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "graph match", "value": 0.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 1.0}, {"from": "background knowledge", "title": "contextual proximity", "to": "hierarchical description", "value": 1.0}, {"from": "background knowledge", "title": "contextual proximity", "to": "inexact graph match", "value": 0.5}, {"from": "background knowledge", "title": "need not exist under relative implication, not even if both the set that is to be generalized and the background knowledge are function-free,contextual proximity", "to": "least generalization", "value": 1.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "background knowledge", "title": "contextual proximity", "to": "representing structural concepts", "value": 1.0}, {"from": "background knowledge", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 1.0}, {"from": "background knowledge", "title": "contextual proximity", "to": "substructure discovery", "value": 3.0}, {"from": "background knowledge", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "backtrack points", "title": "In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.", "to": "deeper in the search space", "value": 1.0}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "backtracking search problem", "value": 0.5}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "empirical analysis", "value": 0.5}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "highly optimized implementation", "value": 0.5}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "path consistency algorithm", "value": 1.0}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "previously suggested reformulation", "value": 0.5}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "problems in molecular biology", "value": 0.5}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "temporal reasoning component", "value": 1.0}, {"from": "backtracking algorithm", "title": "contextual proximity", "to": "temporal reasoning system", "value": 0.5}, {"from": "backtracking search problem", "title": "contextual proximity", "to": "path consistency algorithm", "value": 0.5}, {"from": "backtracking search problem", "title": "can reduce the time and space requirements of the backtracking search", "to": "previously suggested reformulation", "value": 1.0}, {"from": "backtracking search problem", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "base program", "title": "The paper proposes a scheme of generating a candidate base program that covers positive examples, which can then be made consistent by inserting cut where appropriate.,contextual proximity", "to": "learning programs", "value": 1.5}, {"from": "basic adaptive behavior parameters", "title": "contextual proximity", "to": "heterogeneous populations", "value": 0.5}, {"from": "basic adaptive behavior parameters", "title": "We first define a precise framework in which to study adaptive load balancing, important features of which are its stochastic nature and the purely local information available to individual agents. Given this framework, we show illuminating results on the interplay between basic adaptive behavior parameters and their effect on system efficiency.", "to": "system efficiency", "value": 1.0}, {"from": "belief networks", "title": "contextual proximity", "to": "evidence symbols", "value": 0.75}, {"from": "belief networks", "title": "contextual proximity", "to": "network queries", "value": 0.75}, {"from": "belief networks", "title": "contextual proximity", "to": "numeric operations", "value": 0.75}, {"from": "belief networks", "title": "contextual proximity", "to": "on-line, real-world applications", "value": 0.75}, {"from": "belief networks", "title": "contextual proximity", "to": "standard algorithms for exact inference", "value": 1.5}, {"from": "better symbolic models", "title": "We conclude that the SPA generalizes the past tense of unseen verbs better than ANN models by a wide margin,", "to": "ANN models", "value": 1.0}, {"from": "bidirectional heuristic search", "title": "contextual proximity", "to": "misconception", "value": 1.0}, {"from": "bidirectional heuristic search", "title": "contextual proximity", "to": "misunderstanding about the reasons behind it", "value": 1.0}, {"from": "bidirectional heuristic search", "title": "contextual proximity", "to": "new generic approach", "value": 1.0}, {"from": "bidirectional heuristic search", "title": "contextual proximity", "to": "search frontiers passing each other", "value": 1.0}, {"from": "bidirectional heuristic search", "title": "contextual proximity", "to": "traditional approaches", "value": 1.0}, {"from": "bidirectional heuristic search", "title": "contextual proximity", "to": "viability of bidirectional heuristic search", "value": 1.0}, {"from": "binary concept learning algorithms", "title": "contextual proximity", "to": "distributed output representation", "value": 0.5}, {"from": "binary concept learning algorithms", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "binary concept learning algorithms", "title": "contextual proximity", "to": "multiclass learning problems", "value": 1.0}, {"from": "bounded optimality", "title": "Bounded optimality proposed instead of perfect rationality as an alternative theoretical foundation for AI", "to": "property proposed instead of perfect rationality", "value": 1.0}, {"from": "branching rate", "title": "when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate.", "to": "mean branching rate", "value": 1.0}, {"from": "calculus", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "calculus", "title": "Our calculus extends the general technique of constraint systems for reasoning in ALCNR-knowledge bases.", "to": "constraint systems", "value": 1.0}, {"from": "candidate base program", "title": "The paper investigates the difficulties caused by intensional evaluation in making a candidate base program consistent by inserting cut where appropriate.", "to": "consistency", "value": 1.0}, {"from": "candidate base program", "title": "contextual proximity", "to": "learning programs", "value": 0.5}, {"from": "canonical form", "title": "contextual proximity", "to": "causal assertions", "value": 0.5}, {"from": "canonical form", "title": "contextual proximity", "to": "causal relationships", "value": 0.5}, {"from": "canonical form", "title": "Finally, we show how canonical form facilitates counterfactual reasoning.,contextual proximity", "to": "counterfactual reasoning", "value": 1.5}, {"from": "canonical form", "title": "contextual proximity", "to": "decision-theoretic primitives", "value": 0.5}, {"from": "canonical form", "title": "contextual proximity", "to": "directed acyclic graphs", "value": 0.5}, {"from": "canonical form", "title": "contextual proximity", "to": "influence diagrams", "value": 0.5}, {"from": "case-based planning", "title": "contextual proximity", "to": "plan adaptation", "value": 1.0}, {"from": "case-based planning", "title": "Both transformational planning and case-based planning involve a process known as plan adaptation, which modifies or repairs an old plan to solve a new problem.", "to": "transformational planning", "value": 1.0}, {"from": "category measure", "title": "learning component for automatically learning membership functions given a set of example objects labeled with their desired category measure in the functionality-based recognition system Gruff, called Omlet", "to": "membership function", "value": 1.0}, {"from": "causal assertions", "title": "Our definition of cause and effect departs from the traditional view in that causal assertions may vary with the set of decisions available, providing added clarity to the notion of cause.", "to": "decision-theoretic primitives", "value": 1.0}, {"from": "causal independence", "title": "contextual proximity", "to": "conditional probability", "value": 0.5}, {"from": "causal independence", "title": "contextual proximity", "to": "joint probability", "value": 0.5}, {"from": "causal independence", "title": "contextual proximity", "to": "variable", "value": 0.5}, {"from": "causal relationships", "title": "We examine the encoding of causal relationships in directed acyclic graphs.", "to": "directed acyclic graphs", "value": 1.0}, {"from": "central coordination", "title": "contextual proximity", "to": "heterogeneous populations", "value": 0.5}, {"from": "central coordination", "title": "without use of either central coordination or explicit communication...", "to": "distributed system", "value": 1.0}, {"from": "changes in training sample size", "title": "contextual proximity", "to": "distributed output representation", "value": 0.5}, {"from": "changes in training sample size", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "changes in training sample size", "title": "This approach is robust with respect to changes in the size of the training sample,,contextual proximity", "to": "multiclass learning problems", "value": 2.0}, {"from": "class", "title": "This hierarchy consists of classes Omega_1,Omega_2,..., with the properties mentioned in the text.", "to": "hierarchy", "value": 1.0}, {"from": "class", "title": "contextual proximity", "to": "knowledge base", "value": 1.0}, {"from": "class", "title": "contextual proximity", "to": "stable models", "value": 0.5}, {"from": "class definition", "title": "allows for different semantics to coexist in knowledge representation formalism, muALCQ. Recursive definitions enable frame-based descriptions and definitions of recursive data structures such as directed acyclic graphs, lists, streams, etc.", "to": "recursive definitions", "value": 1.0}, {"from": "classical AI", "title": "contextual proximity", "to": "intelligence", "value": 0.5}, {"from": "classical AI", "title": "contextual proximity", "to": "learning", "value": 0.75}, {"from": "classical AI", "title": "contextual proximity", "to": "reasoning", "value": 0.75}, {"from": "classical AI planners", "title": "different types of planners", "to": "Cassandra", "value": 1.0}, {"from": "classical complexity theory", "title": "Generalizing the notion of optimality in classical complexity theory through asymptotic bounded optimality", "to": "asymptotic bounded optimality (ABO)", "value": 1.0}, {"from": "classification of handwritten digits", "title": "contextual proximity", "to": "mean field theory", "value": 0.75}, {"from": "classification of handwritten digits", "title": "We demonstrate the utility of our mean field theory framework for the classification of handwritten digits, a benchmark problem in statistical pattern recognition.,contextual proximity", "to": "sigmoid belief networks", "value": 1.5}, {"from": "clausal representation of knowledge", "title": "contextual proximity", "to": "inductive learning", "value": 0.75}, {"from": "clausal representation of knowledge", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "clausal representation of knowledge", "title": "There has been a rising interest in clausal representation of knowledge in machine learning", "to": "machine learning", "value": 1.0}, {"from": "clauses", "title": "contextual proximity", "to": "inductive learning", "value": 0.75}, {"from": "clauses", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "clauses containing cut", "title": "contextual proximity", "to": "learning programs", "value": 0.5}, {"from": "clauses containing cut", "title": "Clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems, due to their procedural meaning.", "to": "extensional evaluation method", "value": 1.0}, {"from": "coarse domain theory", "title": "contextual proximity", "to": "fine-tuned theory", "value": 0.5}, {"from": "coarse domain theory", "title": "contextual proximity", "to": "initial theory", "value": 0.5}, {"from": "collection of geometric bodies", "title": "the process of finding the configuration of a collection of geometric bodies to satisfy given constraints is an important problem in geometric reasoning.", "to": "configuration of a collection of geometric bodies", "value": 1.0}, {"from": "combinatorial search", "title": "introduce an algorithm for combinatorial search on quantum computers that is capable of significantly concentrating amplitude into solutions for some NP search problems, on average.", "to": "quantum computers", "value": 1.0}, {"from": "communication", "title": "contextual proximity", "to": "heterogeneous populations", "value": 0.5}, {"from": "communication", "title": "contextual proximity", "to": "joint intentions", "value": 0.75}, {"from": "communication", "title": "Finally, we show that naive use of communication may not improve, and might even harm system efficiency.", "to": "naive use of communication", "value": 1.0}, {"from": "communication", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "compact circuitry", "title": "contextual proximity", "to": "dynamic environments", "value": 0.5}, {"from": "compact circuitry", "title": "contextual proximity", "to": "formalism", "value": 0.5}, {"from": "compact, easily interpretable solutions", "title": "The new induction method aims to induce compact and easily interpretable solutions.", "to": "induction method", "value": 1.0}, {"from": "compact, easily interpretable solutions", "title": "contextual proximity", "to": "machine learning method", "value": 0.5}, {"from": "compact, easily interpretable solutions", "title": "contextual proximity", "to": "ordered disjunctive normal form (DNF)", "value": 0.5}, {"from": "competition between decrease in number of solutions and increased pruning", "title": "The easy-hard-easy pattern in the difficulty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in number of solutions and increased pruning.,contextual proximity", "to": "easy-hard-easy pattern", "value": 1.75}, {"from": "competition between decrease in number of solutions and increased pruning", "title": "contextual proximity", "to": "search cost", "value": 0.75}, {"from": "competitive ratio", "title": "In the study of feedback structures, the competitive ratio criterion refers to the long-run optimality criterion used in our analysis.", "to": "optimality criterion", "value": 1.0}, {"from": "completeness", "title": "The completeness of our algorithm ensures that the adaptation algorithm will eventually search the entire plan graph without redundantly searching any parts of it.,contextual proximity", "to": "plan adaptation", "value": 2.0}, {"from": "complex structural alterations that may be required", "title": "contextual proximity", "to": "fine-tuned theory", "value": 0.5}, {"from": "complex structural alterations that may be required", "title": "contextual proximity", "to": "initial theory", "value": 0.5}, {"from": "complex structural alterations that may be required", "title": "have limited value for accomplishing.", "to": "small, local changes to a theory", "value": 1.0}, {"from": "complex, dynamic multi-agent domains", "title": "contextual proximity", "to": "joint intentions", "value": 0.75}, {"from": "complex, dynamic multi-agent domains", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "computational mechanisms used to process negated atoms", "title": "Many computational mechanisms for processing negated atoms, such as Clark\u0027s negation as failure and Chan\u0027s constructive negation, are based on termination conditions.,contextual proximity", "to": "termination of general logic programs", "value": 1.75}, {"from": "computational simplification of activity", "title": "contextual proximity", "to": "conventions and invariants", "value": 0.5}, {"from": "computational simplification of activity", "title": "Lifeworlds computationally simplify activity by providing structures that are maintained throughout agent activity.,contextual proximity", "to": "lifeworld", "value": 1.75}, {"from": "computer", "title": "contextual proximity", "to": "performance system", "value": 0.5}, {"from": "computer", "title": "contextual proximity", "to": "user interface", "value": 0.75}, {"from": "computer", "title": "The text mentions that recording information on a computer is less efficient but more powerful than doing it on paper, indicating that note taking and computers are related concepts.", "to": "note taking", "value": 1.0}, {"from": "computer program", "title": "contextual proximity", "to": "critic", "value": 3.75}, {"from": "computer program", "title": "contextual proximity", "to": "difference matching", "value": 0.75}, {"from": "computer program", "title": "contextual proximity", "to": "differences", "value": 0.75}, {"from": "computer program", "title": "contextual proximity", "to": "diverging proof attempts", "value": 1.5}, {"from": "computer program", "title": "contextual proximity", "to": "generalizations", "value": 0.75}, {"from": "computer program", "title": "contextual proximity", "to": "lemmas", "value": 0.75}, {"from": "computer program", "title": "contextual proximity", "to": "proof attempt", "value": 2.25}, {"from": "computer science perspective", "title": "this paper surveys the field of reinforcement learning from a computer science perspective, which is written to be accessible to researchers familiar with machine learning.", "to": "machine learning", "value": 1.0}, {"from": "concept language", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "concept language", "title": "TKRSs make use of terminological languages, which are also called concept languages.", "to": "terminological language", "value": 1.0}, {"from": "concrete", "title": "In the proposed new abstraction methodology and learning algorithm, planning cases can be completely changed from concrete to abstract using a new approach that allows for a powerful change in representation language. However, an admissible way of abstracting states and the abstract language itself must be provided in the domain model.", "to": "abstract", "value": 1.0}, {"from": "conditional probability", "title": "can be specified in terms of an associative and commutative operator on the contribution of each parent (e.g., \u0027or\u0027, \u0027sum\u0027, or \u0027max\u0027)", "to": "variable", "value": 1.0}, {"from": "conjunctive queries", "title": "Our approach is also applicable to counting the number of records in a dataset that match conjunctive queries.", "to": "counting the number of records", "value": 1.0}, {"from": "conjunctive queries", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "conjunctive queries", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "connectionist networks", "title": "contextual proximity", "to": "hand-coded symbolic grammar or symbolic semantic component", "value": 0.5}, {"from": "connectionist networks", "title": "allows more robust processing of spontaneous spoken language than deeply structured representations.,contextual proximity", "to": "screening approach", "value": 1.75}, {"from": "connectionist networks", "title": "contextual proximity", "to": "spontaneously spoken language", "value": 0.5}, {"from": "consequences", "title": "Adding a formula to the premises can invalidate some consequences in nonmonotonic logic.,contextual proximity", "to": "formulae", "value": 1.5}, {"from": "consequences", "title": "contextual proximity", "to": "nonmonotonicity", "value": 0.5}, {"from": "consequences", "title": "contextual proximity", "to": "preferential logics", "value": 0.5}, {"from": "conservative", "title": "When a formula is a consequence, it cannot be invalidated when adding any formula to the premises in conservative logic.,contextual proximity", "to": "formulae", "value": 1.5}, {"from": "conservative", "title": "contextual proximity", "to": "nonmonotonicity", "value": 0.5}, {"from": "conservative", "title": "contextual proximity", "to": "preferential logics", "value": 0.5}, {"from": "consistency", "title": "contextual proximity", "to": "learning programs", "value": 0.5}, {"from": "consistent decision trees", "title": "all decision trees consistent with the training data are constructed.", "to": "training data", "value": 1.0}, {"from": "consistent instantiation", "title": "contextual proximity", "to": "functional CSPs", "value": 0.75}, {"from": "consistent instantiation", "title": "contextual proximity", "to": "root set", "value": 0.5}, {"from": "constants and unary predicates", "title": "limitation relationship, as the random-worlds method is restricted to this type of vocabulary", "to": "vocabulary underlying Phi and KB", "value": 1.0}, {"from": "constraint", "title": "The method\u0027s two constraints reduce the size of the grammar.", "to": "reduces", "value": 1.0}, {"from": "constraint", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "constraint systems", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "constructing contingency tables", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "constructing contingency tables", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "contextually guided responses to incomplete explanations", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "continuous computation", "title": "contextual proximity", "to": "dynamic environments", "value": 0.5}, {"from": "continuous computation", "title": "contextual proximity", "to": "formalism", "value": 0.5}, {"from": "continuous computation", "title": "We introduce the notion of teleo-reactive (T-R) programs whose execution entails the construction of circuitry for the continuous computation of the parameters and conditions on which agent action is based.", "to": "teleo-reactive (T-R) programs", "value": 1.0}, {"from": "control structures", "title": "contextual proximity", "to": "conventions and invariants", "value": 0.5}, {"from": "control structures", "title": "contextual proximity", "to": "lifeworld", "value": 0.75}, {"from": "controllable agent", "title": "The designer directly controls the behavior of controllable agents in a partially controlled multi-agent system.,contextual proximity", "to": "designer", "value": 2.0}, {"from": "controllable agent", "title": "contextual proximity", "to": "expected utility maximizer", "value": 0.5}, {"from": "controllable agent", "title": "contextual proximity", "to": "multi-agent system", "value": 0.5}, {"from": "controllable agent", "title": "contextual proximity", "to": "partially controlled multi-agent system", "value": 1.5}, {"from": "controllable agent", "title": "contextual proximity", "to": "reinforcement learner", "value": 0.5}, {"from": "controllable agent", "title": "contextual proximity", "to": "uncontrollable agent", "value": 2.0}, {"from": "conventional methods used in many similar systems", "title": "contextual proximity", "to": "identifying inaccurate data", "value": 0.75}, {"from": "conventional methods used in many similar systems", "title": "The experimental results show that the method is significantly better than the conventional methods used in many similar systems.,contextual proximity", "to": "qualitative correlations among related data", "value": 1.5}, {"from": "conventions and invariants", "title": "A lifeworld is defined by the conventions and invariants maintained by agents during their activity.,contextual proximity", "to": "lifeworld", "value": 2.5}, {"from": "conventions and invariants", "title": "contextual proximity", "to": "lifeworlds", "value": 0.5}, {"from": "counting the number of records", "title": "contextual proximity", "to": "independent of the number of records", "value": 0.5}, {"from": "counting the number of records", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "critic", "title": "contextual proximity", "to": "difference matching", "value": 1.25}, {"from": "critic", "title": "contextual proximity", "to": "differences", "value": 1.25}, {"from": "critic", "title": "contextual proximity", "to": "diverging proof attempts", "value": 2.5}, {"from": "critic", "title": "proposes,contextual proximity", "to": "generalizations", "value": 2.25}, {"from": "critic", "title": "proposes,contextual proximity", "to": "lemmas", "value": 2.25}, {"from": "critic", "title": "contextual proximity", "to": "proof attempt", "value": 3.75}, {"from": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "title": "contextual proximity", "to": "learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause", "value": 0.75}, {"from": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "title": "The class of programs with an unbounded number of constant-depth linear recursive clauses is cryptographically hard to learn in Valiant\u0027s model of pac-learnability.,contextual proximity", "to": "programs with an unbounded number of constant-depth linear recursive clauses", "value": 1.75}, {"from": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "title": "The class of programs with one constant-depth determinate clause containing an unbounded number of recursive calls is cryptographically hard to learn in Valiant\u0027s model of pac-learnability.,contextual proximity", "to": "programs with one constant-depth determinate clause containing an unbounded number of recursive calls", "value": 1.75}, {"from": "cryptographically hard to learn in Valiant\u0027s model of pac-learnability", "title": "The class of programs with one linear recursive clause of constant locality is cryptographically hard to learn in Valiant\u0027s model of pac-learnability.,contextual proximity", "to": "programs with one linear recursive clause of constant locality", "value": 1.75}, {"from": "cue phrases may be used", "title": "contextual proximity", "to": "discourse sense", "value": 0.75}, {"from": "cue phrases may be used", "title": "correctly classifying cue phrases as discourse or sentential is critical in natural language processing systems that exploit discourse structure,contextual proximity", "to": "sentential sense", "value": 1.5}, {"from": "custom, button-box user interface", "title": "contextual proximity", "to": "performance system", "value": 0.5}, {"from": "custom, button-box user interface", "title": "The text describes how the system constructs a custom user interface on request, indicating that there is a connection between the user interface and the custom, button-box user interface.,contextual proximity", "to": "user interface", "value": 1.75}, {"from": "data", "title": "contextual proximity", "to": "database", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "discovering knowledge in structural data", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "graph", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "graph match", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "hierarchical description", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "representing structural concepts", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 0.5}, {"from": "data", "title": "contextual proximity", "to": "substructure discovery", "value": 1.5}, {"from": "data", "title": "contextual proximity", "to": "two substructures", "value": 0.5}, {"from": "data-driven learning", "title": "contextual proximity", "to": "hand-coded symbolic grammar or symbolic semantic component", "value": 0.5}, {"from": "data-driven learning", "title": "uses (1) data-driven learning and (2) robustness of connectionist networks for supporting speech and language processing, rather than using a deeply structured symbolic analysis.,contextual proximity", "to": "screening approach", "value": 1.75}, {"from": "data-driven learning", "title": "contextual proximity", "to": "spontaneously spoken language", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "discovering knowledge in structural data", "value": 0.5}, {"from": "database", "title": "represents,represents,contextual proximity", "to": "graph", "value": 2.5}, {"from": "database", "title": "contextual proximity", "to": "graph match", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "hierarchical description", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "representing structural concepts", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 0.5}, {"from": "database", "title": "contextual proximity", "to": "substructure discovery", "value": 1.5}, {"from": "database", "title": "contextual proximity", "to": "two substructures", "value": 0.5}, {"from": "decision-making procedures", "title": "availability in Cassandra", "to": "different decision-making procedures", "value": 1.0}, {"from": "decision-tree learning algorithms", "title": "we discuss a new default strategy for decision-tree learning algorithms.", "to": "default strategy", "value": 1.0}, {"from": "decomposable dependency models", "title": "contextual proximity", "to": "graphical models", "value": 0.5}, {"from": "decomposable dependency models", "title": "contextual proximity", "to": "independence relationships", "value": 0.5}, {"from": "deeply structured symbolic analysis", "title": "contextual proximity", "to": "hand-coded symbolic grammar or symbolic semantic component", "value": 0.5}, {"from": "deeply structured symbolic analysis", "title": "contextual proximity", "to": "screening approach", "value": 0.75}, {"from": "deeply structured symbolic analysis", "title": "approaches often have been based on encoding syntactic and semantic knowledge manually and symbolically, in contrast to the screening approach described in this paper.,contextual proximity", "to": "spontaneously spoken language", "value": 1.5}, {"from": "default reasoning", "title": "The axiomatization of the logic of relative likelihood in the case of partial orders gives insight into the connection between relative likelihood and default reasoning.,contextual proximity", "to": "logic of relative likelihood", "value": 1.5}, {"from": "degrees of freedom analysis", "title": "recently suggested approach", "to": "efficiently solving the problem of finding the configuration of a collection of geometric bodies to satisfy given constraints by symbolically reasoning about geometry", "value": 1.0}, {"from": "delayed reinforcement", "title": "the central issues of reinforcement learning, including learning from delayed reinforcement, are discussed in this paper.", "to": "learning from delayed reinforcement", "value": 1.0}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "difficult goal interactions", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "eager-commitment", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "eager-commitment planners", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "efficient planning strategies", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "least-commitment planners", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "planning algorithm", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "planning domains and problems", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "planning problems", "value": 0.5}, {"from": "delayed-commitment", "title": "contextual proximity", "to": "planning strategy", "value": 0.5}, {"from": "dependency-directed backtracking", "title": "The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.", "to": "useful control information", "value": 1.0}, {"from": "description graphs", "title": "contextual proximity", "to": "description logics", "value": 0.5}, {"from": "description graphs", "title": "contextual proximity", "to": "individuals", "value": 0.5}, {"from": "description graphs", "title": "contextual proximity", "to": "standard, model-theoretic semantics for description logics", "value": 1.0}, {"from": "description graphs", "title": "contextual proximity", "to": "subsumption algorithm", "value": 0.5}, {"from": "description logics", "title": "contextual proximity", "to": "standard, model-theoretic semantics for description logics", "value": 0.5}, {"from": "designer", "title": "contextual proximity", "to": "expected utility maximizer", "value": 0.5}, {"from": "designer", "title": "contextual proximity", "to": "multi-agent system", "value": 0.5}, {"from": "designer", "title": "contextual proximity", "to": "partially controlled multi-agent system", "value": 1.5}, {"from": "designer", "title": "contextual proximity", "to": "reinforcement learner", "value": 0.5}, {"from": "designer", "title": "contextual proximity", "to": "uncontrollable agent", "value": 2.0}, {"from": "desirable TKRS-deduction services", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "deterministic efficient optimal strategy", "title": "In the imperfect monitoring case, it is proven that a deterministic efficient optimal strategy exists under the maxmin criterion.", "to": "maxmin criterion", "value": 1.0}, {"from": "difference matching", "title": "contextual proximity", "to": "diverging proof attempts", "value": 0.5}, {"from": "difference matching", "title": "recognizes,contextual proximity", "to": "proof attempt", "value": 1.75}, {"from": "differences", "title": "contextual proximity", "to": "diverging proof attempts", "value": 0.5}, {"from": "differences", "title": "contextual proximity", "to": "proof attempt", "value": 0.75}, {"from": "differing, incomplete, and possibly inconsistent views of their environment", "title": "contextual proximity", "to": "joint intentions", "value": 0.75}, {"from": "differing, incomplete, and possibly inconsistent views of their environment", "title": "Uncertainties in complex, dynamic domains obstruct coherent teamwork as team members often encounter differing, incomplete, and possibly inconsistent views of their environment.,contextual proximity", "to": "team members", "value": 1.75}, {"from": "difficult goal interactions", "title": "There has been evidence that least-commitment planners can efficiently handle planning problems involving difficult goal interactions.", "to": "least-commitment planners", "value": 1.0}, {"from": "difficult problem instances", "title": "displaying the same phase transition behavior, and at the same location, as seen in many previously studied classical search methods.", "to": "underconstrained/overconstrained problems", "value": 1.0}, {"from": "difficult real-time constraints imposed by moving vehicle applications", "title": "The main aim of this work is the development of a vision-based road detection system that can cope with the difficult real-time constraints imposed by moving vehicle applications.,contextual proximity", "to": "vision-based road detection system", "value": 1.5}, {"from": "direct application of multiclass algorithms", "title": "contextual proximity", "to": "distributed output representation", "value": 0.5}, {"from": "direct application of multiclass algorithms", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "direct application of multiclass algorithms", "title": "Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART.,contextual proximity", "to": "multiclass learning problems", "value": 2.0}, {"from": "directed graphs representing a Markov chain", "title": "contextual proximity", "to": "graphical framework", "value": 0.5}, {"from": "directed graphs representing a Markov chain", "title": "Directed graphs representing a Markov chain are a type of graphical model, specifically Bayesian networks.,contextual proximity", "to": "graphical models", "value": 2.0}, {"from": "directed graphs representing a Markov chain", "title": "contextual proximity", "to": "graphical specification", "value": 0.5}, {"from": "discourse sense", "title": "contextual proximity", "to": "explicitly signal discourse structure", "value": 0.75}, {"from": "discourse sense", "title": "contextual proximity", "to": "manually derived classification models already in the literature", "value": 0.75}, {"from": "discourse sense", "title": "contextual proximity", "to": "semantic rather than structural information", "value": 0.75}, {"from": "discourse sense", "title": "contextual proximity", "to": "sentential sense", "value": 1.5}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "graph", "value": 0.5}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "graph match", "value": 0.5}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 1.0}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "hierarchical description", "value": 1.0}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "inexact graph match", "value": 0.5}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "representing structural concepts", "value": 1.0}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 1.0}, {"from": "discovering knowledge in structural data", "title": "essential component,essential component,essential component,essential component,contextual proximity", "to": "substructure discovery", "value": 7.0}, {"from": "discovering knowledge in structural data", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "discrete symbols", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "discrete symbols", "title": "SEQUITUR operates on a sequence of discrete symbols.", "to": "sequence", "value": 1.0}, {"from": "distorted template", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "distorted template", "title": "The distorted template is the process output.", "to": "original template", "value": 1.0}, {"from": "distributed output representation", "title": "contextual proximity", "to": "distributed output representations", "value": 0.5}, {"from": "distributed output representation", "title": "This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation.,contextual proximity", "to": "error-correcting codes", "value": 1.5}, {"from": "distributed output representation", "title": "contextual proximity", "to": "error-correcting output codes", "value": 0.5}, {"from": "distributed output representation", "title": "contextual proximity", "to": "k classes", "value": 1.0}, {"from": "distributed output representation", "title": "contextual proximity", "to": "multiclass learning problems", "value": 2.0}, {"from": "distributed output representation", "title": "contextual proximity", "to": "multiclass problems", "value": 0.5}, {"from": "distributed output representation", "title": "contextual proximity", "to": "overfitting avoidance techniques", "value": 0.5}, {"from": "distributed output representation", "title": "contextual proximity", "to": "particular classes", "value": 0.5}, {"from": "distributed output representation", "title": "contextual proximity", "to": "reliable class probability estimates", "value": 0.5}, {"from": "distributed output representation", "title": "contextual proximity", "to": "robustness", "value": 0.5}, {"from": "distributed output representations", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "distributed output representations", "title": "contextual proximity", "to": "multiclass learning problems", "value": 1.0}, {"from": "distributed output representations", "title": "The assignment of distributed representations to particular classes,", "to": "particular classes", "value": 1.0}, {"from": "distributed system", "title": "contextual proximity", "to": "heterogeneous populations", "value": 0.5}, {"from": "diverging proof attempts", "title": "contextual proximity", "to": "generalizations", "value": 0.5}, {"from": "diverging proof attempts", "title": "contextual proximity", "to": "lemmas", "value": 0.5}, {"from": "diverging proof attempts", "title": "is,contextual proximity", "to": "proof attempt", "value": 2.5}, {"from": "domain theory", "title": "contextual proximity", "to": "logical domain theories", "value": 0.5}, {"from": "domain theory", "title": "In this paper, we consider the problem of theory patching for domain theories that are possibly flawed. The objective is to revise only the indicated components of the theory based on labeled training examples, such that the resulting theory correctly classifies all the training examples.,contextual proximity", "to": "theory patching", "value": 2.0}, {"from": "domain-independent techniques", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "domain-independent techniques", "title": "The author proposes some domain-independent techniques for bringing well-founded partial-order planners closer to practicality.", "to": "practicality of well-founded partial-order planners", "value": 1.0}, {"from": "domain-independent techniques", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "domain-independent techniques", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "domain-independent techniques", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "domains in which the attributes are numeric", "title": "Oblique decision tree methods are tuned especially for domains in which the attributes are numeric, although they can be adapted to symbolic or mixed symbolic/numeric attributes.", "to": "oblique decision tree methods", "value": 1.0}, {"from": "dynamic environments", "title": "A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments.,contextual proximity", "to": "formalism", "value": 2.0}, {"from": "dynamic environments", "title": "contextual proximity", "to": "intuitive and easy to write", "value": 0.5}, {"from": "dynamic environments", "title": "contextual proximity", "to": "run time construction", "value": 0.5}, {"from": "dynamic environments", "title": "contextual proximity", "to": "teleo-reactive (T-R) programs", "value": 0.5}, {"from": "dynamic shift intervals of inaccurate data", "title": "Both of the approaches are based on SCF. Finally we present an algorithm for identifying inaccurate data by using qualitative correlations among related data as confirmatory or disconfirmatory evidence.,contextual proximity", "to": "identifying inaccurate data", "value": 1.75}, {"from": "dynamic shift intervals of inaccurate data", "title": "contextual proximity", "to": "qualitative correlations among related data", "value": 0.5}, {"from": "eager-commitment planners", "title": "We recently found evidence that eager-commitment planners can handle a variety of planning problems more efficiently, particularly those with difficult operator choices.", "to": "planning problems", "value": 1.0}, {"from": "easy-hard-easy pattern", "title": "contextual proximity", "to": "median search cost", "value": 0.75}, {"from": "easy-hard-easy pattern", "title": "contextual proximity", "to": "number of solutions", "value": 0.75}, {"from": "easy-hard-easy pattern", "title": "For some search methods, the easy-hard-easy pattern is observed even when the number of solutions is held constant, leading to a monotonic decrease in search cost as constraints are added.,contextual proximity", "to": "search cost", "value": 3.25}, {"from": "easy-hard-easy pattern", "title": "The easy-hard-easy pattern is observed for some search methods even when the number of solutions is held constant.,contextual proximity", "to": "search method", "value": 1.75}, {"from": "efficient and accurate", "title": "The techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate.", "to": "mixtures of Gaussians and locally weighted regression", "value": 1.0}, {"from": "efficient and accurate", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "efficient planning strategies", "title": "FLECS represents a novel contribution to planning in that it explicitly provides the choice of which commitment strategy to use while planning. FLECS provides a framework to investigate the mapping from planning domains and problems to efficient planning strategies.", "to": "planning domains and problems", "value": 1.0}, {"from": "efficient stochastic policy", "title": "In the perfect monitoring case, the existence of an efficient stochastic policy is proven that ensures a long-run optimality criterion with an arbitrarily high probability, where efficiency is measured in terms of rate of convergence.", "to": "optimal policy", "value": 1.0}, {"from": "electronic organizer", "title": "Handwriting recognition is a feature that can be implemented in an electronic organizer to efficiently enter information into a computer. This paper highlights its usage and compares its speed with other input methods for adding a person\u0027s name and address.,contextual proximity", "to": "handwriting recognition", "value": 2.25}, {"from": "electronic organizer", "title": "A person\u0027s address is another concept that can be added to an electronic organizer using the aforementioned intelligent user interfaces, as demonstrated in this paper.,contextual proximity", "to": "person\u0027s address", "value": 2.25}, {"from": "electronic organizer", "title": "A person\u0027s name is a concept that can be entered into an electronic organizer using handwriting recognition, adaptive menus, or predictive fillin, as illustrated in this paper.,contextual proximity", "to": "person\u0027s name", "value": 2.25}, {"from": "electronic organizer", "title": "Predictive fillin is another user interface that can be implemented in an electronic organizer to efficiently enter information into a computer, as shown in this paper for adding a person\u0027s name and address. Its speed can be twice as fast compared to other methods.,contextual proximity", "to": "predictive fillin", "value": 2.25}, {"from": "empirical analysis", "title": "contextual proximity", "to": "path consistency algorithm", "value": 0.5}, {"from": "empirical analysis", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "empirical models", "title": "the central issues of reinforcement learning, including constructing empirical models to accelerate learning, are discussed in this paper.", "to": "accelerating learning", "value": 1.0}, {"from": "entropy", "title": "association relationship, as entropy can be naturally associated with each world when Phi and KB use constants and unary predicates only", "to": "each world", "value": 1.0}, {"from": "ergodicity", "title": "Markovian models with ergodic transition probability matrices are less likely to have diffusion of context and credit due to their ability to visit all possible states in the long run.", "to": "Markovian models", "value": 1.0}, {"from": "error-correcting codes", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "error-correcting codes", "title": "contextual proximity", "to": "multiclass learning problems", "value": 1.0}, {"from": "error-correcting output codes", "title": "contextual proximity", "to": "k classes", "value": 0.5}, {"from": "error-correcting output codes", "title": "contextual proximity", "to": "multiclass learning problems", "value": 1.0}, {"from": "error-correcting output codes", "title": "Finally, we show that---like the other methods---the error-correcting code technique can provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.", "to": "multiclass problems", "value": 1.0}, {"from": "evidence symbols", "title": "contextual proximity", "to": "standard algorithms for exact inference", "value": 0.5}, {"from": "existing backtracking methods", "title": "Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem.", "to": "meaningful progress toward solving a search problem", "value": 1.0}, {"from": "existing solutions", "title": "The paper shows under some conditions that the existence of solutions can be guaranteed for functional CSPs by combining semantic properties of functional constraints and structural properties of the network.,contextual proximity", "to": "functional CSPs", "value": 1.75}, {"from": "existing solutions", "title": "contextual proximity", "to": "root set", "value": 0.5}, {"from": "expansions", "title": "We describe a technique to reduce generalizations under implication of a clause to generalizations under theta-subsumption of what we call an expansion", "to": "induction", "value": 1.0}, {"from": "expansions", "title": "contextual proximity", "to": "inductive learning", "value": 0.75}, {"from": "expansions", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "expectation maximization algorithm", "title": "contextual proximity", "to": "graphical framework", "value": 0.5}, {"from": "expectation maximization algorithm", "title": "contextual proximity", "to": "graphical models", "value": 1.0}, {"from": "expectation maximization algorithm", "title": "contextual proximity", "to": "graphical specification", "value": 0.5}, {"from": "expectation-driven low-level image segmentation", "title": "This paper presents a novel approach to expectation-driven low-level image segmentation, which can be mapped naturally onto mesh-connected massively parallel SIMD architectures capable of handling hierarchical data structures.", "to": "massively parallel SIMD architectures capable of handling hierarchical data structures", "value": 1.0}, {"from": "expectation-driven low-level image segmentation", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "expected utility maximizer", "title": "contextual proximity", "to": "partially controlled multi-agent system", "value": 0.75}, {"from": "expected utility maximizer", "title": "contextual proximity", "to": "uncontrollable agent", "value": 1.0}, {"from": "experiments based on modifications of UCPOP", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "experiments based on modifications of UCPOP", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "experiments based on modifications of UCPOP", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "experiments based on modifications of UCPOP", "title": "The author\u0027s improved plan and goal selection strategies gave speedups by factors ranging from 5 to more than 1000 for a variety of problems that are nontrivial for the unmodified version during experiments.,contextual proximity", "to": "speedups", "value": 1.5}, {"from": "explicit decision-steps", "title": "incompatibility", "to": "action outcome predictability", "value": 1.0}, {"from": "explicit negative examples", "title": "contextual proximity", "to": "first-order decision lists", "value": 0.5}, {"from": "explicit negative examples", "title": "contextual proximity", "to": "learning a new class of concepts", "value": 0.5}, {"from": "explicitly signal discourse structure", "title": "contextual proximity", "to": "sentential sense", "value": 0.5}, {"from": "exploration vs. exploitation", "title": "contextual proximity", "to": "heterogeneous populations", "value": 0.5}, {"from": "extensional evaluation method", "title": "contextual proximity", "to": "learning programs", "value": 0.5}, {"from": "failed to fulfill responsibilities or discovered unexpected opportunities", "title": "contextual proximity", "to": "joint intentions", "value": 0.75}, {"from": "failed to fulfill responsibilities or discovered unexpected opportunities", "title": "Furthermore, team members can unexpectedly fail in fulfilling responsibilities or discover unexpected opportunities.,contextual proximity", "to": "team members", "value": 1.75}, {"from": "feed-forward networks", "title": "contextual proximity", "to": "graphical framework", "value": 0.5}, {"from": "feed-forward networks", "title": "contextual proximity", "to": "graphical models", "value": 1.0}, {"from": "feed-forward networks", "title": "contextual proximity", "to": "graphical specification", "value": 0.5}, {"from": "feedforward neural networks", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "improved theory", "value": 0.5}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "inductive learning", "value": 0.5}, {"from": "fine-tuned theory", "title": "a more accurate theory forced to use that same representation may be bulky, cumbersome, and difficult to reach.,contextual proximity", "to": "initial theory", "value": 2.0}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "more accurate theory", "value": 0.5}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "original representation", "value": 0.5}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "previous theory-guided systems", "value": 0.5}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "small, local changes to a theory", "value": 0.5}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "theory revision", "value": 0.5}, {"from": "fine-tuned theory", "title": "contextual proximity", "to": "theory-guided constructive induction", "value": 0.5}, {"from": "finite set of clauses containing at least one non-tautologous function-free clause (among other, not necessarily function-free clauses)", "title": "existence under implication in each of the six ordered sets,contextual proximity", "to": "least generalization", "value": 1.5}, {"from": "first step", "title": "contextual proximity", "to": "high level of system performance", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "human performance", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "information", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "information extraction", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "interest", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "key word search", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "first step", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "first-order decision lists", "title": "contextual proximity", "to": "intensional background knowledge", "value": 0.5}, {"from": "first-order decision lists", "title": "contextual proximity", "to": "learning a new class of concepts", "value": 1.0}, {"from": "first-order decision lists", "title": "contextual proximity", "to": "significantly fewer examples", "value": 0.5}, {"from": "first-order decision lists", "title": "contextual proximity", "to": "symbolic/connectionist debate", "value": 0.5}, {"from": "flexibility", "title": "contextual proximity", "to": "joint intentions", "value": 0.75}, {"from": "flexibility", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "flexible paradigm for teaching tasks", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "flexible paradigm for teaching tasks", "title": "allows an instructor to communicate whatever types of knowledge an agent might need in whatever situations might arise.", "to": "interactive tutorial instruction", "value": 1.0}, {"from": "form of explanation-based learning", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "formalism", "title": "contextual proximity", "to": "intuitive and easy to write", "value": 0.5}, {"from": "formalism", "title": "contextual proximity", "to": "run time construction", "value": 0.5}, {"from": "formalism", "title": "contextual proximity", "to": "teleo-reactive (T-R) programs", "value": 0.5}, {"from": "formula Phi", "title": "implication relationship, as the degree of belief for Phi is computed given KB using the random-worlds method", "to": "knowledge base KB", "value": 1.0}, {"from": "formulae", "title": "contextual proximity", "to": "formulae preserving truth-value", "value": 0.5}, {"from": "formulae", "title": "contextual proximity", "to": "nonmonotonicity", "value": 1.0}, {"from": "formulae", "title": "contextual proximity", "to": "preferential logics", "value": 1.0}, {"from": "formulae", "title": "contextual proximity", "to": "safely added formulae", "value": 0.5}, {"from": "formulae", "title": "contextual proximity", "to": "theorem provers", "value": 0.5}, {"from": "formulae preserving truth-value", "title": "contextual proximity", "to": "nonmonotonicity", "value": 0.5}, {"from": "formulae preserving truth-value", "title": "The formulae whose truth-value is preserved along the ordering are closely linked to preferential logics.,contextual proximity", "to": "preferential logics", "value": 1.5}, {"from": "four in total", "title": "In the process of our investigation, we identify all maximal tractable subalgebras, which number four in total.", "to": "maximal tractable subalgebras", "value": 1.0}, {"from": "full knowledge of the conditions under which the plan will be executed", "title": "opposite concepts", "to": "uncertainty in the world", "value": 1.0}, {"from": "functional CSPs", "title": "contextual proximity", "to": "functional constraints", "value": 0.75}, {"from": "functional CSPs", "title": "contextual proximity", "to": "local consistency", "value": 0.75}, {"from": "functional CSPs", "title": "contextual proximity", "to": "root set", "value": 1.5}, {"from": "functional CSPs", "title": "contextual proximity", "to": "semantic properties", "value": 0.75}, {"from": "functional constraints", "title": "contextual proximity", "to": "root set", "value": 0.5}, {"from": "functional constraints", "title": "The paper proposes a decomposition method that takes into account semantic properties of functional constraints (not bijective constraints) in solving functional CSPs.", "to": "semantic properties", "value": 1.0}, {"from": "game-tree search", "title": "Logistic regression is applied in the context of game playing for estimating feature weights in three well-known statistical methods. This application is described in this article, where it leads to better results than other approaches like Fisher\u0027s linear discriminant and quadratic discriminant function for normally distributed features.,contextual proximity", "to": "logistic regression", "value": 3.0}, {"from": "game-tree search", "title": "contextual proximity", "to": "playing strengths", "value": 1.0}, {"from": "game-tree search", "title": "The quadratic discriminant function for normally distributed features is utilized as part of three well-known statistical methods to estimate feature weights using a large number of classified Othello positions in the context of game playing, as discussed in this article.,contextual proximity", "to": "quadratic discriminant function", "value": 2.0}, {"from": "game-tree search", "title": "contextual proximity", "to": "well-known statistical methods", "value": 1.0}, {"from": "game-tree search", "title": "contextual proximity", "to": "world-class Othello program", "value": 1.0}, {"from": "general concepts", "title": "This TKRS allows to express inclusion statements between general concepts, which is often required in practical applications.,contextual proximity", "to": "inclusion statements", "value": 1.5}, {"from": "generalization", "title": "In the area of inductive learning, generalization is a main operation,contextual proximity", "to": "inductive learning", "value": 1.75}, {"from": "generalization", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "generalization and hierarchy", "title": "the central issues of reinforcement learning, including making use of generalization and hierarchy, are discussed in this paper.", "to": "making use of generalization and hierarchy", "value": 1.0}, {"from": "generalizations", "title": "contextual proximity", "to": "proof attempt", "value": 0.75}, {"from": "geometric bodies", "title": "the problem of finding the configuration of a collection of geometric bodies to satisfy given constraints applies to geometric bodies.", "to": "collection of geometric shapes or objects", "value": 1.0}, {"from": "good performance", "title": "Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.", "to": "optimal data selection techniques", "value": 1.0}, {"from": "good performance", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "gradient", "title": "conjecture that both the average score and average branching rate decay exponentially during plateau search.", "to": "average gradient", "value": 1.0}, {"from": "grammatical", "title": "The algorithm replaces repeated phrases with a grammatical rule that generates the phrase.", "to": "rule", "value": 1.0}, {"from": "grammatical", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "graph match", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "hierarchical description", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "representing structural concepts", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 0.5}, {"from": "graph", "title": "contextual proximity", "to": "substructure discovery", "value": 1.5}, {"from": "graph", "title": "contextual proximity", "to": "two substructures", "value": 0.5}, {"from": "graph match", "title": "contextual proximity", "to": "guides the search towards more appropriate substructures", "value": 0.5}, {"from": "graph match", "title": "contextual proximity", "to": "hierarchical description", "value": 0.5}, {"from": "graph match", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "graph match", "title": "contextual proximity", "to": "representing structural concepts", "value": 0.5}, {"from": "graph match", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 0.5}, {"from": "graph match", "title": "contextual proximity", "to": "substructure discovery", "value": 1.5}, {"from": "graph match", "title": "contextual proximity", "to": "two substructures", "value": 0.5}, {"from": "graph of partial plans", "title": "Plan adaptation involves searching a graph of partial plans, starting at the root and moving from node to node using plan-refinement operators.,contextual proximity", "to": "plan adaptation", "value": 2.0}, {"from": "graphical framework", "title": "contextual proximity", "to": "graphical models", "value": 2.0}, {"from": "graphical framework", "title": "contextual proximity", "to": "graphical specification", "value": 1.0}, {"from": "graphical framework", "title": "contextual proximity", "to": "learning Gaussian and discrete Bayesian networks from data", "value": 0.5}, {"from": "graphical framework", "title": "contextual proximity", "to": "linear regression", "value": 0.5}, {"from": "graphical framework", "title": "contextual proximity", "to": "plates", "value": 0.5}, {"from": "graphical framework", "title": "contextual proximity", "to": "undirected networks representing a Markov field", "value": 0.5}, {"from": "graphical models", "title": "contextual proximity", "to": "graphical specification", "value": 2.0}, {"from": "graphical models", "title": "contextual proximity", "to": "learning Gaussian and discrete Bayesian networks from data", "value": 1.0}, {"from": "graphical models", "title": "contextual proximity", "to": "linear regression", "value": 1.0}, {"from": "graphical models", "title": "Plates are an extension of graphical models to model data analysis and empirical learning.,contextual proximity", "to": "plates", "value": 2.0}, {"from": "graphical models", "title": "contextual proximity", "to": "undirected networks representing a Markov field", "value": 1.0}, {"from": "graphical specification", "title": "contextual proximity", "to": "learning Gaussian and discrete Bayesian networks from data", "value": 0.5}, {"from": "graphical specification", "title": "Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification, including versions of linear regression.,contextual proximity", "to": "linear regression", "value": 1.5}, {"from": "graphical specification", "title": "contextual proximity", "to": "plates", "value": 0.5}, {"from": "graphical specification", "title": "contextual proximity", "to": "undirected networks representing a Markov field", "value": 0.5}, {"from": "greatest specialization", "title": "contextual proximity", "to": "least generalization", "value": 0.5}, {"from": "greatest specialization", "title": "complete discussion of existence and non-existence", "to": "sets of clauses in each of the six ordered languages", "value": 1.0}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "hierarchical description", "value": 1.0}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "inexact graph match", "value": 0.5}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "representing structural concepts", "value": 1.0}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 1.0}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "substructure discovery", "value": 3.0}, {"from": "guides the search towards more appropriate substructures", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "hand-coded symbolic grammar or symbolic semantic component", "title": "is a flat analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic, semantic and dialog levels, in contrast to the deeply structured symbolic analysis.,contextual proximity", "to": "screening approach", "value": 2.5}, {"from": "hand-coded symbolic grammar or symbolic semantic component", "title": "approaches often have been based on encoding syntactic and semantic knowledge manually and symbolically, in contrast to the screening approach described in this paper.,contextual proximity", "to": "spontaneously spoken language", "value": 2.0}, {"from": "hardest problems", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "hardest problems", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "hardest problems", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "hardest problems", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "head-to-head", "title": "We conduct extensive head-to-head comparisons on the generalization ability between ANN models and the SPA under different representations.", "to": "comparisons", "value": 1.0}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "individual agents", "value": 0.5}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "load balancing", "value": 0.5}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "multi-agent reinforcement learning", "value": 0.5}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "naive use of communication", "value": 0.5}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "purely local information", "value": 0.5}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "stochastic nature", "value": 0.5}, {"from": "heterogeneous populations", "title": "contextual proximity", "to": "system efficiency", "value": 0.5}, {"from": "hidden state", "title": "the central issues of reinforcement learning, including coping with hidden state, are discussed in this paper.", "to": "coping with hidden state", "value": 1.0}, {"from": "hierarchical", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "hierarchical description", "title": "contextual proximity", "to": "inexact graph match", "value": 0.5}, {"from": "hierarchical description", "title": "contextual proximity", "to": "original data", "value": 0.5}, {"from": "hierarchical description", "title": "contextual proximity", "to": "representing structural concepts", "value": 1.0}, {"from": "hierarchical description", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 1.0}, {"from": "hierarchical description", "title": "multiple passes of SUBDUE,multiple passes of SUBDUE,multiple passes of SUBDUE,multiple passes of SUBDUE,contextual proximity", "to": "substructure discovery", "value": 7.0}, {"from": "hierarchical description", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "hierarchy", "title": "contextual proximity", "to": "knowledge base", "value": 1.0}, {"from": "hierarchy", "title": "contextual proximity", "to": "stable models", "value": 0.5}, {"from": "high level of system performance", "title": "Evaluation results show a high level of system performance which approaches human performance.,Evaluation results show a high level of system performance which approaches human performance.,contextual proximity", "to": "human performance", "value": 2.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "information", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "information extraction", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "interest", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "key word search", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "high level of system performance", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "higher level IE processing", "title": "has a subset relationship", "to": "information extraction (IE) processing", "value": 1.0}, {"from": "highly expressive terminological language", "title": "contextual proximity", "to": "inclusion statements", "value": 0.5}, {"from": "highly optimized implementation", "title": "develop techniques that can result in up to a ten-fold speedup over,contextual proximity", "to": "path consistency algorithm", "value": 1.5}, {"from": "highly optimized implementation", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "hill-climbing", "title": "GSAT performs greedy hill-climbing on the number of satisfied clauses in a truth assignment.", "to": "greedy", "value": 1.0}, {"from": "hill-climbing phase", "title": "describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search.", "to": "rapid hill-climbing", "value": 1.0}, {"from": "human performance", "title": "contextual proximity", "to": "information", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "information extraction", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "interest", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "key word search", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "human performance", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "identifying inaccurate data", "title": "contextual proximity", "to": "qualitative correlations among related data", "value": 1.5}, {"from": "identifying inaccurate data", "title": "contextual proximity", "to": "real spectra", "value": 0.75}, {"from": "implication", "title": "contextual proximity", "to": "inductive learning", "value": 0.75}, {"from": "implication", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "improved theory", "title": "representation language appropriate for the initial theory may be inappropriate for an improved theory.,contextual proximity", "to": "initial theory", "value": 1.5}, {"from": "inclusion statements", "title": "contextual proximity", "to": "knowledge base", "value": 0.5}, {"from": "inclusion statements", "title": "Terminological cycles are a particular case of inclusion statements between general concepts.,contextual proximity", "to": "terminological cycles", "value": 1.5}, {"from": "inclusion statements", "title": "contextual proximity", "to": "terminological language", "value": 0.5}, {"from": "independent of the number of records", "title": "contextual proximity", "to": "loglinear in the number of non-zero entries", "value": 0.5}, {"from": "independent of the number of records", "title": "contextual proximity", "to": "machine learning datasets", "value": 0.5}, {"from": "independent of the number of records", "title": "contextual proximity", "to": "merits", "value": 0.5}, {"from": "independent of the number of records", "title": "contextual proximity", "to": "minimize memory use", "value": 0.5}, {"from": "independent of the number of records", "title": "contextual proximity", "to": "quick counting", "value": 1.0}, {"from": "independent of the number of records", "title": "contextual proximity", "to": "traditional direct counting approaches", "value": 0.5}, {"from": "individual agents", "title": "available to individual agents.", "to": "purely local information", "value": 1.0}, {"from": "individual members\u0027", "title": "Furthermore, in STEAM, team members monitor the team\u0027s and individual members\u0027 performance, reorganizing the team as necessary.,contextual proximity", "to": "joint intentions", "value": 1.75}, {"from": "individual members\u0027", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "individuals", "title": "contextual proximity", "to": "standard, model-theoretic semantics for description logics", "value": 0.5}, {"from": "induced solutions", "title": "contextual proximity", "to": "machine learning method", "value": 0.5}, {"from": "induced solutions", "title": "Induced solutions are presented in the form of ordered disjunctive normal form (DNF).,contextual proximity", "to": "ordered disjunctive normal form (DNF)", "value": 1.5}, {"from": "induction", "title": "contextual proximity", "to": "inductive learning", "value": 0.75}, {"from": "induction", "title": "contextual proximity", "to": "inductive learning systems", "value": 0.5}, {"from": "induction method", "title": "contextual proximity", "to": "machine learning method", "value": 0.5}, {"from": "induction method", "title": "contextual proximity", "to": "ordered disjunctive normal form (DNF)", "value": 0.5}, {"from": "inductive learning", "title": "contextual proximity", "to": "inductive learning systems", "value": 1.5}, {"from": "inductive learning", "title": "contextual proximity", "to": "initial theory", "value": 0.5}, {"from": "inductive learning", "title": "contextual proximity", "to": "learning recursive clauses", "value": 0.75}, {"from": "inductive learning", "title": "contextual proximity", "to": "logical implication", "value": 0.75}, {"from": "inductive learning", "title": "contextual proximity", "to": "machine learning", "value": 0.75}, {"from": "inductive learning", "title": "contextual proximity", "to": "non-tautological clauses", "value": 0.75}, {"from": "inductive learning", "title": "contextual proximity", "to": "recursive clauses", "value": 0.75}, {"from": "inductive learning", "title": "contextual proximity", "to": "theta-subsumption", "value": 0.75}, {"from": "inductive learning", "title": "integrates by combining training examples with a coarse domain theory to produce a more accurate theory.", "to": "theory revision", "value": 1.0}, {"from": "inductive learning systems", "title": "contextual proximity", "to": "learning recursive clauses", "value": 0.5}, {"from": "inductive learning systems", "title": "contextual proximity", "to": "logical implication", "value": 0.5}, {"from": "inductive learning systems", "title": "contextual proximity", "to": "machine learning", "value": 0.5}, {"from": "inductive learning systems", "title": "contextual proximity", "to": "non-tautological clauses", "value": 0.5}, {"from": "inductive learning systems", "title": "contextual proximity", "to": "recursive clauses", "value": 0.5}, {"from": "inductive learning systems", "title": "Almost all inductive learning systems that perform generalization of clauses use the relation theta-subsumption instead of implication,contextual proximity", "to": "theta-subsumption", "value": 1.5}, {"from": "inexact graph match", "title": "contextual proximity", "to": "representing structural concepts", "value": 0.5}, {"from": "inexact graph match", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 0.5}, {"from": "inexact graph match", "title": "contextual proximity", "to": "substructure discovery", "value": 1.5}, {"from": "inexact graph match", "title": "contextual proximity", "to": "two substructures", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "information extraction", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "interest", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "key word search", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "information", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "interest", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "key word search", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "information extraction", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "initial and goal conditions", "title": "contextual proximity", "to": "operator parameter domains", "value": 0.5}, {"from": "initial and goal conditions", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "initial and goal conditions", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "initial and goal conditions", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "initial theory", "title": "contextual proximity", "to": "more accurate theory", "value": 0.5}, {"from": "initial theory", "title": "contextual proximity", "to": "original representation", "value": 0.5}, {"from": "initial theory", "title": "contextual proximity", "to": "previous theory-guided systems", "value": 0.5}, {"from": "initial theory", "title": "contextual proximity", "to": "small, local changes to a theory", "value": 0.5}, {"from": "initial theory", "title": "contextual proximity", "to": "theory revision", "value": 0.5}, {"from": "initial theory", "title": "contextual proximity", "to": "theory-guided constructive induction", "value": 0.5}, {"from": "input", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "input", "title": "SEQUITUR\u0027s implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences.", "to": "symbols", "value": 1.0}, {"from": "input image", "title": "The input image is assumed to contain a distorted version of a given template; a multiresolution stretching process is used to reshape the original template in accordance with the acquired image content, minimizing a potential function.", "to": "multiresolution stretching process", "value": 1.0}, {"from": "input image", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions)", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "intelligence", "title": "contextual proximity", "to": "learning", "value": 1.5}, {"from": "intelligence", "title": "contextual proximity", "to": "machine learning", "value": 0.5}, {"from": "intelligence", "title": "contextual proximity", "to": "reasoning", "value": 1.5}, {"from": "intelligent systems", "title": "Intelligent systems with a desired property as per the theoretical foundation", "to": "desired property", "value": 1.0}, {"from": "intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.", "title": "contextual proximity", "to": "joint intentions", "value": 0.75}, {"from": "intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "intensional background knowledge", "title": "contextual proximity", "to": "learning a new class of concepts", "value": 0.5}, {"from": "interactive tutorial instruction", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "interest", "title": "contextual proximity", "to": "key word search", "value": 0.5}, {"from": "interest", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "interest", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "interest", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "interest", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "interest", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "ion", "title": "In several domains, abstraction by dropping sentences has proven useful in problem solving approaches. However, this approach has significant drawbacks as illustrated in this paper. To overcome these drawbacks, a more general view of abstraction involving the change of representation language is proposed.", "to": "abstraction by dropping sentences", "value": 1.0}, {"from": "joint intentions", "title": "contextual proximity", "to": "partial SharedPlans", "value": 0.75}, {"from": "joint intentions", "title": "contextual proximity", "to": "reorganizing the team", "value": 0.75}, {"from": "joint intentions", "title": "contextual proximity", "to": "reusability", "value": 0.75}, {"from": "joint intentions", "title": "contextual proximity", "to": "team members", "value": 2.25}, {"from": "joint intentions", "title": "contextual proximity", "to": "team members\u0027", "value": 0.75}, {"from": "joint intentions", "title": "STEAM\u0027s teamwork is based on agents building up a (partial) hierarchy of joint intentions.,contextual proximity", "to": "teamwork", "value": 1.75}, {"from": "k classes", "title": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k \u0026gt 2 values, which are referred to as k \u0027classes\u0027.,contextual proximity", "to": "multiclass learning problems", "value": 3.0}, {"from": "k classes", "title": "contextual proximity", "to": "multiclass problems", "value": 0.5}, {"from": "k classes", "title": "contextual proximity", "to": "overfitting avoidance techniques", "value": 0.5}, {"from": "k classes", "title": "contextual proximity", "to": "particular classes", "value": 0.5}, {"from": "k classes", "title": "contextual proximity", "to": "reliable class probability estimates", "value": 0.5}, {"from": "k classes", "title": "contextual proximity", "to": "robustness", "value": 0.5}, {"from": "key word search", "title": "contextual proximity", "to": "pieces of information", "value": 0.5}, {"from": "key word search", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "key word search", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "key word search", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "key word search", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "knowledge base", "title": "contextual proximity", "to": "minimum k", "value": 1.0}, {"from": "knowledge base", "title": "contextual proximity", "to": "stable models", "value": 2.0}, {"from": "knowledge base", "title": "contextual proximity", "to": "stratified knowledge base", "value": 1.0}, {"from": "known or unknown commands", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "learning", "title": "Seemingly minor aspect of language acquisition is learning, which has generated heated debates since 1986.", "to": "acquisition", "value": 1.0}, {"from": "learning", "title": "Machine learning falls under the topic of learning.,contextual proximity", "to": "machine learning", "value": 1.75}, {"from": "learning", "title": "contextual proximity", "to": "reasoning", "value": 2.25}, {"from": "learning a new class of concepts", "title": "contextual proximity", "to": "significantly fewer examples", "value": 0.5}, {"from": "learning a new class of concepts", "title": "contextual proximity", "to": "symbolic/connectionist debate", "value": 0.5}, {"from": "learning approaches based on continuous optimization", "title": "The results found in this paper apply to learning approaches based on continuous optimization, such as gradient descent and the Baum-Welch algorithm.", "to": "gradient descent and the Baum-Welch algorithm", "value": 1.0}, {"from": "learning each class of knowledge it uses to perform tasks", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "learning from situated, interactive tutorial instruction", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "learning hierarchies of new tasks and other domain knowledge from interactive natural language instructions", "title": "contextual proximity", "to": "situated explanation", "value": 0.5}, {"from": "learning programs", "title": "contextual proximity", "to": "logic programs with cut", "value": 0.5}, {"from": "learning recursive clauses", "title": "is a crucial problem since recursion is the basic program structure of logic programs", "to": "recursive clauses", "value": 1.0}, {"from": "learning system", "title": "In this approach, a learning system explores a space of possible heuristic methods for one well-suited to the eccentricities of the given domain and problem distribution.", "to": "space of possible heuristic methods", "value": 1.0}, {"from": "learning-apprentice software-agent", "title": "contextual proximity", "to": "performance system", "value": 0.5}, {"from": "learning-apprentice software-agent", "title": "contextual proximity", "to": "user interface", "value": 0.75}, {"from": "least generalization", "title": "contextual proximity", "to": "sets of clauses in each of the six ordered languages", "value": 0.5}, {"from": "legal reasoning example", "title": "A legal reasoning example illustrates the usefulness of the approach.", "to": "usefulness of the approach", "value": 1.0}, {"from": "lemmas", "title": "contextual proximity", "to": "proof attempt", "value": 0.75}, {"from": "lifeworld", "title": "contextual proximity", "to": "lifeworlds", "value": 0.75}, {"from": "likelihood of evidence", "title": "In addition to providing a tractable approximation, our mean field theory also yields a lower bound on the likelihood of evidence in sigmoid belief networks.,contextual proximity", "to": "mean field theory", "value": 1.75}, {"from": "likelihood of evidence", "title": "contextual proximity", "to": "sigmoid belief networks", "value": 0.5}, {"from": "likelihood ordering on worlds", "title": "contextual proximity", "to": "logic of relative likelihood", "value": 0.5}, {"from": "load balancing", "title": "We study the process of multi-agent reinforcement learning in the context of load balancing in a distributed system...", "to": "multi-agent reinforcement learning", "value": 1.0}, {"from": "local consistency", "title": "contextual proximity", "to": "root set", "value": 0.5}, {"from": "locally weighted regression", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "logic programs", "title": "This extension is for logic programs with two types of negation.", "to": "two types of negation", "value": 1.0}, {"from": "logical domain theories", "title": "contextual proximity", "to": "propositional and first-order domain theories", "value": 0.5}, {"from": "logical domain theories", "title": "contextual proximity", "to": "soundness and completeness", "value": 0.5}, {"from": "logical domain theories", "title": "contextual proximity", "to": "stability", "value": 0.5}, {"from": "logical domain theories", "title": "Our concern in this paper is to determine for which classes of logical domain theories, the theory patching problem is tractable.,contextual proximity", "to": "theory patching", "value": 3.0}, {"from": "logistic regression", "title": "contextual proximity", "to": "playing strengths", "value": 0.5}, {"from": "logistic regression", "title": "contextual proximity", "to": "quadratic discriminant function", "value": 0.5}, {"from": "logistic regression", "title": "contextual proximity", "to": "well-known statistical methods", "value": 0.5}, {"from": "logistic regression", "title": "contextual proximity", "to": "world-class Othello program", "value": 0.5}, {"from": "loglinear in the number of non-zero entries", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "long-run optimality", "title": "Our approach to long-run optimality in feedback structures is qualitative, distinguishing it from previous work in this area.", "to": "qualitative", "value": 1.0}, {"from": "low-acceptable program", "title": "contextual proximity", "to": "termination of general logic programs", "value": 0.75}, {"from": "low-acceptable program", "title": "The notions of low-, weakly up-, and up-acceptable programs are introduced to distinguish parts of the program based on whether or not their termination depends on the selection rule.", "to": "up-acceptable program", "value": 1.0}, {"from": "low-level membership values", "title": "combined through an and-or tree structure to give a final overall membership value", "to": "Gruff recognition system", "value": 1.0}, {"from": "machine architectures", "title": "Constructing agents with bounded optimality for a simple class of machine architectures in real-time environments", "to": "construct agents with bounded optimality", "value": 1.0}, {"from": "machine learning", "title": "contextual proximity", "to": "reasoning", "value": 0.75}, {"from": "machine learning algorithms", "title": "For many types of machine learning algorithms, one can compute the statistically optimal way to select training data.", "to": "optimal way to select training data", "value": 1.0}, {"from": "machine learning algorithms", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "machine learning component", "title": "The text mentions that the performance system uses learned information, which implies that there is a link between the performance system and the machine learning component.,contextual proximity", "to": "performance system", "value": 1.5}, {"from": "machine learning component", "title": "contextual proximity", "to": "user interface", "value": 0.75}, {"from": "machine learning datasets", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "machine learning method", "title": "contextual proximity", "to": "multiple input variables", "value": 0.5}, {"from": "machine learning method", "title": "contextual proximity", "to": "ordered disjunctive normal form (DNF)", "value": 1.0}, {"from": "machine learning method", "title": "contextual proximity", "to": "predicting the value of a real-valued function", "value": 0.5}, {"from": "machine learning method", "title": "contextual proximity", "to": "rule-based decision model", "value": 0.5}, {"from": "machine learning method", "title": "contextual proximity", "to": "search for similar cases", "value": 0.5}, {"from": "machine learning method", "title": "contextual proximity", "to": "similar cases", "value": 0.5}, {"from": "manually derived classification models already in the literature", "title": "contextual proximity", "to": "sentential sense", "value": 0.5}, {"from": "massively parallel SIMD architectures capable of handling hierarchical data structures", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "maximal generality", "title": "contextual proximity", "to": "single k-ary recursive constant-depth determinate clause", "value": 0.5}, {"from": "maximal generality", "title": "contextual proximity", "to": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "value": 0.5}, {"from": "mean field theory", "title": "contextual proximity", "to": "sigmoid belief networks", "value": 1.5}, {"from": "mean field theory", "title": "contextual proximity", "to": "tractable approximation", "value": 0.75}, {"from": "median search cost", "title": "In these cases, the easy-hard-easy pattern appears to be due to changes in the size of the minimal unsolvable subproblems, rather than changing numbers of solutions.,contextual proximity", "to": "search cost", "value": 1.75}, {"from": "merits", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "minimize memory use", "title": "contextual proximity", "to": "quick counting", "value": 0.5}, {"from": "minimize system production and operational costs", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "minimize system production and operational costs", "title": "The hardware platform, a special-purpose massively parallel system, has been chosen to minimize system production and operational costs.", "to": "special-purpose massively parallel system", "value": 1.0}, {"from": "minimum k", "title": "contextual proximity", "to": "stable models", "value": 0.5}, {"from": "misconception", "title": "Although there is still wide-spread belief that bidirectional heuristic search is afflicted by the problem of search frontiers passing each other, we demonstrate that this conjecture is wrong.", "to": "search frontiers passing each other", "value": 1.0}, {"from": "mixtures of Gaussians", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "mixtures of Gaussians and locally weighted regression", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "more accurate theory", "title": "forced to use that same representation may be bulky, cumbersome, and difficult to reach.", "to": "original representation", "value": 1.0}, {"from": "muALCQ", "title": "formulated correspondence to establish several properties of muALCQ, including decidability and computational complexity of reasoning", "to": "modal mu-calculus", "value": 1.0}, {"from": "multi-agent system", "title": "contextual proximity", "to": "partially controlled multi-agent system", "value": 0.75}, {"from": "multi-agent system", "title": "contextual proximity", "to": "uncontrollable agent", "value": 1.0}, {"from": "multiclass learning problems", "title": "contextual proximity", "to": "multiclass problems", "value": 1.0}, {"from": "multiclass learning problems", "title": "contextual proximity", "to": "overfitting avoidance techniques", "value": 1.0}, {"from": "multiclass learning problems", "title": "contextual proximity", "to": "particular classes", "value": 1.0}, {"from": "multiclass learning problems", "title": "contextual proximity", "to": "reliable class probability estimates", "value": 1.0}, {"from": "multiclass learning problems", "title": "contextual proximity", "to": "robustness", "value": 1.0}, {"from": "multiple input variables", "title": "contextual proximity", "to": "ordered disjunctive normal form (DNF)", "value": 0.5}, {"from": "multiresolution stretching process", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "network queries", "title": "contextual proximity", "to": "standard algorithms for exact inference", "value": 0.5}, {"from": "non-monotonic reasoning", "title": "The methodology for proving termination of general logic programs is applied to formalize and implement interesting problems in non-monotonic reasoning.,contextual proximity", "to": "termination of general logic programs", "value": 1.75}, {"from": "nondeterministic effects of actions, incomplete observability of state", "title": "contextual proximity", "to": "region observable POMDP", "value": 0.5}, {"from": "nonmonotonicity", "title": "contextual proximity", "to": "preferential logics", "value": 1.0}, {"from": "nonmonotonicity", "title": "Exist formulae that can always be safely added to the premises without destroying any consequences in nonmonotonic logic.,contextual proximity", "to": "safely added formulae", "value": 1.5}, {"from": "nonmonotonicity", "title": "contextual proximity", "to": "theorem provers", "value": 0.5}, {"from": "note taking", "title": "contextual proximity", "to": "performance system", "value": 0.5}, {"from": "note taking", "title": "contextual proximity", "to": "user interface", "value": 0.75}, {"from": "note taking agent", "title": "contextual proximity", "to": "performance system", "value": 0.5}, {"from": "note taking agent", "title": "contextual proximity", "to": "user interface", "value": 0.75}, {"from": "number of solutions", "title": "If the number of solutions is held fixed by the choice of problems, then increased pruning should lead to a monotonic decrease in search cost, according to existing theory.,contextual proximity", "to": "search cost", "value": 1.75}, {"from": "numeric operations", "title": "contextual proximity", "to": "standard algorithms for exact inference", "value": 0.5}, {"from": "on-line, real-world applications", "title": "contextual proximity", "to": "standard algorithms for exact inference", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "practicality of well-founded partial-order planners", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 1.0}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "pruning nonviable operator instances", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "pruning search", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "search control", "value": 1.0}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "speedups", "value": 1.0}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "spurious clobbering threats", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "techniques and test problems", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "well-founded partial-order planners", "value": 0.5}, {"from": "operator parameter domains", "title": "contextual proximity", "to": "zero commitment plan refinements", "value": 0.5}, {"from": "optimal data selection techniques", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "optimal way to select training data", "title": "contextual proximity", "to": "statistically optimal way to select training data", "value": 0.75}, {"from": "oracle", "title": "Provides additional information by informing the planning agent that current state is within a certain region.,contextual proximity", "to": "region observable POMDP", "value": 1.5}, {"from": "ordered disjunctive normal form (DNF)", "title": "contextual proximity", "to": "predicting the value of a real-valued function", "value": 0.5}, {"from": "ordered disjunctive normal form (DNF)", "title": "contextual proximity", "to": "rule-based decision model", "value": 0.5}, {"from": "ordered disjunctive normal form (DNF)", "title": "contextual proximity", "to": "search for similar cases", "value": 0.5}, {"from": "ordered disjunctive normal form (DNF)", "title": "contextual proximity", "to": "similar cases", "value": 0.5}, {"from": "original data", "title": "contextual proximity", "to": "representing structural concepts", "value": 0.5}, {"from": "original data", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 0.5}, {"from": "original data", "title": "contextual proximity", "to": "substructure discovery", "value": 1.5}, {"from": "original data", "title": "contextual proximity", "to": "two substructures", "value": 0.5}, {"from": "original template", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "overfitting avoidance techniques", "title": "and the application of overfitting avoidance techniques such as decision-tree pruning.", "to": "robustness", "value": 1.0}, {"from": "pac-learnability", "title": "contextual proximity", "to": "single k-ary recursive constant-depth determinate clause", "value": 0.5}, {"from": "pac-learnability", "title": "contextual proximity", "to": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "value": 0.5}, {"from": "partial SharedPlans", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "partial-order planning", "title": "The paper presents a comparative analysis of partial-order and total-order planning, focusing on two specific planners that can be directly compared. It highlights some subtle assumptions underlying the supposed efficiency of partial-order planning and shows that this superiority can depend critically upon the search strategy and the structure of the search space.", "to": "total-order planning", "value": 1.0}, {"from": "partially controlled multi-agent system", "title": "contextual proximity", "to": "reinforcement learner", "value": 0.75}, {"from": "partially controlled multi-agent system", "title": "Uncontrollable agents are not under the direct control of the designer within a partially controlled multi-agent system.,contextual proximity", "to": "uncontrollable agent", "value": 4.0}, {"from": "path consistency algorithm", "title": "contextual proximity", "to": "previously suggested reformulation", "value": 0.5}, {"from": "path consistency algorithm", "title": "contextual proximity", "to": "problems in molecular biology", "value": 0.5}, {"from": "path consistency algorithm", "title": "contextual proximity", "to": "temporal reasoning component", "value": 1.0}, {"from": "path consistency algorithm", "title": "contextual proximity", "to": "temporal reasoning system", "value": 0.5}, {"from": "perfect monitoring case", "title": "In the study of feedback structures in partially observable processes, the perfect monitoring case refers to environments where the agent is able to observe the previous state as part of his feedback, while in the imperfect monitoring case all that is available to the agent is the reward obtained.", "to": "imperfect monitoring case", "value": 1.0}, {"from": "performance system", "title": "contextual proximity", "to": "user interface", "value": 1.5}, {"from": "phrases", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "phrases", "title": "The algorithm replaces repeated phrases with a grammatical rule that generates the phrase.", "to": "repeated", "value": 1.0}, {"from": "pieces of information", "title": "contextual proximity", "to": "scattered throughout the text", "value": 0.5}, {"from": "pieces of information", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "pieces of information", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "pieces of information", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "plan adaptation", "title": "contextual proximity", "to": "plan refinement operators", "value": 1.0}, {"from": "plan adaptation", "title": "contextual proximity", "to": "systematicity", "value": 1.0}, {"from": "plan adaptation", "title": "contextual proximity", "to": "transformational planning", "value": 1.0}, {"from": "plan fragments", "title": "a set of plan fragments is employed in degrees of freedom analysis", "to": "specialized routines used in degrees of freedom analysis to change the configuration of a set of bodies to satisfy new constraints while preserving existing constraints", "value": 1.0}, {"from": "plateau search", "title": "describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search.", "to": "long plateau search", "value": 1.0}, {"from": "playing strengths", "title": "The playing strengths of resulting versions of a world-class Othello program are compared by means of tournaments as described in this article.", "to": "world-class Othello program", "value": 1.0}, {"from": "polynomial or NP-complete", "title": "We provide a complete classification of the satisfiability problem for all these subclasses, which we find to be either polynomial or NP-complete.", "to": "satisfiability problem for all subclasses", "value": 1.0}, {"from": "practical utility", "title": "this paper concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.", "to": "assessment of practical utility", "value": 1.0}, {"from": "practicality of well-founded partial-order planners", "title": "contextual proximity", "to": "preferring zero commitment plan refinements", "value": 0.5}, {"from": "practicality of well-founded partial-order planners", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "practicality of well-founded partial-order planners", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "preferential logics", "title": "contextual proximity", "to": "safely added formulae", "value": 0.5}, {"from": "preferential logics", "title": "contextual proximity", "to": "theorem provers", "value": 0.5}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "pruning nonviable operator instances", "value": 0.5}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "pruning search", "value": 0.5}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "search control", "value": 1.0}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "speedups", "value": 1.0}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "spurious clobbering threats", "value": 0.5}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "techniques and test problems", "value": 0.5}, {"from": "preferring zero commitment plan refinements", "title": "contextual proximity", "to": "well-founded partial-order planners", "value": 0.5}, {"from": "preferring zero commitment plan refinements", "title": "The author prefers \u0027zero commitment\u0027 (forced) plan refinements whenever possible during planning.,contextual proximity", "to": "zero commitment plan refinements", "value": 1.5}, {"from": "previous theory-guided systems", "title": "experiments in three domains show improvement over.", "to": "theory-guided constructive induction", "value": 1.0}, {"from": "previously suggested reformulation", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "problems in molecular biology", "title": "contextual proximity", "to": "temporal reasoning component", "value": 0.5}, {"from": "produces", "title": "SEQUITUR produces structure as a by-product.,contextual proximity", "to": "structure", "value": 1.5}, {"from": "propositional and first-order domain theories", "title": "contextual proximity", "to": "theory patching", "value": 1.0}, {"from": "pruning nonviable operator instances", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "pruning nonviable operator instances", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "pruning nonviable operator instances", "title": "During planning, parameter domains can be used to prune nonviable operator instances and to remove spurious clobbering threats.", "to": "spurious clobbering threats", "value": 1.0}, {"from": "pruning search", "title": "contextual proximity", "to": "search control", "value": 0.5}, {"from": "pruning search", "title": "contextual proximity", "to": "speedups", "value": 0.5}, {"from": "qualitative correlations among related data", "title": "contextual proximity", "to": "real spectra", "value": 0.5}, {"from": "quantum algorithm", "title": "exploiting the same aspects of problem structure as used by classical backtrack methods to avoid unproductive search choices.", "to": "classical backtrack methods", "value": 1.0}, {"from": "quantum parallelism", "title": "exploiting the same aspects of problem structure as used by classical backtrack methods to avoid", "to": "unproductive search choices", "value": 1.0}, {"from": "quick counting", "title": "contextual proximity", "to": "traditional direct counting approaches", "value": 0.5}, {"from": "real-time constraints", "title": "Universal ABO programs constructed no matter what real-time constraints are applied", "to": "universal ABO programs", "value": 1.0}, {"from": "real-time constraints imposed by moving vehicle applications", "title": "The main aim of this work is the development of a vision-based road detection system that can cope with the difficult real-time constraints imposed by moving vehicle applications.,contextual proximity", "to": "vision-based road detection system", "value": 1.5}, {"from": "recursive constant-depth determinate clause", "title": "contextual proximity", "to": "single k-ary recursive constant-depth determinate clause", "value": 0.5}, {"from": "recursive constant-depth determinate clause", "title": "contextual proximity", "to": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "value": 0.5}, {"from": "reduces", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "reinforcement", "title": "the work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement\".", "to": "resemblance to work in psychology", "value": 1.0}, {"from": "reinforcement learner", "title": "contextual proximity", "to": "uncontrollable agent", "value": 1.0}, {"from": "reinforcement learning", "title": "reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment.", "to": "learning through trial-and-error interactions with a dynamic environment", "value": 1.0}, {"from": "reorganizing the team", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "reorganizing the team", "title": "In STEAM, team members monitor the team\u0027s and individual members\u0027 performance, reorganizing the team as necessary.", "to": "team members\u0027", "value": 1.0}, {"from": "repeated", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "repeated game", "title": "In a model of an agent-environment interaction, the repeated game is an appropriate tool for modeling interactions with Nature\u0027s changing state.", "to": "Nature", "value": 1.0}, {"from": "representing structural concepts", "title": "contextual proximity", "to": "similar instances of a substructure", "value": 1.0}, {"from": "representing structural concepts", "title": "compresses original data,compresses original data,compresses original data,compresses original data,contextual proximity", "to": "substructure discovery", "value": 7.0}, {"from": "representing structural concepts", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "reusability", "title": "contextual proximity", "to": "team members", "value": 0.75}, {"from": "root set", "title": "contextual proximity", "to": "semantic properties", "value": 0.5}, {"from": "rule", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "scattered throughout the text", "title": "contextual proximity", "to": "second step", "value": 0.5}, {"from": "scattered throughout the text", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "scattered throughout the text", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "scheduling problems", "title": "Although most scheduling problems are NP-hard, domain specific techniques perform well in practice but are quite expensive to construct.", "to": "domain specific techniques", "value": 1.0}, {"from": "scheduling satellite communications", "title": "Using problem distributions based on actual mission requirements, our approach identifies strategies that not only decrease the amount of CPU time required to produce schedules, but also increase the percentage of problems that are solvable within computational resource limitations.", "to": "problem distributions based on actual mission requirements", "value": 1.0}, {"from": "score", "title": "when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate.", "to": "mean number of satisfied clauses", "value": 1.0}, {"from": "screening approach", "title": "contextual proximity", "to": "spontaneously spoken language", "value": 1.5}, {"from": "search control", "title": "contextual proximity", "to": "speedups", "value": 1.0}, {"from": "search control", "title": "contextual proximity", "to": "spurious clobbering threats", "value": 0.5}, {"from": "search control", "title": "contextual proximity", "to": "techniques and test problems", "value": 0.5}, {"from": "search control", "title": "contextual proximity", "to": "well-founded partial-order planners", "value": 0.5}, {"from": "search control", "title": "contextual proximity", "to": "zero commitment plan refinements", "value": 0.5}, {"from": "search cost", "title": "contextual proximity", "to": "search method", "value": 0.75}, {"from": "search for similar cases", "title": "The new technique can be extended to search efficiently for similar cases prior to approximating function values.", "to": "similar cases", "value": 1.0}, {"from": "second step", "title": "contextual proximity", "to": "simple pattern search", "value": 0.5}, {"from": "second step", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "semantic rather than structural information", "title": "cue phrases may be used in a sentential sense to convey semantic rather than structural information,contextual proximity", "to": "sentential sense", "value": 1.5}, {"from": "sequence", "title": "contextual proximity", "to": "structure", "value": 0.5}, {"from": "sequentiality between intervals", "title": "Two of the algebras can express the notion of sequentiality between intervals, being the first such algebras admitting both qualitative and metric time.", "to": "two algebras", "value": 1.0}, {"from": "sigmoid belief networks", "title": "contextual proximity", "to": "tractable approximation", "value": 0.5}, {"from": "similar instances of a substructure", "title": "contextual proximity", "to": "substructure discovery", "value": 3.0}, {"from": "similar instances of a substructure", "title": "contextual proximity", "to": "two substructures", "value": 1.0}, {"from": "simple pattern search", "title": "contextual proximity", "to": "unconstrained text", "value": 0.5}, {"from": "single k-ary recursive constant-depth determinate clause", "title": "contextual proximity", "to": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "value": 1.0}, {"from": "single k-ary recursive constant-depth determinate clause", "title": "is a more complex version of,contextual proximity", "to": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause", "value": 1.5}, {"from": "soundness and completeness", "title": "We also show how the concepts introduced can be used to determine the soundness and completeness of particular theory patching algorithms.,contextual proximity", "to": "theory patching", "value": 2.0}, {"from": "special-purpose massively parallel system", "title": "contextual proximity", "to": "vision-based road detection system", "value": 0.5}, {"from": "speedups", "title": "contextual proximity", "to": "spurious clobbering threats", "value": 0.5}, {"from": "speedups", "title": "contextual proximity", "to": "techniques and test problems", "value": 0.5}, {"from": "speedups", "title": "contextual proximity", "to": "well-founded partial-order planners", "value": 0.5}, {"from": "speedups", "title": "contextual proximity", "to": "zero commitment plan refinements", "value": 0.5}, {"from": "stability", "title": "contextual proximity", "to": "theory patching", "value": 1.0}, {"from": "stable models", "title": "contextual proximity", "to": "stratified knowledge base", "value": 0.5}, {"from": "standard, model-theoretic semantics for description logics", "title": "contextual proximity", "to": "subsumption algorithm", "value": 0.5}, {"from": "state selection strategy of Nature", "title": "In a model of an agent-environment interaction, the feedback/reward function is initially unknown and the agent does not form a prior probability on Nature\u0027s state selection strategy.", "to": "unknown", "value": 1.0}, {"from": "structure", "title": "contextual proximity", "to": "symbols", "value": 0.5}, {"from": "substructure discovery", "title": "contextual proximity", "to": "two substructures", "value": 3.0}, {"from": "task environment", "title": "Task environment presented by an agent\u0027s architecture and the constrained optimization problem it solves", "to": "constrained optimization problem", "value": 1.0}, {"from": "team members", "title": "contextual proximity", "to": "team members\u0027", "value": 0.75}, {"from": "team members", "title": "contextual proximity", "to": "teamwork", "value": 0.75}, {"from": "temporal reasoning component", "title": "contextual proximity", "to": "temporal reasoning system", "value": 0.5}, {"from": "termination of general logic programs", "title": "contextual proximity", "to": "up-acceptable program", "value": 0.75}, {"from": "topology", "title": "first principles about geometric bodies and topology are used to automatically synthesize plan fragments.", "to": "study of the properties that are preserved under continuous transformations (such as bending, stretching, or crumpling) while preserving the connectivity of a space", "value": 1.0}, {"from": "trading off exploration and exploitation", "title": "the central issues of reinforcement learning, including trading off exploration and exploitation, are discussed in this paper.", "to": "central issues of reinforcement learning", "value": 1.0}, {"from": "transition probability matrices", "title": "Sparse or deterministic transition probability matrices reduce the phenomenon of diffusion of context and credit, making it easier to learn long-term context for sequential data.", "to": "sparse or deterministic transition probability matrices", "value": 1.0}, {"from": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause", "title": "contextual proximity", "to": "two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause", "value": 0.5}, {"from": "well-founded conclusions", "title": "The well-founded conclusions of prioritized logic programs can be computed in polynomial time.", "to": "prioritized logic programs", "value": 1.0}, {"from": "well-founded semantics", "title": "In this extension of well-founded semantics for logic programs with two types of negation, information about preferences between rules can be expressed in the logical language and derived dynamically using a reserved predicate symbol and a naming technique. Conflicts among rules are resolved whenever possible on the basis of derived preference information.", "to": "preferences between rules", "value": 1.0}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>