node_1,node_2,edge,count,topic_name
existing backtracking methods,meaningful progress toward solving a search problem,"Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem.",4,Dynamic Backtracking
backtrack points,deeper in the search space,"In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.",4,Dynamic Backtracking
dependency-directed backtracking,useful control information,The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.,4,Dynamic Backtracking
Market price systems,Mechanisms for decentralized decision making,"Under certain conditions, market price systems provide effective decentralization of decision making with minimal communication overhead. This is a well-understood class of mechanisms.",4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Distributed problem solving,"In a market-oriented programming approach to distributed problem solving, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy.",4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Artificial economy,We compute the competitive equilibrium of an artificial economy to derive the activities and resource allocations for a set of computational agents in market-oriented programming approach.,4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Computational agents,"In a market-oriented programming approach, we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy.",4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Computational market structures,WALRAS provides basic constructs for defining computational market structures.,4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Price equilibria,WALRAS provides protocols for deriving their corresponding price equilibria.,4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Artificial economy,Competitive equilibrium,We compute the competitive equilibrium of an artificial economy to derive the activities and resource allocations for a set of computational agents.,4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Competitive equilibrium,Activities and resource allocations,"By computing the competitive equilibrium of an artificial economy, we can derive the activities and resource allocations for a set of computational agents.",4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Multicommodity flow problem,"In a particular realization of this approach for a form of multicommodity flow problem,",4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Efficient distributed resource allocation,We see that careful construction of the decision process according to economic principles can lead to efficient distributed resource allocation.,4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
Market price systems,Behavior analysis,The behavior of the system can be meaningfully analyzed in economic terms.,4,A Market-Oriented Programming Environment and its Application to   Distributed Multicommodity Flow Problems
GSAT,propositional satisfiability,GSAT is an approximation procedure for propositional satisfiability.,4,An Empirical Analysis of Search in GSAT
hill-climbing,greedy,GSAT performs greedy hill-climbing on the number of satisfied clauses in a truth assignment.,4,An Empirical Analysis of Search in GSAT
score,mean number of satisfied clauses,"when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate.",4,An Empirical Analysis of Search in GSAT
branching rate,mean branching rate,"when applied to randomly generated 3SAT problems, there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate.",4,An Empirical Analysis of Search in GSAT
hill-climbing phase,rapid hill-climbing,describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search.,4,An Empirical Analysis of Search in GSAT
plateau search,long plateau search,describe in detail the two phases of search: rapid hill-climbing followed by a long plateau search.,4,An Empirical Analysis of Search in GSAT
gradient,average gradient,conjecture that both the average score and average branching rate decay exponentially during plateau search.,4,An Empirical Analysis of Search in GSAT
learning programs,logic programs with cut,"The paper investigates the difficulties of learning programs with cut, as it is a natural and reasonable approach for programs that normally use cut. However, current induction techniques should probably be restricted to purely declarative logic languages due to the difficulties caused by intensional evaluation.",4,The Difficulties of Learning Logic Programs with Cut
learning programs,base program,"The paper proposes a scheme of generating a candidate base program that covers positive examples, which can then be made consistent by inserting cut where appropriate.",4,The Difficulties of Learning Logic Programs with Cut
candidate base program,consistency,The paper investigates the difficulties caused by intensional evaluation in making a candidate base program consistent by inserting cut where appropriate.,4,The Difficulties of Learning Logic Programs with Cut
extensional evaluation method,clauses containing cut,"Clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems, due to their procedural meaning.",4,The Difficulties of Learning Logic Programs with Cut
note taking,computer,"The text mentions that recording information on a computer is less efficient but more powerful than doing it on paper, indicating that note taking and computers are related concepts.",4,Software Agents: Completing Patterns and Constructing User Interfaces
note taking agent,user interface,"The text describes a new note taking software with an agent that acts for the user and constructs a custom user interface, implying that there is a relationship between the note taking agent and the user interface.",4,Software Agents: Completing Patterns and Constructing User Interfaces
agent,learning-apprentice software-agent,"The text refers to the note taking agent as a learning-apprentice software-agent, suggesting that there is a connection between the two terms.",4,Software Agents: Completing Patterns and Constructing User Interfaces
performance system,user interface,"The text explains that the performance system uses learned information to generate completion strings and construct a user interface, implying that there is a relationship between the performance system and the user interface.",4,Software Agents: Completing Patterns and Constructing User Interfaces
performance system,machine learning component,"The text mentions that the performance system uses learned information, which implies that there is a link between the performance system and the machine learning component.",4,Software Agents: Completing Patterns and Constructing User Interfaces
user interface,"custom, button-box user interface","The text describes how the system constructs a custom user interface on request, indicating that there is a connection between the user interface and the custom, button-box user interface.",4,Software Agents: Completing Patterns and Constructing User Interfaces
TKRS,knowledge base,A TKRS is a tool used for designing and using knowledge bases.,4,Decidable Reasoning in Terminological Knowledge Representation Systems
terminological language,concept language,"TKRSs make use of terminological languages, which are also called concept languages.",4,Decidable Reasoning in Terminological Knowledge Representation Systems
ALCNR,highly expressive terminological language,"The capabilities of this TKRS go beyond those of presently available ones because it uses a highly expressive terminological language called ALCNR, which includes general complements of concepts, number restrictions, and role conjunction.",4,Decidable Reasoning in Terminological Knowledge Representation Systems
inclusion statements,general concepts,"This TKRS allows to express inclusion statements between general concepts, which is often required in practical applications.",4,Decidable Reasoning in Terminological Knowledge Representation Systems
terminological cycles,inclusion statements,Terminological cycles are a particular case of inclusion statements between general concepts.,4,Decidable Reasoning in Terminological Knowledge Representation Systems
desirable TKRS-deduction services,ALCNR-knowledge bases,"A number of desirable TKRS-deduction services, like satisfiability, subsumption, and instance checking, are decidable for reasoning in ALCNR-knowledge bases.",4,Decidable Reasoning in Terminological Knowledge Representation Systems
constraint systems,calculus,Our calculus extends the general technique of constraint systems for reasoning in ALCNR-knowledge bases.,4,Decidable Reasoning in Terminological Knowledge Representation Systems
formalism,dynamic environments,A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments.,4,Teleo-Reactive Programs for Agent Control
autonomous agents,formalism,A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments.,4,Teleo-Reactive Programs for Agent Control
dynamic environments,autonomous agents,A formalism is presented for computing and organizing actions for autonomous agents in dynamic environments.,4,Teleo-Reactive Programs for Agent Control
teleo-reactive (T-R) programs,continuous computation,We introduce the notion of teleo-reactive (T-R) programs whose execution entails the construction of circuitry for the continuous computation of the parameters and conditions on which agent action is based.,4,Teleo-Reactive Programs for Agent Control
T-R programs,compact circuitry,"In addition to continuous feedback, T-R programs support parameter binding and recursion. A primary difference between T-R programs and many other circuit-based systems is that the circuitry of T-R programs is more compact;",4,Teleo-Reactive Programs for Agent Control
T-R programs,run time construction,it does not have to anticipate all the contingencies that might arise over all possible runs.,4,Teleo-Reactive Programs for Agent Control
T-R programs,intuitive and easy to write,T-R programs are written in a form that is compatible with automatic planning and learning methods. We briefly describe some experimental applications of T-R programs in the control of simulated and actual mobile robots.,4,Teleo-Reactive Programs for Agent Control
learning,acquisition,"Seemingly minor aspect of language acquisition is learning, which has generated heated debates since 1986.",4,Learning the Past Tense of English Verbs: The Symbolic Pattern   Associator vs. Connectionist Models
English verbs,past tense,The past tense of English verbs is a topic for testing the adequacy of cognitive modeling.,4,Learning the Past Tense of English Verbs: The Symbolic Pattern   Associator vs. Connectionist Models
ANNs,SPA,"Several artificial neural networks (ANNs) have been implemented, and a challenge for better symbolic models has been posed. In this paper, we present a general-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree learning algorithm ID3.",4,Learning the Past Tense of English Verbs: The Symbolic Pattern   Associator vs. Connectionist Models
head-to-head,comparisons,We conduct extensive head-to-head comparisons on the generalization ability between ANN models and the SPA under different representations.,4,Learning the Past Tense of English Verbs: The Symbolic Pattern   Associator vs. Connectionist Models
better symbolic models,ANN models,"We conclude that the SPA generalizes the past tense of unseen verbs better than ANN models by a wide margin,",4,Learning the Past Tense of English Verbs: The Symbolic Pattern   Associator vs. Connectionist Models
decision-tree learning algorithms,default strategy,we discuss a new default strategy for decision-tree learning algorithms.,4,Learning the Past Tense of English Verbs: The Symbolic Pattern   Associator vs. Connectionist Models
substructure discovery,discovering knowledge in structural data,essential component,4,Substructure Discovery Using Minimum Description Length and Background   Knowledge
substructure discovery,representing structural concepts,compresses original data,4,Substructure Discovery Using Minimum Description Length and Background   Knowledge
substructure discovery,hierarchical description,multiple passes of SUBDUE,4,Substructure Discovery Using Minimum Description Length and Background   Knowledge
inexact graph match,similar instances of a substructure,IDENTIFIES,4,Substructure Discovery Using Minimum Description Length and Background   Knowledge
approximate measure of closeness,two substructures,finds an approximate measure of closeness,4,Substructure Discovery Using Minimum Description Length and Background   Knowledge
background knowledge,guides the search towards more appropriate substructures,used by SUBDUE,4,Substructure Discovery Using Minimum Description Length and Background   Knowledge
substructure discovery,discovering knowledge in structural data,essential component,4,Bias-Driven Revision of Logical Domain Theories
substructure discovery,representing structural concepts,compresses original data,4,Bias-Driven Revision of Logical Domain Theories
substructure discovery,hierarchical description,multiple passes of SUBDUE,4,Bias-Driven Revision of Logical Domain Theories
graph match,similar instances of a substructure,IDENTIFIES,4,Bias-Driven Revision of Logical Domain Theories
approximate measure of closeness,two substructures,finds an approximate measure of closeness,4,Bias-Driven Revision of Logical Domain Theories
background knowledge,guides the search towards more appropriate substructures,used by SUBDUE,4,Bias-Driven Revision of Logical Domain Theories
graph,database,represents,4,Bias-Driven Revision of Logical Domain Theories
data,original data,compresses,4,Bias-Driven Revision of Logical Domain Theories
substructure discovery,discovering knowledge in structural data,essential component,4,Exploring the Decision Forest: An Empirical Investigation of Occam's   Razor in Decision Tree Induction
substructure discovery,representing structural concepts,compresses original data,4,Exploring the Decision Forest: An Empirical Investigation of Occam's   Razor in Decision Tree Induction
substructure discovery,hierarchical description,multiple passes of SUBDUE,4,Exploring the Decision Forest: An Empirical Investigation of Occam's   Razor in Decision Tree Induction
inexact graph match,similar instances of a substructure,IDENTIFIES,4,Exploring the Decision Forest: An Empirical Investigation of Occam's   Razor in Decision Tree Induction
approximate measure of closeness,two substructures,finds an approximate measure of closeness,4,Exploring the Decision Forest: An Empirical Investigation of Occam's   Razor in Decision Tree Induction
background knowledge,guides the search towards more appropriate substructures,used by SUBDUE,4,Exploring the Decision Forest: An Empirical Investigation of Occam's   Razor in Decision Tree Induction
substructure discovery,discovering knowledge in structural data,essential component,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
substructure discovery,representing structural concepts,compresses original data,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
substructure discovery,hierarchical description,multiple passes of SUBDUE,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
graph match,similar instances of a substructure,IDENTIFIES,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
approximate measure of closeness,two substructures,finds an approximate measure of closeness,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
background knowledge,guides the search towards more appropriate substructures,used by SUBDUE,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
graph,database,represents,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
data,original data,compresses,4,A Semantics and Complete Algorithm for Subsumption in the CLASSIC   Description Logic
Theory revision problem,Domain theory,Theory revision problem involves modifying a domain theory to address its deficiencies as revealed by examples.,4,Applying GSAT to Non-Clausal Formulas
Deficient domain theory,Examples,"Examples expose inaccuracies in the domain theory, leading to the need for revision.",4,Applying GSAT to Non-Clausal Formulas
Propositional domain theories,PTR,PTR is an approach to theory revision for propositional domain theories.,4,Applying GSAT to Non-Clausal Formulas
PTR,Probabilities,PTR uses probabilities associated with domain theory elements to track the flow of proof through the theory.,4,Applying GSAT to Non-Clausal Formulas
Ptr,Flawed elements,PTR efficiently locates and repairs flawed elements of the theory.,4,Applying GSAT to Non-Clausal Formulas
Ptr,Correctly classifies,PTR converges to a theory that correctly classifies all examples.,4,Applying GSAT to Non-Clausal Formulas
smaller consistent decision trees,accuracy of individual trees,"for many of the problems investigated, smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees.",4,Random Worlds and Maximum Entropy
consistent decision trees,training data,all decision trees consistent with the training data are constructed.,4,Random Worlds and Maximum Entropy
accuracy of individual trees,test data,individual trees on test data.,4,Random Worlds and Maximum Entropy
description logics,CLASSIC,CLASSIC is a description logic-based knowledge representation system that is being used in practical applications.,4,Pattern Matching and Discourse Processing in Information Extraction from   Japanese Text
individuals,CLASSIC descriptions,"In order to deal efficiently with individuals in CLASSIC descriptions, the developers have had to use an algorithm that is incomplete with respect to the standard, model-theoretic semantics for description logics.",4,Pattern Matching and Discourse Processing in Information Extraction from   Japanese Text
description graphs,subsumption algorithm,"The soundness and completeness of the polynomial-time subsumption algorithm is established using description graphs, which are an abstracted version of the implementation structures used in CLASSIC, and are of independent interest.",4,Pattern Matching and Discourse Processing in Information Extraction from   Japanese Text
"standard, model-theoretic semantics for description logics",algorithm that is incomplete with respect to,"The developers had to use an algorithm that is incomplete with respect to the standard, model-theoretic semantics for description logics.",4,Pattern Matching and Discourse Processing in Information Extraction from   Japanese Text
description graphs,"standard, model-theoretic semantics for description logics","The soundness and completeness of the polynomial-time subsumption algorithm is established using description graphs, which are an abstracted version of the implementation structures used in CLASSIC, and are of independent interest. This variant semantics for descriptions with respect to which the current implementation is complete, and which can be independently motivated.",4,Pattern Matching and Discourse Processing in Information Extraction from   Japanese Text
GSAT,CNF conversion,"In this paper, we propose a way to modify GSAT to apply it to non-clausal formulas by using a particular 'score' function that calculates the number of false clauses in the CNF conversion of a formula under a given truth assignment. This value is computed in linear time without constructing the entire CNF conversion.",4,A System for Induction of Oblique Decision Trees
GSAT,Non-clausal formulas,Our proposed methodology applies to most of the variants of GSAT suggested till now.,4,A System for Induction of Oblique Decision Trees
formula Phi,knowledge base KB,"implication relationship, as the degree of belief for Phi is computed given KB using the random-worlds method",4,On Planning while Learning
N individuals,"all possible worlds with domain {1,...,N}","instantiation relationship, as all possible worlds are considered for computing the degree of belief given KB and N",4,On Planning while Learning
constants and unary predicates,vocabulary underlying Phi and KB,"limitation relationship, as the random-worlds method is restricted to this type of vocabulary",4,On Planning while Learning
entropy,each world,"association relationship, as entropy can be naturally associated with each world when Phi and KB use constants and unary predicates only",4,On Planning while Learning
information extraction,unconstrained text,Information extraction is the task of automatically picking up information of interest from an unconstrained text.,4,Wrap-Up: a Trainable Discourse Module for Information Extraction
information,interest,Information of interest is usually extracted in two steps.,4,Wrap-Up: a Trainable Discourse Module for Information Extraction
pieces of information,scattered throughout the text,"Pieces of information scattered throughout the text; second, discourse processing merges coreferential information to generate the output.",4,Wrap-Up: a Trainable Discourse Module for Information Extraction
key word search,simple pattern search,A key word search or simple pattern search can achieve this purpose.,4,Wrap-Up: a Trainable Discourse Module for Information Extraction
first step,second step,"In the first step, pieces of information are locally identified without recognizing any relationships among them.",4,Wrap-Up: a Trainable Discourse Module for Information Extraction
human performance,high level of system performance,Evaluation results show a high level of system performance which approaches human performance.,4,Wrap-Up: a Trainable Discourse Module for Information Extraction
Japanese information extraction system,pattern matcher and discourse processor,This paper reports on a Japanese information extraction system that merges information using a pattern matcher and discourse processor.,4,Operations for Learning with Graphical Models
information extraction,unconstrained text,Information extraction is the task of automatically picking up information of interest from an unconstrained text.,4,Total-Order and Partial-Order Planning: A Comparative Analysis
information,interest,Information of interest is usually extracted in two steps.,4,Total-Order and Partial-Order Planning: A Comparative Analysis
pieces of information,scattered throughout the text,"Pieces of information scattered throughout the text; second, discourse processing merges coreferential information to generate the output.",4,Total-Order and Partial-Order Planning: A Comparative Analysis
key word search,simple pattern search,A key word search or simple pattern search can achieve this purpose.,4,Total-Order and Partial-Order Planning: A Comparative Analysis
first step,second step,"In the first step, pieces of information are locally identified without recognizing any relationships among them.",4,Total-Order and Partial-Order Planning: A Comparative Analysis
human performance,high level of system performance,Evaluation results show a high level of system performance which approaches human performance.,4,Total-Order and Partial-Order Planning: A Comparative Analysis
Japanese information extraction system,pattern matcher and discourse processor,This paper reports on a Japanese information extraction system that merges information using a pattern matcher and discourse processor.,4,Solving Multiclass Learning Problems via Error-Correcting Output Codes
oblique decision tree methods,domains in which the attributes are numeric,"Oblique decision tree methods are tuned especially for domains in which the attributes are numeric, although they can be adapted to symbolic or mixed symbolic/numeric attributes.",4,A Domain-Independent Algorithm for Plan Adaptation
OC1,oblique split (in the form of a hyperplane),"This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree.",4,A Domain-Independent Algorithm for Plan Adaptation
OC1,smaller and more accurate than their axis-parallel counterparts,"We present extensive empirical studies, using both real and artificial data, that analyze OC1's ability to construct oblique trees that are smaller and more accurate than their axis-parallel counterparts.",4,A Domain-Independent Algorithm for Plan Adaptation
Planning while Learning,Goal to achieve,"In a partially known environment, the agent learns and adapts its plans to achieve the given goal.",4,Truncating Temporal Differences: On the Efficient Implementation of   TD(lambda) for Reinforcement Learning
Plan-design process,Tractability,"Discussion on the tractability of various plan-design processes for Planning while Learning systems, as some classes are computationally expensive.",4,Truncating Temporal Differences: On the Efficient Implementation of   TD(lambda) for Reinforcement Learning
Plan-design process,Algorithmic,Showing that finding a plan algorithmically is intractable even for simple classes of systems.,4,Truncating Temporal Differences: On the Efficient Implementation of   TD(lambda) for Reinforcement Learning
Off-line plan-design process,Role,"Emphasizing the importance and efficiency of off-line plan-design processes, especially during verification or projection in most natural cases.",4,Truncating Temporal Differences: On the Efficient Implementation of   TD(lambda) for Reinforcement Learning
information extraction (IE) processing,higher level IE processing,has a subset relationship,4,Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic   Decision Tree Induction Algorithm
machine learning,acquires knowledge for some of the higher level IE processing,used to acquire knowledge,4,Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic   Decision Tree Induction Algorithm
Unrestricted text,vast amounts of,associated with,4,Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic   Decision Tree Induction Algorithm
IE discourse component,Wrap-Up,identifies as,4,Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic   Decision Tree Induction Algorithm
IE discourse component,partially trainable discourse module,performance equals that of,4,Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic   Decision Tree Induction Algorithm
graphical models,Bayesian networks,"Graphical models include Bayesian networks, which are directed graphs representing a Markov chain.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
graphical models,directed graphs representing a Markov chain,"Directed graphs representing a Markov chain are a type of graphical model, specifically Bayesian networks.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
graphical models,undirected networks representing a Markov field,Graphical models also include undirected networks representing a Markov field.,4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
plates,graphical models,Plates are an extension of graphical models to model data analysis and empirical learning.,4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
Gibbs sampling,graphical framework,"Two standard algorithm schemas for learning, Gibbs sampling and the expectation maximization algorithm, are reviewed in a graphical framework.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
expectation maximization algorithm,graphical framework,"Two standard algorithm schemas for learning, Gibbs sampling and the expectation maximization algorithm, are reviewed in a graphical framework.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
linear regression,graphical specification,"Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification, including versions of linear regression.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
Gaussian Bayesian networks,learning Gaussian and discrete Bayesian networks from data,"Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification, including learning Gaussian and discrete Bayesian networks from data.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
feed-forward networks,graphical specification,"Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification, including techniques for feed-forward networks.",4,Rerepresenting and Restructuring Domain Theories: A Constructive   Induction Approach
partial-order planning,total-order planning,"The paper presents a comparative analysis of partial-order and total-order planning, focusing on two specific planners that can be directly compared. It highlights some subtle assumptions underlying the supposed efficiency of partial-order planning and shows that this superiority can depend critically upon the search strategy and the structure of the search space.",4,Using Pivot Consistency to Decompose and Solve Functional CSPs
multiclass learning problems,k classes,"Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k &gt 2 values, which are referred to as k 'classes'.",4,Adaptive Load Balancing: A Study in Multi-Agent Learning
multiclass learning problems,direct application of multiclass algorithms,Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART.,4,Adaptive Load Balancing: A Study in Multi-Agent Learning
binary concept learning algorithms,k classes,Another approach to multiclass learning problems is to apply binary concept learning algorithms to learn individual binary functions for each of the k classes.,4,Adaptive Load Balancing: A Study in Multi-Agent Learning
error-correcting codes,distributed output representation,This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation.,4,Adaptive Load Balancing: A Study in Multi-Agent Learning
C4.5 and backpropagation,distributed output representation,We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks.,4,Adaptive Load Balancing: A Study in Multi-Agent Learning
multiclass learning problems,changes in training sample size,"This approach is robust with respect to changes in the size of the training sample,",4,Adaptive Load Balancing: A Study in Multi-Agent Learning
distributed output representations,particular classes,"The assignment of distributed representations to particular classes,",4,Adaptive Load Balancing: A Study in Multi-Agent Learning
overfitting avoidance techniques,robustness,and the application of overfitting avoidance techniques such as decision-tree pruning.,4,Adaptive Load Balancing: A Study in Multi-Agent Learning
error-correcting output codes,multiclass problems,"Finally, we show that---like the other methods---the error-correcting code technique can provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.",4,Adaptive Load Balancing: A Study in Multi-Agent Learning
multiclass learning problems,reliable class probability estimates,"Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems and can also provide reliable class probability estimates.",4,Adaptive Load Balancing: A Study in Multi-Agent Learning
plan adaptation,plan refinement operators,"Plan adaptation involves modifying or repairing an old plan to solve a new problem, and can apply both the same refinement operators available to a generative planner as well as retract constraints and steps from the plan. This is part of a domain-independent algorithm for plan adaptation, which searches a graph of partial plans in a sound, complete, and systematic way.",4,Provably Bounded-Optimal Agents
plan adaptation,completeness,The completeness of our algorithm ensures that the adaptation algorithm will eventually search the entire plan graph without redundantly searching any parts of it.,4,Provably Bounded-Optimal Agents
plan adaptation,systematicity,The systematicity of our algorithm ensures that it will do so in a way that is not redundant.,4,Provably Bounded-Optimal Agents
transformational planning,case-based planning,"Both transformational planning and case-based planning involve a process known as plan adaptation, which modifies or repairs an old plan to solve a new problem.",4,Provably Bounded-Optimal Agents
plan adaptation,graph of partial plans,"Plan adaptation involves searching a graph of partial plans, starting at the root and moving from node to node using plan-refinement operators.",4,Provably Bounded-Optimal Agents
Temporal difference methods,Multi-step prediction problems,TD methods are used to learn predictions in multi-step prediction problems.,4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
TD methods,Reinforcement learning algorithms,"Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learning.",4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
Lambda,TD methods,"Currently the most important application of these methods is to temporal credit assignment in reinforcement learning algorithms optimizing the discounted sum of rewards, parameterized by a recency factor lambda.",4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
Truncated Temporal Differences (TTD),TD(lambda),"The TTD procedure is proposed as an alternative to the traditional approach, based on eligibility traces, that suffers from both inefficiency and lack of generality.",4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
TTD,Arbitrary lambda,The TTD procedure can be used with arbitrary function representation methods and requires very little computation per action.,4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
Lambda &gt 0,TTD,Using lambda > 0 with the TTD procedure allows one to obtain a significant learning speedup at essentially the same cost as usual TD(0) learning.,4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
Reinforcement learning algorithms,Discounted sum of rewards,TD methods are used to learn predictions in reinforcement learning algorithms optimizing the discounted sum of rewards.,4,Pac-Learning Recursive Logic Programs: Efficient Algorithms
ICET,cost-sensitive classification,ICET is a new algorithm for cost-sensitive classification introduced in this paper. Cost-sensitive classification considers both the costs of tests and classification errors while classifying.,4,Pac-learning Recursive Logic Programs: Negative Results
ICET,genetic algorithm,ICET uses a genetic algorithm to evolve a population of biases for decision tree induction in cost-sensitive classification.,4,Pac-learning Recursive Logic Programs: Negative Results
ICET,decision tree,"In ICET, the fitness function of the genetic algorithm is the average cost of classification using the decision tree, including both test and classification error costs.",4,Pac-learning Recursive Logic Programs: Negative Results
ICET,five real-world medical datasets,ICET is empirically evaluated on five real-world medical datasets in comparison to other cost-sensitive classification algorithms.,4,Pac-learning Recursive Logic Programs: Negative Results
EG2,ICET,"In a set of experiments, ICET is compared with three other algorithms for cost-sensitive classification - EG2, CS-ID3, and IDX, as well as C4.5 which classifies without regard to cost.",4,Pac-learning Recursive Logic Programs: Negative Results
theory revision,inductive learning,integrates by combining training examples with a coarse domain theory to produce a more accurate theory.,4,FLECS: Planning with a Flexible Commitment Strategy
initial theory,improved theory,representation language appropriate for the initial theory may be inappropriate for an improved theory.,4,FLECS: Planning with a Flexible Commitment Strategy
original representation,more accurate theory,"forced to use that same representation may be bulky, cumbersome, and difficult to reach.",4,FLECS: Planning with a Flexible Commitment Strategy
initial theory,fine-tuned theory,"a more accurate theory forced to use that same representation may be bulky, cumbersome, and difficult to reach.",4,FLECS: Planning with a Flexible Commitment Strategy
coarse domain theory,fine-tuned theory,a theory structure suitable for a coarse domain theory may be insufficient for a fine-tuned theory.,4,FLECS: Planning with a Flexible Commitment Strategy
"small, local changes to a theory",complex structural alterations that may be required,have limited value for accomplishing.,4,FLECS: Planning with a Flexible Commitment Strategy
theory-guided constructive induction,previous theory-guided systems,experiments in three domains show improvement over.,4,FLECS: Planning with a Flexible Commitment Strategy
functional CSPs,local consistency,"The paper proposes a new decomposition method for functional CSPs that benefits from both semantic properties of functional constraints and structural properties of the network, as well as introduces a new local consistency called pivot consistency. Pivot consistency is a weak form of path consistency and can be achieved in O(n^2d^2) complexity, which is faster than the O(n^3d^3) complexity for path consistency.",4,Induction of First-Order Decision Lists: Results on Learning the Past   Tense of English Verbs
functional CSPs,root set,The paper introduces a particular subset of variables called a root set that is characterized in the context of solving functional CSPs by combining semantic properties of functional constraints and structural properties of the network.,4,Induction of First-Order Decision Lists: Results on Learning the Past   Tense of English Verbs
consistent instantiation,root set,"The paper shows that any consistent instantiation of the root set can be linearly extended to a solution, leading to the presentation of the new method for solving functional CSPs by decomposing.",4,Induction of First-Order Decision Lists: Results on Learning the Past   Tense of English Verbs
semantic properties,functional constraints,The paper proposes a decomposition method that takes into account semantic properties of functional constraints (not bijective constraints) in solving functional CSPs.,4,Induction of First-Order Decision Lists: Results on Learning the Past   Tense of English Verbs
functional CSPs,existing solutions,The paper shows under some conditions that the existence of solutions can be guaranteed for functional CSPs by combining semantic properties of functional constraints and structural properties of the network.,4,Induction of First-Order Decision Lists: Results on Learning the Past   Tense of English Verbs
multi-agent reinforcement learning,load balancing,We study the process of multi-agent reinforcement learning in the context of load balancing in a distributed system...,4,Building and Refining Abstract Planning Cases by Change of   Representation Language
distributed system,central coordination,without use of either central coordination or explicit communication...,4,Building and Refining Abstract Planning Cases by Change of   Representation Language
adaptive load balancing,stochastic nature,important features of which are its stochastic nature and the purely local information available to individual agents.,4,Building and Refining Abstract Planning Cases by Change of   Representation Language
individual agents,purely local information,available to individual agents.,4,Building and Refining Abstract Planning Cases by Change of   Representation Language
basic adaptive behavior parameters,system efficiency,"We first define a precise framework in which to study adaptive load balancing, important features of which are its stochastic nature and the purely local information available to individual agents. Given this framework, we show illuminating results on the interplay between basic adaptive behavior parameters and their effect on system efficiency.",4,Building and Refining Abstract Planning Cases by Change of   Representation Language
heterogeneous populations,adaptive load balancing,"We then investigate the properties of adaptive load balancing in heterogeneous populations,",4,Building and Refining Abstract Planning Cases by Change of   Representation Language
exploration vs. exploitation,heterogeneous populations,and address the issue of exploration vs. exploitation in that context.,4,Building and Refining Abstract Planning Cases by Change of   Representation Language
communication,naive use of communication,"Finally, we show that naive use of communication may not improve, and might even harm system efficiency.",4,Building and Refining Abstract Planning Cases by Change of   Representation Language
artificial intelligence,perfect rationality,Theoretical foundation of artificial intelligence centered around perfect rationality,4,Using Qualitative Hypotheses to Identify Inaccurate Data
intelligent systems,desired property,Intelligent systems with a desired property as per the theoretical foundation,4,Using Qualitative Hypotheses to Identify Inaccurate Data
bounded optimality,property proposed instead of perfect rationality,Bounded optimality proposed instead of perfect rationality as an alternative theoretical foundation for AI,4,Using Qualitative Hypotheses to Identify Inaccurate Data
agent,program,Agent's program is a solution to the constrained optimization problem presented by its architecture and task environment,4,Using Qualitative Hypotheses to Identify Inaccurate Data
machine architectures,construct agents with bounded optimality,Constructing agents with bounded optimality for a simple class of machine architectures in real-time environments,4,Using Qualitative Hypotheses to Identify Inaccurate Data
real-time constraints,universal ABO programs,Universal ABO programs constructed no matter what real-time constraints are applied,4,Using Qualitative Hypotheses to Identify Inaccurate Data
task environment,constrained optimization problem,Task environment presented by an agent's architecture and the constrained optimization problem it solves,4,Using Qualitative Hypotheses to Identify Inaccurate Data
classical complexity theory,asymptotic bounded optimality (ABO),Generalizing the notion of optimality in classical complexity theory through asymptotic bounded optimality,4,Using Qualitative Hypotheses to Identify Inaccurate Data
recursive constant-depth determinate clause,single k-ary recursive constant-depth determinate clause,is a special case of,4,An Integrated Framework for Learning and Reasoning
two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive clause,single k-ary recursive constant-depth determinate clause,is a more complex version of,4,An Integrated Framework for Learning and Reasoning
pac-learnability,two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause,is a learning algorithm for,4,An Integrated Framework for Learning and Reasoning
maximal generality,two-clause programs consisting of one learnable recursive clause and one constant-depth determinant non-recursive clause,is a property that makes the learning problem computationally difficult for,4,An Integrated Framework for Learning and Reasoning
programs with an unbounded number of constant-depth linear recursive clauses,cryptographically hard to learn in Valiant's model of pac-learnability,The class of programs with an unbounded number of constant-depth linear recursive clauses is cryptographically hard to learn in Valiant's model of pac-learnability.,4,Diffusion of Context and Credit Information in Markovian Models
programs with one constant-depth determinate clause containing an unbounded number of recursive calls,cryptographically hard to learn in Valiant's model of pac-learnability,The class of programs with one constant-depth determinate clause containing an unbounded number of recursive calls is cryptographically hard to learn in Valiant's model of pac-learnability.,4,Diffusion of Context and Credit Information in Markovian Models
programs with one linear recursive clause of constant locality,cryptographically hard to learn in Valiant's model of pac-learnability,The class of programs with one linear recursive clause of constant locality is cryptographically hard to learn in Valiant's model of pac-learnability.,4,Diffusion of Context and Credit Information in Markovian Models
learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause,as hard as learning boolean DNF,Learning a constant-depth determinate program with either two linear recursive clauses or one linear recursive clause and one non-recursive clause is as hard as learning boolean DNF.,4,Diffusion of Context and Credit Information in Markovian Models
least-commitment planners,difficult goal interactions,There has been evidence that least-commitment planners can efficiently handle planning problems involving difficult goal interactions.,4,Improving Connectionist Energy Minimization
delayed-commitment,planning strategy,The common belief is that delayed-commitment is the 'best' possible planning strategy due to evidence in handling planning problems with difficult goal interactions.,4,Improving Connectionist Energy Minimization
eager-commitment planners,planning problems,"We recently found evidence that eager-commitment planners can handle a variety of planning problems more efficiently, particularly those with difficult operator choices.",4,Improving Connectionist Energy Minimization
FLECS,planning algorithm,"Introducing this new planning algorithm, FLECS, which uses a FLExible Commitment Strategy with respect to plan-step orderings.",4,Improving Connectionist Energy Minimization
delayed-commitment,eager-commitment,FLECS can use any strategy from delayed-commitment to eager-commitment.,4,Improving Connectionist Energy Minimization
planning domains and problems,efficient planning strategies,FLECS represents a novel contribution to planning in that it explicitly provides the choice of which commitment strategy to use while planning. FLECS provides a framework to investigate the mapping from planning domains and problems to efficient planning strategies.,4,Improving Connectionist Energy Minimization
first-order decision lists,learning a new class of concepts,"The paper presents a method for inducing logic programs from examples that learns a new class of concepts called first-order decision lists, which are defined as ordered lists of clauses each ending in a cut and can be used for learning a variety of concepts. This method, called FOIDL, is based on FOIL but employs intensional background knowledge and avoids the need for explicit negative examples.",4,Learning Membership Functions in a Function-Based Object Recognition   System
FOIDL,learning a new class of concepts,"The paper presents a method for inducing logic programs from examples called FOIDL, which learns a new class of concepts called first-order decision lists. This method is particularly useful for problems that involve rules with specific exceptions and can be applied to learning a variety of concepts.",4,Learning Membership Functions in a Function-Based Object Recognition   System
first-order decision lists,intensional background knowledge,"FOIDL, the method presented in the paper for inducing logic programs from examples, employs intensional background knowledge to learn a new class of concepts called first-order decision lists.",4,Learning Membership Functions in a Function-Based Object Recognition   System
FOIDL,explicit negative examples,"The method presented in the paper for inducing logic programs from examples, FOIDL, avoids the need for explicit negative examples in learning a new class of concepts called first-order decision lists.",4,Learning Membership Functions in a Function-Based Object Recognition   System
FOIDL,symbolic/connectionist debate,"The paper describes how FOIDL, the method presented for inducing logic programs from examples, is particularly useful for problems that involve rules with specific exceptions, such as learning the past-tense of English verbs, a task widely studied in the context of the symbolic/connectionist debate.",4,Learning Membership Functions in a Function-Based Object Recognition   System
FOIDL,significantly fewer examples,"The paper reports that FOIDL is able to learn concise, accurate programs for learning the past-tense of English verbs from significantly fewer examples than previous methods (both connectionist and symbolic).",4,Learning Membership Functions in a Function-Based Object Recognition   System
ion,abstraction by dropping sentences,"In several domains, abstraction by dropping sentences has proven useful in problem solving approaches. However, this approach has significant drawbacks as illustrated in this paper. To overcome these drawbacks, a more general view of abstraction involving the change of representation language is proposed.",4,Flexibly Instructable Agents
concrete,abstract,"In the proposed new abstraction methodology and learning algorithm, planning cases can be completely changed from concrete to abstract using a new approach that allows for a powerful change in representation language. However, an admissible way of abstracting states and the abstract language itself must be provided in the domain model.",4,Flexibly Instructable Agents
Paris,classical hierarchical planning,An empirical study in the domain of process planning in mechanical engineering shows significant advantages of reasoning from abstract cases using Paris over classical hierarchical planning.,4,Flexibly Instructable Agents
identifying inaccurate data,qualitative correlations among related data,"First, we introduce the definitions of related data and qualitative correlations among related data. Then we put forward a new concept called support coefficient function (SCF). SCF can be used to extract, represent, and calculate qualitative correlations among related data within a dataset.",4,OPUS: An Efficient Admissible Algorithm for Unordered Search
identifying inaccurate data,dynamic shift intervals of inaccurate data,Both of the approaches are based on SCF. Finally we present an algorithm for identifying inaccurate data by using qualitative correlations among related data as confirmatory or disconfirmatory evidence.,4,OPUS: An Efficient Admissible Algorithm for Unordered Search
qualitative correlations among related data,conventional methods used in many similar systems,The experimental results show that the method is significantly better than the conventional methods used in many similar systems.,4,OPUS: An Efficient Admissible Algorithm for Unordered Search
identifying inaccurate data,real spectra,"We have developed a practical system for interpreting infrared spectra by applying the method, and have fully tested the system against several hundred real spectra.",4,OPUS: An Efficient Admissible Algorithm for Unordered Search
intelligence,learning,Learning is an aspect of intelligence.,4,Vision-Based Road Detection in Automotive Systems: A Real-Time   Expectation-Driven Approach
intelligence,reasoning,Reasoning is an aspect of intelligence.,4,Vision-Based Road Detection in Automotive Systems: A Real-Time   Expectation-Driven Approach
machine learning,learning,Machine learning falls under the topic of learning.,4,Vision-Based Road Detection in Automotive Systems: A Real-Time   Expectation-Driven Approach
classical AI,reasoning,Classical (or symbolic) AI studies reasoning.,4,Vision-Based Road Detection in Automotive Systems: A Real-Time   Expectation-Driven Approach
FLARE,learning,FLARE combines inductive learning with prior knowledge.,4,Vision-Based Road Detection in Automotive Systems: A Real-Time   Expectation-Driven Approach
FLARE,reasoning,FLARE combines reasoning and propositional setting.,4,Vision-Based Road Detection in Automotive Systems: A Real-Time   Expectation-Driven Approach
ergodicity,Markovian models,Markovian models with ergodic transition probability matrices are less likely to have diffusion of context and credit due to their ability to visit all possible states in the long run.,4,Generalization of Clauses under Implication
transition probability matrices,sparse or deterministic transition probability matrices,"Sparse or deterministic transition probability matrices reduce the phenomenon of diffusion of context and credit, making it easier to learn long-term context for sequential data.",4,Generalization of Clauses under Implication
learning approaches based on continuous optimization,gradient descent and the Baum-Welch algorithm,"The results found in this paper apply to learning approaches based on continuous optimization, such as gradient descent and the Baum-Welch algorithm.",4,Generalization of Clauses under Implication
Symmetric networks,Energy minimization,"Such networks are frequently investigated for use in optimization, constraint satisfaction and approximation of NP-hard problems.",4,Decision-Theoretic Foundations for Causal Reasoning
Boltzman machines,Hopfield nets,Are examples of symmetric networks designed for energy minimization.,4,Decision-Theoretic Foundations for Causal Reasoning
Global solution,Exponential number of steps,Finding a global solution in such networks may take an exponential number of steps and even a local solution is not guaranteed.,4,Decision-Theoretic Foundations for Causal Reasoning
Tree-like subnetworks,Linear time,Our proposed algorithm guarantees that a global minimum is found in linear time for tree-like subnetworks.,4,Decision-Theoretic Foundations for Causal Reasoning
Activate,Improvement to standard local activation function,We propose an improvement to the standard local activation function used for such networks.,4,Decision-Theoretic Foundations for Causal Reasoning
Uniform algorithm,Does not assume network is tree-like,"The improved algorithm, called activate, is uniform and does not assume that the network is tree-like.",4,Decision-Theoretic Foundations for Causal Reasoning
Identify tree-like subnetworks,Even in cyclic topologies,The algorithm can identify tree-like subnetworks even in cyclic topologies (arbitrary networks).,4,Decision-Theoretic Foundations for Causal Reasoning
Converge to a global minimum,From any initial state of the system,"For acyclic networks, the algorithm is guaranteed to converge to a global minimum from any initial state of the system (self-stabilization).",4,Decision-Theoretic Foundations for Causal Reasoning
Uniform algorithm,Does not exist for cycles,"In the presence of cycles, no uniform algorithm exists that guarantees optimality even under a sequential asynchronous scheduler.",4,Decision-Theoretic Foundations for Causal Reasoning
Asynchronous scheduler,Activate only one unit at a time,An asynchronous scheduler can activate only one unit at a time while a synchronous scheduler can activate any number of units in a single time step.,4,Decision-Theoretic Foundations for Causal Reasoning
Uniform algorithm,Does not exist for acyclic networks,No uniform algorithm exists to optimize even acyclic networks when the scheduler is synchronous.,4,Decision-Theoretic Foundations for Causal Reasoning
Cycle-cutset scheme,Improves over activate,"Finally, we show how the algorithm can be improved using the cycle-cutset scheme. The general algorithm, called activate-with-cutset, improves over activate and has some performance guarantees that are related to the size of the network's cycle-cutset.",4,Decision-Theoretic Foundations for Causal Reasoning
category measure,membership function,"learning component for automatically learning membership functions given a set of example objects labeled with their desired category measure in the functionality-based recognition system Gruff, called Omlet",4,Translating between Horn Representations and their Characteristic Models
low-level membership values,Gruff recognition system,combined through an and-or tree structure to give a final overall membership value,4,Translating between Horn Representations and their Characteristic Models
interactive tutorial instruction,flexible paradigm for teaching tasks,allows an instructor to communicate whatever types of knowledge an agent might need in whatever situations might arise.,4,Statistical Feature Combination for the Evaluation of Game Positions
"learning from situated, interactive tutorial instruction",agent,within an ongoing,4,Statistical Feature Combination for the Evaluation of Game Positions
situated explanation,"approach to learning from situated, interactive tutorial instruction",achieves such learning through a combination of analytic and inductive techniques.,4,Statistical Feature Combination for the Evaluation of Game Positions
Situated explanation-based learning,form of explanation-based learning,that is situated for each instruction,4,Statistical Feature Combination for the Evaluation of Game Positions
contextually guided responses to incomplete explanations,situated explanation,,4,Statistical Feature Combination for the Evaluation of Game Positions
Instructo-Soar,learning hierarchies of new tasks and other domain knowledge from interactive natural language instructions,,4,Statistical Feature Combination for the Evaluation of Game Positions
known or unknown commands,Instructo-Soar,can take at any instruction point,4,Statistical Feature Combination for the Evaluation of Game Positions
"instructions that apply to either its current situation or to a hypothetical situation specified in language (as in, for instance, conditional instructions)",Instructo-Soar,,4,Statistical Feature Combination for the Evaluation of Game Positions
learning each class of knowledge it uses to perform tasks,Interactive tutorial instruction,,4,Statistical Feature Combination for the Evaluation of Game Positions
OPUS,admissible search,"OPUS is a branch and bound search algorithm that enables efficient admissible search through spaces for which the order of search operator application is not significant. This feature makes OPUS an efficient search algorithm, particularly for very large machine learning search spaces.",4,Rule-based Machine Learning Methods for Functional Prediction
OPUS,exact learning biases,The use of admissible search in OPUS means that the exact learning biases to be employed for complex learning tasks can be precisely specified and manipulated.,4,Rule-based Machine Learning Methods for Functional Prediction
OPUS,complex learning tasks,The potential value of admissible search in OPUS lies in its ability to precisely specify and manipulate the exact learning biases required for complex learning tasks.,4,Rule-based Machine Learning Methods for Functional Prediction
OPUS,machine learning community,The efficiency of OPUS with respect to very large machine learning search spaces has potential value for the machine learning community as it allows for precisely specified and manipulated exact learning biases for complex learning tasks.,4,Rule-based Machine Learning Methods for Functional Prediction
OPUS,truth maintenance,"The potential application of OPUS in other areas of artificial intelligence, notably truth maintenance, is a result of its efficient admissible search through spaces for which the order of search operator application is not significant.",4,Rule-based Machine Learning Methods for Functional Prediction
vision-based road detection system,real-time constraints imposed by moving vehicle applications,The main aim of this work is the development of a vision-based road detection system that can cope with the difficult real-time constraints imposed by moving vehicle applications.,4,The Design and Experimental Analysis of Algorithms for Temporal   Reasoning
vision-based road detection system,difficult real-time constraints imposed by moving vehicle applications,The main aim of this work is the development of a vision-based road detection system that can cope with the difficult real-time constraints imposed by moving vehicle applications.,4,The Design and Experimental Analysis of Algorithms for Temporal   Reasoning
special-purpose massively parallel system,minimize system production and operational costs,"The hardware platform, a special-purpose massively parallel system, has been chosen to minimize system production and operational costs.",4,The Design and Experimental Analysis of Algorithms for Temporal   Reasoning
expectation-driven low-level image segmentation,massively parallel SIMD architectures capable of handling hierarchical data structures,"This paper presents a novel approach to expectation-driven low-level image segmentation, which can be mapped naturally onto mesh-connected massively parallel SIMD architectures capable of handling hierarchical data structures.",4,The Design and Experimental Analysis of Algorithms for Temporal   Reasoning
input image,multiresolution stretching process,"The input image is assumed to contain a distorted version of a given template; a multiresolution stretching process is used to reshape the original template in accordance with the acquired image content, minimizing a potential function.",4,The Design and Experimental Analysis of Algorithms for Temporal   Reasoning
original template,distorted template,The distorted template is the process output.,4,The Design and Experimental Analysis of Algorithms for Temporal   Reasoning
inductive learning,generalization,"In the area of inductive learning, generalization is a main operation",4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
inductive learning,logical implication,the usual definition of induction is based on logical implication,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
machine learning,clausal representation of knowledge,There has been a rising interest in clausal representation of knowledge in machine learning,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
recursive clauses,learning recursive clauses,is a crucial problem since recursion is the basic program structure of logic programs,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
theta-subsumption,inductive learning systems,Almost all inductive learning systems that perform generalization of clauses use the relation theta-subsumption instead of implication,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
implication,inductive learning systems,However generalization under theta-subsumption is inappropriate for learning recursive clauses,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
T-implication,inductive learning,"We introduce a stronger form of implication, called T-implication, which is decidable between clauses",4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
clauses,T-implication,For every finite set of clauses there exists a least general generalization under T-implication,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
expansions,induction,We describe a technique to reduce generalizations under implication of a clause to generalizations under theta-subsumption of what we call an expansion,4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
non-tautological clauses,T-complete expansions,"For every non-tautological clause there exists a T-complete expansion, which means that every generalization under T-implication of the clause is reduced to a generalization under theta-subsumption of the expansion",4,Well-Founded Semantics for Extended Logic Programs with Dynamic   Preferences
causal assertions,decision-theoretic primitives,"Our definition of cause and effect departs from the traditional view in that causal assertions may vary with the set of decisions available, providing added clarity to the notion of cause.",4,Logarithmic-Time Updates and Queries in Probabilistic Networks
causal relationships,directed acyclic graphs,We examine the encoding of causal relationships in directed acyclic graphs.,4,Logarithmic-Time Updates and Queries in Probabilistic Networks
canonical form,influence diagrams,"We describe a special class of influence diagrams, those in canonical form, and show its relationship to Pearl's representation of cause and effect.",4,Logarithmic-Time Updates and Queries in Probabilistic Networks
counterfactual reasoning,canonical form,"Finally, we show how canonical form facilitates counterfactual reasoning.",4,Logarithmic-Time Updates and Queries in Probabilistic Networks
Characteristic models,Horn expressions,"Alternative, model based, representation for Horn expressions. The two representations are incomparable and each has its advantages over the other, leading to translation questions between them. These questions also arise in database theory with applications to the design of relational databases.",4,Quantum Computing and Phase Transitions in Combinatorial Search
Characteristic models,Decision problem,The translation problems are equivalent to deciding whether a given set of models is the set of characteristic models for a given Horn expression.,4,Quantum Computing and Phase Transitions in Combinatorial Search
Horn expressions,Characteristic models,"Translation questions arise between these representations, and translating is equivalent to deciding whether a given set of models is the set of characteristic models for a given Horn expression.",4,Quantum Computing and Phase Transitions in Combinatorial Search
Horn expressions,Hypergraph transversal problem,"In general, our translation problems are at least as hard as the hypergraph transversal problem, which is related to other applications in AI and for which no polynomial time algorithm is known.",4,Quantum Computing and Phase Transitions in Combinatorial Search
Hypergraph transversal problem,Horn expressions,The translation problems are equivalent to the hypergraph transversal problem in a special case.,4,Quantum Computing and Phase Transitions in Combinatorial Search
logistic regression,game-tree search,"Logistic regression is applied in the context of game playing for estimating feature weights in three well-known statistical methods. This application is described in this article, where it leads to better results than other approaches like Fisher's linear discriminant and quadratic discriminant function for normally distributed features.",4,Mean Field Theory for Sigmoid Belief Networks
logistic regression,well-known statistical methods,"Logistic regression is used in this article to estimate feature weights using a large number of classified Othello positions, which falls under the category of three well-known statistical methods commonly employed in game-tree search.",4,Mean Field Theory for Sigmoid Belief Networks
Fisher's linear discriminant,game-tree search,Fisher's linear discriminant is also used in this article for estimating feature weights as part of three well-known statistical methods applied to a large number of classified Othello positions in the context of game playing.,4,Mean Field Theory for Sigmoid Belief Networks
quadratic discriminant function,game-tree search,"The quadratic discriminant function for normally distributed features is utilized as part of three well-known statistical methods to estimate feature weights using a large number of classified Othello positions in the context of game playing, as discussed in this article.",4,Mean Field Theory for Sigmoid Belief Networks
Othello,game-tree search,"Othello is used in conjunction with game-tree search and statistical methods like logistic regression, Fisher's linear discriminant, and the quadratic discriminant function for normally distributed features to estimate feature weights using a large number of classified positions.",4,Mean Field Theory for Sigmoid Belief Networks
world-class Othello program,playing strengths,The playing strengths of resulting versions of a world-class Othello program are compared by means of tournaments as described in this article.,4,Mean Field Theory for Sigmoid Belief Networks
machine learning method,predicting the value of a real-valued function,A machine learning method is used to predict the value of a real-valued function.,4,Improved Use of Continuous Attributes in C4.5
machine learning method,multiple input variables,A machine learning method is applied to multiple input variables to predict the value of a real-valued function.,4,Improved Use of Continuous Attributes in C4.5
ordered disjunctive normal form (DNF),induced solutions,Induced solutions are presented in the form of ordered disjunctive normal form (DNF).,4,Improved Use of Continuous Attributes in C4.5
"compact, easily interpretable solutions",induction method,The new induction method aims to induce compact and easily interpretable solutions.,4,Improved Use of Continuous Attributes in C4.5
ordered disjunctive normal form (DNF),rule-based decision model,The induced solutions in the form of ordered disjunctive normal form (DNF) contribute to the rule-based decision model.,4,Improved Use of Continuous Attributes in C4.5
similar cases,search for similar cases,The new technique can be extended to search efficiently for similar cases prior to approximating function values.,4,Improved Use of Continuous Attributes in C4.5
temporal reasoning system,Allen's interval-based framework for representing temporal information,based on,4,Active Learning with Statistical Models
applications,temporal reasoning component,rely heavily on,4,Active Learning with Statistical Models
problems in molecular biology,temporal reasoning component,rely heavily on,4,Active Learning with Statistical Models
path consistency algorithm,algorithms for determining whether the temporal information is consistent,part of,4,Active Learning with Statistical Models
backtracking algorithm,algorithms for determining whether the temporal information is consistent,part of,4,Active Learning with Statistical Models
path consistency algorithm,highly optimized implementation,develop techniques that can result in up to a ten-fold speedup over,4,Active Learning with Statistical Models
backtracking algorithm,empirical analysis,develop variable and value ordering heuristics that are shown empirically to dramatically improve the performance of the algorithm,4,Active Learning with Statistical Models
backtracking search problem,previously suggested reformulation,can reduce the time and space requirements of the backtracking search,4,Active Learning with Statistical Models
well-founded semantics,preferences between rules,"In this extension of well-founded semantics for logic programs with two types of negation, information about preferences between rules can be expressed in the logical language and derived dynamically using a reserved predicate symbol and a naming technique. Conflicts among rules are resolved whenever possible on the basis of derived preference information.",4,A Divergence Critic for Inductive Proof
logic programs,two types of negation,This extension is for logic programs with two types of negation.,4,A Divergence Critic for Inductive Proof
well-founded conclusions,prioritized logic programs,The well-founded conclusions of prioritized logic programs can be computed in polynomial time.,4,A Divergence Critic for Inductive Proof
legal reasoning example,usefulness of the approach,A legal reasoning example illustrates the usefulness of the approach.,4,A Divergence Critic for Inductive Proof
Traditional databases,Dynamic reasoning in probabilistic databases,Our goal is to take a first step toward dynamic reasoning in probabilistic databases with comparable efficiency as traditional databases commonly support efficient query and update procedures that operate in time which is sublinear in the size of the database.,4,Practical Methods for Proving Termination of General Logic Programs
Singly connected Bayesian networks,Dynamic data structure,We propose a dynamic data structure that supports efficient algorithms for updating and querying singly connected Bayesian networks.,4,Practical Methods for Proving Termination of General Logic Programs
O(1) time,New evidence absorption,"In the conventional algorithm, new evidence is absorbed in O(1) time.",4,Practical Methods for Proving Termination of General Logic Programs
O(N),Queries,"Queries are processed in time O(N), where N is the size of the network.",4,Practical Methods for Proving Termination of General Logic Programs
Log N time,Queries,"We propose an algorithm which, after a preprocessing phase, allows us to answer queries in time O(log N) at the expense of O(log N) time per evidence absorption.",4,Practical Methods for Proving Termination of General Logic Programs
Real-time response,Large probabilistic databases,The usefulness of sub-linear processing time manifests itself in applications requiring (near) real-time response over large probabilistic databases.,4,Practical Methods for Proving Termination of General Logic Programs
Computational biology,Dynamic probabilistic reasoning,We briefly discuss a potential application of dynamic probabilistic reasoning in computational biology.,4,Practical Methods for Proving Termination of General Logic Programs
combinatorial search,quantum computers,"introduce an algorithm for combinatorial search on quantum computers that is capable of significantly concentrating amplitude into solutions for some NP search problems, on average.",4,Iterative Optimization and Simplification of Hierarchical Clusterings
quantum parallelism,unproductive search choices,exploiting the same aspects of problem structure as used by classical backtrack methods to avoid,4,Iterative Optimization and Simplification of Hierarchical Clusterings
difficult problem instances,underconstrained/overconstrained problems,"displaying the same phase transition behavior, and at the same location, as seen in many previously studied classical search methods.",4,Iterative Optimization and Simplification of Hierarchical Clusterings
quantum algorithm,classical backtrack methods,exploiting the same aspects of problem structure as used by classical backtrack methods to avoid unproductive search choices.,4,Iterative Optimization and Simplification of Hierarchical Clusterings
mean field theory,sigmoid belief networks,"Our mean field theory is developed specifically for sigmoid belief networks, providing a tractable approximation to the true probability distribution in these networks.",4,Further Experimental Evidence against the Utility of Occam's Razor
mean field theory,tractable approximation,"Our mean field theory provides a tractable approximation to the true probability distribution in sigmoid belief networks, allowing for more efficient and scalable computation.",4,Further Experimental Evidence against the Utility of Occam's Razor
mean field theory,likelihood of evidence,"In addition to providing a tractable approximation, our mean field theory also yields a lower bound on the likelihood of evidence in sigmoid belief networks.",4,Further Experimental Evidence against the Utility of Occam's Razor
sigmoid belief networks,classification of handwritten digits,"We demonstrate the utility of our mean field theory framework for the classification of handwritten digits, a benchmark problem in statistical pattern recognition.",4,Further Experimental Evidence against the Utility of Occam's Razor
C4.5,Modifications to address weakness in continuous attribute domains,A reported weakness of C4.5 in domains with continuous attributes is addressed by modifying the formation and evaluation of tests on continuous attributes.,4,Least Generalizations and Greatest Specializations of Sets of Clauses
Smaller decision trees,Empirical trials show that the modifications lead to smaller decision trees,,4,Least Generalizations and Greatest Specializations of Sets of Clauses
Higher predictive accuracies,Empirical trials show that the modifications lead to smaller decision trees with higher predictive accuracies.,,4,Least Generalizations and Greatest Specializations of Sets of Clauses
New version of C4.5,Results also confirm that a new version of C4.5 incorporating these changes is superior to recent approaches that use global discretization and that construct small trees with multi-interval splits.,,4,Least Generalizations and Greatest Specializations of Sets of Clauses
Continuous attribute domains,A reported weakness of C4.5 in domains with continuous attributes,,4,Least Generalizations and Greatest Specializations of Sets of Clauses
Tests on continuous attributes,"The modifications apply an MDL-inspired penalty to such tests, eliminating some of them from consideration and altering the relative desirability of all tests.",,4,Least Generalizations and Greatest Specializations of Sets of Clauses
machine learning algorithms,optimal way to select training data,"For many types of machine learning algorithms, one can compute the statistically optimal way to select training data.",4,Reinforcement Learning: A Survey
feedforward neural networks,statistically optimal way to select training data,Optimal data selection techniques have been used with feedforward neural networks.,4,Reinforcement Learning: A Survey
mixtures of Gaussians,statistically optimal way to select training data,The same principles may be used to select data for mixtures of Gaussians.,4,Reinforcement Learning: A Survey
locally weighted regression,statistically optimal way to select training data,The same principles may be used to select data for locally weighted regression.,4,Reinforcement Learning: A Survey
efficient and accurate,mixtures of Gaussians and locally weighted regression,The techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate.,4,Reinforcement Learning: A Survey
good performance,optimal data selection techniques,"Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.",4,Reinforcement Learning: A Survey
diverging proof attempts,Inductive theorem provers,often,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
computer program,critic,describes,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
proof attempt,diverging proof attempts,is,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
computer program,critic,monitors,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
proof attempt,difference matching,recognizes,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
computer program,critic,proposes,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
lemmas,critic,proposes,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
generalizations,critic,proposes,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
differences,proof attempt,ripples,4,Adaptive Problem-solving for Large-scale Scheduling Problems: A Case   Study
termination of general logic programs,computational mechanisms used to process negated atoms,"Many computational mechanisms for processing negated atoms, such as Clark's negation as failure and Chan's constructive negation, are based on termination conditions.",4,A Formal Framework for Speedup Learning from Problems and Solutions
termination of general logic programs,Prolog selection rule,The methodology for proving termination of general logic programs is introduced in relation to the Prolog selection rule.,4,A Formal Framework for Speedup Learning from Problems and Solutions
low-acceptable program,up-acceptable program,"The notions of low-, weakly up-, and up-acceptable programs are introduced to distinguish parts of the program based on whether or not their termination depends on the selection rule.",4,A Formal Framework for Speedup Learning from Problems and Solutions
termination of general logic programs,non-monotonic reasoning,The methodology for proving termination of general logic programs is applied to formalize and implement interesting problems in non-monotonic reasoning.,4,A Formal Framework for Speedup Learning from Problems and Solutions
Clustering,Structure in data,Clustering is often used for discovering structure in data.,4,2Planning for Contingencies: A Decision-based Approach
Quality of clustering,Evaluation objective function,"Ideally, the search strategy should consistently construct clusterings of high quality, but be computationally inexpensive as well. In general, we cannot have it both ways, but we can partition the search so that a system inexpensively constructs a `tentative' clustering for initial examination, followed by iterative optimization, which continues to search in background for improved clusterings.",4,2Planning for Contingencies: A Decision-based Approach
Control strategy,Iterative optimization,Each of which repeatedly modifies an initial clustering in search of a better one. One of these methods appears novel as an iterative optimization strategy in clustering contexts.,4,2Planning for Contingencies: A Decision-based Approach
Performance task,Pattern completion,"Several authors have abstracted these criteria and posited a generic performance task akin to pattern completion, where the error rate over completed patterns is used to `externally' judge clustering utility.",4,2Planning for Contingencies: A Decision-based Approach
Resampling-based pruning strategies,Simplifying hierarchical clusterings,"Given this performance task, we adapt resampling-based pruning strategies used by supervised learning systems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis.",4,2Planning for Contingencies: A Decision-based Approach
Attribute-selection measures,Decision-tree induction,"Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate and simplicity dimensions.",4,2Planning for Contingencies: A Decision-based Approach
Occam's razor,Utility of Occam's razor,This paper presents new experimental evidence against the utility of Occam's razor.,4,A Principled Approach Towards Symbolic Geometric Constraint Satisfaction
Decision trees produced by C4.5,Post-processing decision trees,A systematic procedure is presented for post-processing decision trees produced by C4.5.,4,A Principled Approach Towards Symbolic Geometric Constraint Satisfaction
Similar objects,Same class,This procedure was derived by rejecting Occam's razor and instead attending to the assumption that similar objects are likely to belong to the same class.,4,A Principled Approach Towards Symbolic Geometric Constraint Satisfaction
Decision trees,More complex decision trees,"The resulting more complex decision trees are demonstrated to have, on average, for a variety of common learning tasks, higher predictive accuracy than the less complex original decision trees.",4,A Principled Approach Towards Symbolic Geometric Constraint Satisfaction
Occam's razor,Utility of Occam's razor,This result raises considerable doubt about the utility of Occam's razor as it is commonly applied in modern machine learning.,4,A Principled Approach Towards Symbolic Geometric Constraint Satisfaction
least generalization,"finite set of clauses containing at least one non-tautologous function-free clause (among other, not necessarily function-free clauses)",existence under implication in each of the six ordered sets,4,On Partially Controlled Multi-Agent Systems
least generalization,background knowledge,"need not exist under relative implication, not even if both the set that is to be generalized and the background knowledge are function-free",4,On Partially Controlled Multi-Agent Systems
greatest specialization,sets of clauses in each of the six ordered languages,complete discussion of existence and non-existence,4,On Partially Controlled Multi-Agent Systems
reinforcement learning,learning through trial-and-error interactions with a dynamic environment,reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment.,4,Spatial Aggregation: Theory and Applications
computer science perspective,machine learning,"this paper surveys the field of reinforcement learning from a computer science perspective, which is written to be accessible to researchers familiar with machine learning.",4,Spatial Aggregation: Theory and Applications
reinforcement,resemblance to work in psychology,"the work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ""reinforcement"".",4,Spatial Aggregation: Theory and Applications
Markov decision theory,establishing the foundations of the field,"the central issues of reinforcement learning, including establishing the foundations of the field via Markov decision theory, are discussed in this paper.",4,Spatial Aggregation: Theory and Applications
trading off exploration and exploitation,central issues of reinforcement learning,"the central issues of reinforcement learning, including trading off exploration and exploitation, are discussed in this paper.",4,Spatial Aggregation: Theory and Applications
delayed reinforcement,learning from delayed reinforcement,"the central issues of reinforcement learning, including learning from delayed reinforcement, are discussed in this paper.",4,Spatial Aggregation: Theory and Applications
empirical models,accelerating learning,"the central issues of reinforcement learning, including constructing empirical models to accelerate learning, are discussed in this paper.",4,Spatial Aggregation: Theory and Applications
generalization and hierarchy,making use of generalization and hierarchy,"the central issues of reinforcement learning, including making use of generalization and hierarchy, are discussed in this paper.",4,Spatial Aggregation: Theory and Applications
hidden state,coping with hidden state,"the central issues of reinforcement learning, including coping with hidden state, are discussed in this paper.",4,Spatial Aggregation: Theory and Applications
practical utility,assessment of practical utility,this paper concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.,4,Spatial Aggregation: Theory and Applications
scheduling problems,domain specific techniques,"Although most scheduling problems are NP-hard, domain specific techniques perform well in practice but are quite expensive to construct.",4,A Hierarchy of Tractable Subsets for Computing Stable Models
adaptive problem-solving solving,domain specific knowledge,"In adaptive problem-solving solving, domain specific knowledge is acquired automatically for a general problem solver with a flexible control architecture.",4,A Hierarchy of Tractable Subsets for Computing Stable Models
learning system,space of possible heuristic methods,"In this approach, a learning system explores a space of possible heuristic methods for one well-suited to the eccentricities of the given domain and problem distribution.",4,A Hierarchy of Tractable Subsets for Computing Stable Models
scheduling satellite communications,problem distributions based on actual mission requirements,"Using problem distributions based on actual mission requirements, our approach identifies strategies that not only decrease the amount of CPU time required to produce schedules, but also increase the percentage of problems that are solvable within computational resource limitations.",4,A Hierarchy of Tractable Subsets for Computing Stable Models
Speedup learning,Problem solving with experience,Seeks to improve computational efficiency,4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
Speedup learning,Random problems and their solutions,"Applies to two different representations of learned knowledge: control rules and macro-operators, and proves theorems that identify sufficient conditions for learning in each representation",4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
Symbolic integration,Speedup learning framework,Illustrates framework with implementation in two domains: symbolic integration and Eight Puzzle,4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
Eight Puzzle,Speedup learning framework,Illustrates framework with implementation in two domains: symbolic integration and Eight Puzzle,4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
Empirical learning of control rules,Speedup learning framework,Integrates many strands of experimental and theoretical work in machine learning,4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
Macro-operator learning,Speedup learning framework,Integrates many strands of experimental and theoretical work in machine learning,4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
Explanation-Based Learning (EBL),Speedup learning framework,Integrates many strands of experimental and theoretical work in machine learning,4,Accelerating Partial-Order Planners: Some Techniques for Effective   Search Control and Pruning
full knowledge of the conditions under which the plan will be executed,uncertainty in the world,opposite concepts,4,Cue Phrase Classification Using Machine Learning
classical AI planners,Cassandra,different types of planners,4,Cue Phrase Classification Using Machine Learning
explicit decision-steps,action outcome predictability,incompatibility,4,Cue Phrase Classification Using Machine Learning
decision-making procedures,different decision-making procedures,availability in Cassandra,4,Cue Phrase Classification Using Machine Learning
collection of geometric bodies,configuration of a collection of geometric bodies,the process of finding the configuration of a collection of geometric bodies to satisfy given constraints is an important problem in geometric reasoning.,4,Mechanisms for Automated Negotiation in State Oriented Domains
degrees of freedom analysis,efficiently solving the problem of finding the configuration of a collection of geometric bodies to satisfy given constraints by symbolically reasoning about geometry,recently suggested approach,4,Mechanisms for Automated Negotiation in State Oriented Domains
plan fragments,specialized routines used in degrees of freedom analysis to change the configuration of a set of bodies to satisfy new constraints while preserving existing constraints,a set of plan fragments is employed in degrees of freedom analysis,4,Mechanisms for Automated Negotiation in State Oriented Domains
geometric bodies,collection of geometric shapes or objects,the problem of finding the configuration of a collection of geometric bodies to satisfy given constraints applies to geometric bodies.,4,Mechanisms for Automated Negotiation in State Oriented Domains
actions,set of operations or transformations that can be performed on geometric bodies,first principles about geometric bodies and actions are used to automatically synthesize plan fragments.,4,Mechanisms for Automated Negotiation in State Oriented Domains
topology,"study of the properties that are preserved under continuous transformations (such as bending, stretching, or crumpling) while preserving the connectivity of a space",first principles about geometric bodies and topology are used to automatically synthesize plan fragments.,4,Mechanisms for Automated Negotiation in State Oriented Domains
multi-agent system,partially controlled multi-agent system,A partially controlled multi-agent system is a type of multi-agent system where some agents are directly controlled by the designer and others are not.,4,Learning First-Order Definitions of Functions
controllable agent,partially controlled multi-agent system,Controllable agents are agents that are directly controlled by the designer within a partially controlled multi-agent system.,4,Learning First-Order Definitions of Functions
uncontrollable agent,partially controlled multi-agent system,Uncontrollable agents are not under the direct control of the designer within a partially controlled multi-agent system.,4,Learning First-Order Definitions of Functions
designer,controllable agent,The designer directly controls the behavior of controllable agents in a partially controlled multi-agent system.,4,Learning First-Order Definitions of Functions
expected utility maximizer,uncontrollable agent,"In one context, the uncontrollable agents are expected utility maximizers within a partially controlled multi-agent system.",4,Learning First-Order Definitions of Functions
reinforcement learner,uncontrollable agent,"In another context, the uncontrollable agents are reinforcement learners within a partially controlled multi-agent system.",4,Learning First-Order Definitions of Functions
designer,uncontrollable agent,The designer influences the behavior of uncontrollable agents in a partially controlled multi-agent system through appropriate design of the controlled agents.,4,Learning First-Order Definitions of Functions
Visual thinking,Scientific reasoning,The given context highlights the importance of visual thinking in scientific reasoning.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Imagistic reasoning,Expert level performance,"Programs incorporating imagistic reasoning can perform at an expert level in domains that defy current analytic or numerical methods, as demonstrated by the research mentioned in the context.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Imagistic reasoning,Image-like analogue representations,"Imagistic reasoning organizes computations around image-like, analogue representations as identified through research on automating diverse reasoning tasks.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Unified description of imagistic problem solvers,A program written in the spatial aggregation paradigm unifies the description of a class of imagistic problem solvers.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Continuous field,A program written in this paradigm takes a continuous field as input.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Optional objective functions,A program written in this paradigm may take optional objective functions as input.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,"High-level descriptions of structure, behavior, or control actions","A program written in this paradigm produces high-level descriptions of structure, behavior, or control actions.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Intermediate representations,A program written in this paradigm computes a multi-layer of intermediate representations called spatial aggregates.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Equivalence classes and adjacency relations,A program written in this paradigm forms equivalence classes and adjacency relations to compute spatial aggregates.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Generic operators,"A program written in this paradigm employs a small set of generic operators such as aggregation, classification, and localization to perform bidirectional mapping between the information-rich field and successively more abstract spatial aggregates.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
Spatial aggregation,Neighborhood graph,A program written in this paradigm uses a data structure called the neighborhood graph as a common interface to modularize computations.,4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
KAM,Implemented problem solver,"The given context mentions KAM, an implemented problem solver.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
MAPS,Implemented problem solver,"The given context mentions MAPS, an implemented problem solver.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
HIPAIR,Implemented problem solver,"The given context mentions HIPAIR, an implemented problem solver.",4,MUSE CSP: An Extension to the Constraint Satisfaction Problem
knowledge base,stable models,Finding the stable models of a knowledge base is a significant computational problem in artificial intelligence.,4,Exploiting Causal Independence in Bayesian Network Inference
knowledge base,stratified knowledge base,"This task is at the computational heart of truth maintenance systems, autoepistemic logic, and default logic. The class Omega_1 contains all stratified knowledge bases.",4,Exploiting Causal Independence in Bayesian Network Inference
knowledge base,NP-hard,"Unfortunately, it is NP-hard.",4,Exploiting Causal Independence in Bayesian Network Inference
stable models,Omegak,"If a knowledge base Pi is in Omega_k, then Pi has at most k stable models, and all of them may be found in time O(lnk).",4,Exploiting Causal Independence in Bayesian Network Inference
knowledge base,minimum k,"For an arbitrary knowledge base Pi, we can find the minimum k such that Pi belongs to Omega_k in time polynomial in the size of Pi.",4,Exploiting Causal Independence in Bayesian Network Inference
class,hierarchy,"This hierarchy consists of classes Omega_1,Omega_2,..., with the properties mentioned in the text.",4,Exploiting Causal Independence in Bayesian Network Inference
domain-independent techniques,practicality of well-founded partial-order planners,The author proposes some domain-independent techniques for bringing well-founded partial-order planners closer to practicality.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
search control,well-founded partial-order planners,The author aims at improving search control while keeping overhead costs low for well-founded partial-order planners.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
A* heuristic,search control,The author proposes a simple adjustment to the default A* heuristic used by UCPOP for search control.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
zero commitment plan refinements,preferring zero commitment plan refinements,The author prefers 'zero commitment' (forced) plan refinements whenever possible during planning.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
LIFO prioritization,preferring zero commitment plan refinements,The author uses LIFO prioritization otherwise during planning.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
operator parameter domains,pruning search,The author uses operator parameter domains to prune search during planning.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
initial and goal conditions,operator parameter domains,"The author initially computes parameter domains from the definitions of operators and initial and goal conditions using a polynomial-time algorithm that propagates sets of constants through the operator graph, starting in the initial conditions during planning.",4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
spurious clobbering threats,pruning nonviable operator instances,"During planning, parameter domains can be used to prune nonviable operator instances and to remove spurious clobbering threats.",4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
speedups,experiments based on modifications of UCPOP,The author's improved plan and goal selection strategies gave speedups by factors ranging from 5 to more than 1000 for a variety of problems that are nontrivial for the unmodified version during experiments.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
hardest problems,speedups,"Crucially, the hardest problems gave the greatest improvements during experiments.",4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
Lisp code,techniques and test problems,The author provides the Lisp code for their techniques and for the test problems in on-line appendices.,4,Quantitative Results Comparing Three Intelligent Interfaces for   Information Capture: A Case Study Adding Name Information into an Electronic   Personal Organizer
discourse sense,automatically construct classification models,makes it easier to comparatively analyze the utility of alternative feature representations of the data,4,Characterizations of Decomposable Dependency Models
discourse sense,manually derived classification models already in the literature,"when compared to, the learned models often perform with higher accuracy and contain new linguistic insights into the data",4,Characterizations of Decomposable Dependency Models
sentential sense,cue phrases may be used,correctly classifying cue phrases as discourse or sentential is critical in natural language processing systems that exploit discourse structure,4,Characterizations of Decomposable Dependency Models
sentential sense,semantic rather than structural information,cue phrases may be used in a sentential sense to convey semantic rather than structural information,4,Characterizations of Decomposable Dependency Models
discourse sense,explicitly signal discourse structure,cue phrases may be used in a discourse sense to explicitly signal discourse structure,4,Characterizations of Decomposable Dependency Models
First-order learning,Finding a clause-form definition of a relation,Involves,4,A Uniform Framework for Concept Definitions in Description Logics
Functional relations,Findings definitions,Customization for,4,A Uniform Framework for Concept Definitions in Description Logics
Faster learning times,Restriction,Leads to,4,A Uniform Framework for Concept Definitions in Description Logics
Higher predictive accuracy,Definitions,"In some cases, result of",4,A Uniform Framework for Concept Definitions in Description Logics
MUSE CSP,Constraint Satisfaction Problem (CSP),"Extension of CSP called MUSE CSP is especially useful for problems that segment into multiple sets of partially shared variables, arising naturally in signal processing applications including computer vision, speech processing, and handwriting recognition.",4,Lifeworld Analysis
MUSE CSP,Low-level information utilized by segmentation algorithms,Such problems often have difficulty segmenting data in only one way given the low-level information.,4,Lifeworld Analysis
MUSE CSP,"Signal processing applications including computer vision, speech processing, and handwriting recognition",MUSE CSP can be used to compactly represent several similar instances of the constraint satisfaction problem.,4,Lifeworld Analysis
MUSE node consistency,MUSE CSP,"Introduced concepts for MUSE node consistency, MUSE arc consistency, and MUSE path consistency.",4,Lifeworld Analysis
MUSE arc consistency,MUSE CSP,Algorithms provided for MUSE arc and path consistency.,4,Lifeworld Analysis
Lexically ambiguous sentences,MUSE CSP,Demonstrated how MUSE CSP can be used to compactly represent lexically ambiguous sentences and multiple sentence hypotheses generated by speech recognition algorithms.,4,Lifeworld Analysis
Set of CSPs,MUSE CSP,Discussed how to create a MUSE CSP from a set of CSPs labeled to indicate when the same variable is shared by more than a single CSP.,4,Lifeworld Analysis
CSP,MUSE CSP,"MUSE CSP can be used to compactly represent several similar instances of the constraint satisfaction problem, reducing the work required to apply the constraints for problems which segment into multiple sets of partially shared variables.",4,Lifeworld Analysis
Bayesian network,joint probability,represents a factorization of the joint probability into conditional probabilities,4,Query DAGs: A Practical Paradigm for Implementing Belief-Network   Inference
causal independence,Bayesian network,enables one to further factorize the conditional probabilities into smaller factors,4,Query DAGs: A Practical Paradigm for Implementing Belief-Network   Inference
conditional probability,variable,"can be specified in terms of an associative and commutative operator on the contribution of each parent (e.g., 'or', 'sum', or 'max')",4,Query DAGs: A Practical Paradigm for Implementing Belief-Network   Inference
VE algorithm,Bayesian network inference,uses the factorization to find the posterior distribution of the query,4,Query DAGs: A Practical Paradigm for Implementing Belief-Network   Inference
causal independence,VE algorithm,extends VE algorithm to exploit causal independence,4,Query DAGs: A Practical Paradigm for Implementing Belief-Network   Inference
CPCS networks for medical diagnosis,Bayesian network inference,empirical studies based on these networks show that the proposed method is more efficient than previous methods and allows for inference in larger networks than previous algorithms,4,Query DAGs: A Practical Paradigm for Implementing Belief-Network   Inference
handwriting recognition,electronic organizer,Handwriting recognition is a feature that can be implemented in an electronic organizer to efficiently enter information into a computer. This paper highlights its usage and compares its speed with other input methods for adding a person's name and address.,4,Connectionist Theory Refinement: Genetically Searching the Space of   Network Topologies
adaptive menus,electronic organizer,"Adaptive menus are another intelligent user interface that can be integrated into an electronic organizer to facilitate fast information entry, as demonstrated in this paper while adding a person's name and address.",4,Connectionist Theory Refinement: Genetically Searching the Space of   Network Topologies
predictive fillin,electronic organizer,"Predictive fillin is another user interface that can be implemented in an electronic organizer to efficiently enter information into a computer, as shown in this paper for adding a person's name and address. Its speed can be twice as fast compared to other methods.",4,Connectionist Theory Refinement: Genetically Searching the Space of   Network Topologies
person's name,electronic organizer,"A person's name is a concept that can be entered into an electronic organizer using handwriting recognition, adaptive menus, or predictive fillin, as illustrated in this paper.",4,Connectionist Theory Refinement: Genetically Searching the Space of   Network Topologies
person's address,electronic organizer,"A person's address is another concept that can be added to an electronic organizer using the aforementioned intelligent user interfaces, as demonstrated in this paper.",4,Connectionist Theory Refinement: Genetically Searching the Space of   Network Topologies
decomposable dependency models,independence relationships,"Decomposable dependency models possess a number of interesting and useful properties. These properties are characterized by adding a single axiom to the well-known set characterizing dependency models isomorphic to undirected graphs, resulting in new characterizations in terms of independence relationships.",4,Flaw Selection Strategies for Partial-Order Planning
decomposable dependency models,graphical models,Our results also briefly discuss a potential application of the new characterizations to the problem of learning graphical models from data.,4,Flaw Selection Strategies for Partial-Order Planning
Instance-based learning techniques,Nominal input attributes,"The Value Difference Metric (VDM) was designed to find reasonable distance values between nominal attribute values, but it largely ignores continuous attributes, requiring discretization to map continuous values into nominal values.",4,A Complete Classification of Tractability in RCC-5
Instance-based learning techniques,Continuous input values,"These new distance functions (HVDM, IVDM, WVDM) are designed to handle applications with continuous attributes.",4,A Complete Classification of Tractability in RCC-5
Distance functions,Classification accuracy,"In experiments on 48 applications, the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.",4,A Complete Classification of Tractability in RCC-5
Nominal input attributes,Continuous input values,"The paper proposes three new heterogeneous distance functions (HVDM, IVDM, WVDM) that are designed to handle applications with nominal attributes, continuous attributes, or both.",4,A Complete Classification of Tractability in RCC-5
spontaneously spoken language,hand-coded symbolic grammar or symbolic semantic component,"approaches often have been based on encoding syntactic and semantic knowledge manually and symbolically, in contrast to the screening approach described in this paper.",4,A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search   Difficulty
screening approach,hand-coded symbolic grammar or symbolic semantic component,"is a flat analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic, semantic and dialog levels, in contrast to the deeply structured symbolic analysis.",4,A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search   Difficulty
spontaneously spoken language,deeply structured symbolic analysis,"approaches often have been based on encoding syntactic and semantic knowledge manually and symbolically, in contrast to the screening approach described in this paper.",4,A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search   Difficulty
screening approach,data-driven learning,"uses (1) data-driven learning and (2) robustness of connectionist networks for supporting speech and language processing, rather than using a deeply structured symbolic analysis.",4,A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search   Difficulty
screening approach,connectionist networks,allows more robust processing of spontaneous spoken language than deeply structured representations.,4,A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search   Difficulty
class definition,recursive definitions,"allows for different semantics to coexist in knowledge representation formalism, muALCQ. Recursive definitions enable frame-based descriptions and definitions of recursive data structures such as directed acyclic graphs, lists, streams, etc.",4,Eight Maximal Tractable Subclasses of Allen's Algebra with Metric Time
muALCQ,modal mu-calculus,"formulated correspondence to establish several properties of muALCQ, including decidability and computational complexity of reasoning",4,Eight Maximal Tractable Subclasses of Allen's Algebra with Metric Time
lifeworld,agent/environment interactions,The analysis of agent/environment interactions should be extended to include the conventions and invariants maintained by agents throughout their activity. This thicker notion of environment is referred to as a lifeworld.,4,Defining Relative Likelihood in Partially-Ordered Preferential   Structures
lifeworld,computational simplification of activity,Lifeworlds computationally simplify activity by providing structures that are maintained throughout agent activity.,4,Defining Relative Likelihood in Partially-Ordered Preferential   Structures
lifeworld,conventions and invariants,A lifeworld is defined by the conventions and invariants maintained by agents during their activity.,4,Defining Relative Likelihood in Partially-Ordered Preferential   Structures
agent/environment interactions,conventions and invariants,Conventions and invariants are maintained by agents during their interaction with the environment.,4,Defining Relative Likelihood in Partially-Ordered Preferential   Structures
Toast system,lifeworlds,The Toast system is analyzed as a specific example of a lifeworld.,4,Defining Relative Likelihood in Partially-Ordered Preferential   Structures
Toast system,control structures,Different versions of the Toast system implement different control structures within a common lifeworld structure.,4,Defining Relative Likelihood in Partially-Ordered Preferential   Structures
belief networks,Q-DAGs,"new paradigm for implementing inference, consists of two steps: compilation and evaluation",4,Towards Flexible Teamwork
belief networks,network queries,each leaf node represents the answer to a network query,4,Towards Flexible Teamwork
Q-DAGs,numeric operations,each node of a Q-DAG represents a numeric operation,4,Towards Flexible Teamwork
Q-DAGs,evidence symbols,each leaf node represents evidence for an event,4,Towards Flexible Teamwork
standard algorithms for exact inference,Q-DAG generation algorithm,"can be generated using clustering and conditioning algorithms, time complexity is no worse than the time complexity of the inference algorithm",4,Towards Flexible Teamwork
standard algorithms for exact inference,Q-DAG evaluation algorithm,"time and space complexity is linear in the size of the Q-DAG, standard evaluation of arithmetic expression",4,Towards Flexible Teamwork
belief networks,"on-line, real-world applications",reduces software and hardware resources required for inference,4,Towards Flexible Teamwork
An algorithm that learns from a set of examples,Abundant computing power,The ability to exploit abundant computing power improves the algorithm's ability to generalize.,4,Identifying Hierarchical Structure in Sequences: A linear-time algorithm
An algorithm that learns from a set of examples,Domain-specific knowledge,"Connectionist theory-refinement systems use domain-specific knowledge to select a neural network's topology and initial weights, which helps exploit domain-specific knowledge.",4,Identifying Hierarchical Structure in Sequences: A linear-time algorithm
REGENT algorithm,An initial population of knowledge-based neural networks,The REGENT algorithm uses domain-specific knowledge to create an initial population of knowledge-based neural networks.,4,Identifying Hierarchical Structure in Sequences: A linear-time algorithm
REGENT algorithm,Genetic operators of crossover and mutation (specifically designed for knowledge-based networks),The REGENT algorithm uses genetic operators to continually search for better network topologies.,4,Identifying Hierarchical Structure in Sequences: A linear-time algorithm
REGENT algorithm,Better network topologies,"By using genetic operators, the REGENT algorithm is able to refine the topology of the neural networks it produces, which helps improve generalization, especially when given impoverished domain theories.",4,Identifying Hierarchical Structure in Sequences: A linear-time algorithm
Least-Cost Flaw Repair (LCFR),Effective in reducing search-space size,"For many problems, combining least-cost flaw selection with delaying separable threats leads to an effective strategy for reducing search-space size without excessive computational overhead. Although this strategy provides a good default, its effectiveness may be reduced by certain domain characteristics.",4,Storing and Indexing Plan Derivations through Explanation-based Analysis   of Retrieval Failures
LCFR,ZLIFO Strategy,"Gerevini and Schubert's ZLIFO strategy makes conflicting claims about the most effective way to reduce search-space size in POCL planning, but much of its benefit is better attributed to other causes. The delay of separable threats in LCFR helps to resolve this conflict.",4,Storing and Indexing Plan Derivations through Explanation-based Analysis   of Retrieval Failures
Least-Cost Flaw Repair (LCFR),Effective in reducing search-space size,"For many problems, combining least-cost flaw selection with delaying separable threats leads to an effective strategy for reducing search-space size without excessive computational overhead. Although this strategy provides a good default, its effectiveness may be reduced by certain domain characteristics.",4,A Model Approximation Scheme for Planning in Partially Observable   Stochastic Domains
LCFR,ZLIFO Strategy,"Gerevini and Schubert's ZLIFO strategy makes conflicting claims about the most effective way to reduce search-space size in POCL planning, but much of its benefit is better attributed to other causes. The delay of separable threats in LCFR helps to resolve this conflict.",4,A Model Approximation Scheme for Planning in Partially Observable   Stochastic Domains
RCC-5,spatial algebra,"RCC-5 is a restricted version of the RCC framework, which is a spatial algebra used for spatial reasoning.",4,Dynamic Non-Bayesian Decision Making
satisfiability problem,RCC-5,The satisfiability problem for RCC-5 is a computational property that has been shown to be NP-complete.,4,Dynamic Non-Bayesian Decision Making
subclasses of RCC-5,approximately four billion,"RCC-5 has approximately four billion subclasses, but not much is known about their computational properties.",4,Dynamic Non-Bayesian Decision Making
satisfiability problem for all subclasses,polynomial or NP-complete,"We provide a complete classification of the satisfiability problem for all these subclasses, which we find to be either polynomial or NP-complete.",4,Dynamic Non-Bayesian Decision Making
maximal tractable subalgebras,four in total,"In the process of our investigation, we identify all maximal tractable subalgebras, which number four in total.",4,Dynamic Non-Bayesian Decision Making
easy-hard-easy pattern,competition between decrease in number of solutions and increased pruning,The easy-hard-easy pattern in the difficulty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in number of solutions and increased pruning.,4,When Gravity Fails: Local Search Topology
search cost,easy-hard-easy pattern,"For some search methods, the easy-hard-easy pattern is observed even when the number of solutions is held constant, leading to a monotonic decrease in search cost as constraints are added.",4,When Gravity Fails: Local Search Topology
search cost,median search cost,"In these cases, the easy-hard-easy pattern appears to be due to changes in the size of the minimal unsolvable subproblems, rather than changing numbers of solutions.",4,When Gravity Fails: Local Search Topology
search cost,number of solutions,"If the number of solutions is held fixed by the choice of problems, then increased pruning should lead to a monotonic decrease in search cost, according to existing theory.",4,When Gravity Fails: Local Search Topology
search method,easy-hard-easy pattern,The easy-hard-easy pattern is observed for some search methods even when the number of solutions is held constant.,4,When Gravity Fails: Local Search Topology
Allen's interval algebra,maximal tractable subclasses of Allen's interval algebra,"This paper combines two important directions of research in temporal resoning: that of finding maximal tractable subclasses of Allen's interval algebra, and that of reasoning with metric temporal information.",4,Bidirectional Heuristic Search Reconsidered
Allen's interval algebra,eight new maximal tractable subclasses of Allen's interval algebra,"Eight new maximal tractable subclasses of Allen's interval algebra are presented, some of them subsuming previously reported tractable algebras.",4,Bidirectional Heuristic Search Reconsidered
Allen's interval algebra,Horn DLRs,"The algebras allow for metric temporal constraints on interval starting or ending points, using the recent framework of Horn DLRs.",4,Bidirectional Heuristic Search Reconsidered
two algebras,sequentiality between intervals,"Two of the algebras can express the notion of sequentiality between intervals, being the first such algebras admitting both qualitative and metric time.",4,Bidirectional Heuristic Search Reconsidered
likelihood ordering on worlds,logic of relative likelihood,"Starting with a likelihood or preference order on worlds, we extend it to a likelihood ordering on sets of worlds in a natural way, and examine the resulting logic. This approach is used to study counterfactuals, and Lewis earlier considered such a notion of relative likelihood for total preference orders on worlds. However, complications arise when examining partial orders that are not present for total orders, and there are subtleties involving the exact approach to lifting the order on worlds to an order on sets of worlds.",4,Incremental Recompilation of Knowledge
logic of relative likelihood,default reasoning,The axiomatization of the logic of relative likelihood in the case of partial orders gives insight into the connection between relative likelihood and default reasoning.,4,Incremental Recompilation of Knowledge
teamwork,joint intentions,STEAM's teamwork is based on agents building up a (partial) hierarchy of joint intentions.,4,Monotonicity and Persistence in Preferential Logics
STEAM,"complex, dynamic multi-agent domains","Many AI researchers are today striving to build agent teams for complex, dynamic multi-agent domains with intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.",4,Monotonicity and Persistence in Preferential Logics
team members,"differing, incomplete, and possibly inconsistent views of their environment","Uncertainties in complex, dynamic domains obstruct coherent teamwork as team members often encounter differing, incomplete, and possibly inconsistent views of their environment.",4,Monotonicity and Persistence in Preferential Logics
team members,failed to fulfill responsibilities or discovered unexpected opportunities,"Furthermore, team members can unexpectedly fail in fulfilling responsibilities or discover unexpected opportunities.",4,Monotonicity and Persistence in Preferential Logics
flexibility,STEAM's central hypothesis,Our central hypothesis is that the key to such flexibility and reusability is providing agents with general models of teamwork.,4,Monotonicity and Persistence in Preferential Logics
reusability,STEAM's central hypothesis,Our central hypothesis is that the key to such flexibility and reusability is providing agents with general models of teamwork.,4,Monotonicity and Persistence in Preferential Logics
joint intentions,team members,"In STEAM, teamwork is based on agents' building up a (partial) hierarchy of joint intentions for team members.",4,Monotonicity and Persistence in Preferential Logics
joint intentions,individual members',"Furthermore, in STEAM, team members monitor the team's and individual members' performance, reorganizing the team as necessary.",4,Monotonicity and Persistence in Preferential Logics
STEAM,partial SharedPlans,"STEAM's basic building block of teamwork is joint intentions (Cohen & Levesque, 1991b); teamwork in STEAM is based on agents' building up a (partial) hierarchy of joint intentions, which parallels Grosz & Kraus's partial SharedPlans.",4,Monotonicity and Persistence in Preferential Logics
communication,STEAM,"Finally, decision-theoretic communication selectivity in STEAM ensures reduction in communication overheads of teamwork, with appropriate sensitivity to the environmental conditions.",4,Monotonicity and Persistence in Preferential Logics
team members',reorganizing the team,"In STEAM, team members monitor the team's and individual members' performance, reorganizing the team as necessary.",4,Monotonicity and Persistence in Preferential Logics
STEAM,"intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.","Many AI researchers are today striving to build agent teams for complex, dynamic multi-agent domains with intended applications in arenas such as education, training, entertainment, information integration, and collective robotics.",4,Monotonicity and Persistence in Preferential Logics
algorithm,SEQUITUR,"SEQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively.",4,Synthesizing Customized Planners from Specifications
hierarchical,structure,"The result of SEQUITUR's algorithm is a hierarchical representation of the original sequence, which offers insights into its lexical structure.",4,Synthesizing Customized Planners from Specifications
sequence,discrete symbols,SEQUITUR operates on a sequence of discrete symbols.,4,Synthesizing Customized Planners from Specifications
grammatical,rule,The algorithm replaces repeated phrases with a grammatical rule that generates the phrase.,4,Synthesizing Customized Planners from Specifications
constraint,reduces,The method's two constraints reduce the size of the grammar.,4,Synthesizing Customized Planners from Specifications
structure,produces,SEQUITUR produces structure as a by-product.,4,Synthesizing Customized Planners from Specifications
repeated,phrases,The algorithm replaces repeated phrases with a grammatical rule that generates the phrase.,4,Synthesizing Customized Planners from Specifications
symbols,input,"SEQUITUR's implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences.",4,Synthesizing Customized Planners from Specifications
Case-Based Planning (CBP),Domain-independent planning,CBP is a way of scaling up domain-independent planning to solve large problems in complex domains.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
CBP,Performance improvements over generative (from-scratch) planning,CBP has been demonstrated to improve performance over generative (from-scratch) planning in solving large problems.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
CBP,Mis-retrieval problem,The success of CBP depends on these retrieval errors being relatively rare. This paper describes the design and implementation of a replay framework for the case-based planner DERSNLP+EBL.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
DERSNLP+EBL,Case library,DERSNLP+EBL extends current CBP methodology by incorporating explanation-based learning techniques that allow it to explain and learn from the retrieval failures it encounters.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
DERSNLP+EBL,Similarity judgements,These techniques are used to refine judgements about case similarity in response to feedback when a wrong decision has been made.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
DERSNLP+EBL,Multi-goal problems,Large problems are split and stored as single goal subproblems. Multi-goal problems are stored only when these smaller cases fail to be merged into a full solution.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
DERSNLP+EBL,Replay framework,An empirical evaluation of this approach demonstrates the advantage of learning from experienced retrieval failure.,4,Cached Sufficient Statistics for Efficient Machine Learning with Large   Datasets
POMDPs,approximation scheme,Proposed in this paper to solve POMDPs due to difficulty in solving them exactly.,4,Tractability of Theory Patching
POMDPs,"nondeterministic effects of actions, incomplete observability of state",Characteristics that make it a natural model for planning problems.,4,Tractability of Theory Patching
POMDPs,region observable POMDP,Transformed POMDP proposed in this paper to make it easier to solve than the original one.,4,Tractability of Theory Patching
region observable POMDP,oracle,Provides additional information by informing the planning agent that current state is within a certain region.,4,Tractability of Theory Patching
repeated game,Nature,"In a model of an agent-environment interaction, the repeated game is an appropriate tool for modeling interactions with Nature's changing state.",4,Integrative Windowing
state selection strategy of Nature,unknown,"In a model of an agent-environment interaction, the feedback/reward function is initially unknown and the agent does not form a prior probability on Nature's state selection strategy.",4,Integrative Windowing
agent,Bayesian,"In a model of an agent-environment interaction, the agent is not Bayesian and does not form a prior probability on his reward function.",4,Integrative Windowing
perfect monitoring case,imperfect monitoring case,"In the study of feedback structures in partially observable processes, the perfect monitoring case refers to environments where the agent is able to observe the previous state as part of his feedback, while in the imperfect monitoring case all that is available to the agent is the reward obtained.",4,Integrative Windowing
efficient stochastic policy,optimal policy,"In the perfect monitoring case, the existence of an efficient stochastic policy is proven that ensures a long-run optimality criterion with an arbitrarily high probability, where efficiency is measured in terms of rate of convergence.",4,Integrative Windowing
competitive ratio,optimality criterion,"In the study of feedback structures, the competitive ratio criterion refers to the long-run optimality criterion used in our analysis.",4,Integrative Windowing
deterministic efficient optimal strategy,maxmin criterion,"In the imperfect monitoring case, it is proven that a deterministic efficient optimal strategy exists under the maxmin criterion.",4,Integrative Windowing
long-run optimality,qualitative,"Our approach to long-run optimality in feedback structures is qualitative, distinguishing it from previous work in this area.",4,Integrative Windowing
Local minima,Plateaus with exits (benches),Plateaus in local search algorithms for combinatorial search problems are characterized by the presence of both local minima and benches. Benches tend to be much larger than minima and may have very few exit states that local search algorithms can use to escape.,4,Model-Based Diagnosis using Structured System Descriptions
Local minima,Small size,"Local minima in randomly generated Boolean Satisfiability problems tend to be small, but occasionally may be very large.",4,Model-Based Diagnosis using Structured System Descriptions
Plateaus with exits (benches),Clusters,The solutions of randomly generated problem instances form clusters that behave similarly to local minima.,4,Model-Based Diagnosis using Structured System Descriptions
Local search algorithms,Plateau moves,"Frequently encountered in local search algorithms for combinatorial search problems, plateau moves refer to a sequence of states in which it is impossible to improve the value of the objective function.",4,Model-Based Diagnosis using Structured System Descriptions
Local search algorithms,Escaping plateaus,Escaping local minima without unsatisfying a large number of clauses can be computationally expensive if the local minimum is large.,4,Model-Based Diagnosis using Structured System Descriptions
bidirectional heuristic search,viability of bidirectional heuristic search,"The assessment of bidirectional heuristic search has been incorrect since it was first published more than a quarter of a century ago. Based on the finding that the conjecture about passing search frontiers is wrong, it is proposed that bidirectional heuristic search be reconsidered as it appears to be better for solving certain difficult problems than corresponding unidirectional search, providing some evidence for its usefulness which was long neglected.",4,A Selective Macro-learning Algorithm and its Application to the NxN   Sliding-Tile Puzzle
bidirectional heuristic search,misunderstanding about the reasons behind it,"For quite a long time, this search strategy did not achieve the expected results, and there was a major misunderstanding about the reasons behind it.",4,A Selective Macro-learning Algorithm and its Application to the NxN   Sliding-Tile Puzzle
search frontiers passing each other,misconception,"Although there is still wide-spread belief that bidirectional heuristic search is afflicted by the problem of search frontiers passing each other, we demonstrate that this conjecture is wrong.",4,A Selective Macro-learning Algorithm and its Application to the NxN   Sliding-Tile Puzzle
bidirectional heuristic search,new generic approach,"Based on this finding, we present both a new generic approach to bidirectional heuristic search and a new approach to dynamically improving heuristic values that is feasible in bidirectional search only.",4,A Selective Macro-learning Algorithm and its Application to the NxN   Sliding-Tile Puzzle
bidirectional heuristic search,traditional approaches,These approaches are put into perspective with both the traditional and more recently proposed approaches in order to facilitate a better overall understanding.,4,A Selective Macro-learning Algorithm and its Application to the NxN   Sliding-Tile Puzzle
Horn approximation,Set of formulas represented by Horn approximation,Represents the relationship between a Horn approximation and the set of formulas it represents. This can be seen as an illustration of the fact that a Horn approximation provides an efficient representation of the underlying set of formulas.,4,The Computational Complexity of Probabilistic Planning
Upper Horn formula,Lower Horn formula,"Represents the relationship between an upper and lower Horn formula, which together constitute a Horn approximation. This can be seen as an illustration of how these formulas work in tandem to provide an efficient representation of the underlying set of formulas.",4,The Computational Complexity of Probabilistic Planning
Horn envelope,Minimum-change update,Represents the relationship between a Horn approximation and its minimum-change update. This can be seen as an illustration of how the Horn envelope is computed when updating a Horn formula by a clause.,4,The Computational Complexity of Probabilistic Planning
Horn core,Minimum-change update,Represents the relationship between a lower Horn formula and its minimum-change update. This can be seen as an illustration of how the Horn core is computed when updating a Horn formula by a clause.,4,The Computational Complexity of Probabilistic Planning
Efficiency,Horn approximation,Represents the relationship between the efficiency and the use of Horn approximations. This can be seen as an illustration of how Horn approximations provide efficient representation of sets of formulas.,4,The Computational Complexity of Probabilistic Planning
Inductivity,Model-based updates,Represents the relationship between inductivity and model-based updates. This can be seen as an illustration of how this scheme preserves positive properties of the represented sets of formulas during updates.,4,The Computational Complexity of Probabilistic Planning
Complexity drawbacks,Theory update and revision schemes,Represents the relationship between complexity drawbacks and theory update and revision schemes. This can be seen as an illustration of how these schemes suffer from serious complexity-theoretic impediments.,4,The Computational Complexity of Probabilistic Planning
nonmonotonicity,Artificial Intelligence,Nonmonotonic logic is a characteristic of many logics used in Artificial Intelligence.,4,SYNERGY: A Linear Planner Based on Genetic Programming
formulae,consequences,Adding a formula to the premises can invalidate some consequences in nonmonotonic logic.,4,SYNERGY: A Linear Planner Based on Genetic Programming
safely added formulae,nonmonotonicity,Exist formulae that can always be safely added to the premises without destroying any consequences in nonmonotonic logic.,4,SYNERGY: A Linear Planner Based on Genetic Programming
formulae,conservative,"When a formula is a consequence, it cannot be invalidated when adding any formula to the premises in conservative logic.",4,SYNERGY: A Linear Planner Based on Genetic Programming
preferential logics,formulae preserving truth-value,The formulae whose truth-value is preserved along the ordering are closely linked to preferential logics.,4,SYNERGY: A Linear Planner Based on Genetic Programming
preferential logics,theorem provers,The results in this paper may improve the efficiency of theorem provers for preferential logics.,4,SYNERGY: A Linear Planner Based on Genetic Programming
domain dependent approaches,automatically synthesized domain independent planners,"in this paper, we investigate the feasibility of using existing automated software synthesis tools to support such synthesis. Specifically, we describe an architecture called CLAY in which the Kestrel Interactive Development System (KIDS) is used to derive a domain-customized planner through a semi-automatic combination of a declarative theory of planning, and the declarative control knowledge specific to a given domain, to semi-automatically combine them to derive domain-customized planners. Our experiments show that the synthesized planners can outperform classical refinement planners (implemented as instantiations of UCP, Kambhampati & Srivastava, 1995), using the same control knowledge.",4,The Essence of Constraint Propagation
domain independent approaches,automatically synthesized domain independent planners,"Existing plan synthesis approaches in artificial intelligence fall into two categories -- domain independent and domain dependent. The domain independent approaches are applicable across a variety of domains, but may not be very efficient in any one given domain.",4,The Essence of Constraint Propagation
machine learning datasets,quick counting,The paper introduces new algorithms and data structures for performing quick counting on machine learning datasets.,4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
constructing contingency tables,quick counting,"The focusing of the paper is on the counting task of constructing contingency tables, which can also be applied to counting the number of records in a dataset that match conjunctive queries.",4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
independent of the number of records,loglinear in the number of non-zero entries,The costs of these operations can be shown to be independent of the number of records in the dataset and loglinear in the number of non-zero entries in the contingency table.,4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
ADtree,minimize memory use,"We provide a very sparse data structure, the ADtree, to minimize memory use.",4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
Assumptions,independent of the number of records,"Subject to certain assumptions, the costs of these operations can be shown to be independent of the number of records in the dataset.",4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
conjunctive queries,counting the number of records,Our approach is also applicable to counting the number of records in a dataset that match conjunctive queries.,4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
ADtree methods,traditional direct counting approaches,"We show how the ADtree can be used to accelerate Bayes net structure finding algorithms, rule learning algorithms, and feature selection algorithms, and we provide a number of empirical results comparing ADtree methods against traditional direct counting approaches.",4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
merits,ADtrees,"We also discuss the possible uses of ADtrees in other machine learning methods, and discuss the merits of ADtrees in comparison with alternative representations such as kd-trees, R-trees and Frequent Sets.",4,A reusable iterative optimization software library to solve   combinatorial problems with approximate reasoning
theory patching,domain theory,"In this paper, we consider the problem of theory patching for domain theories that are possibly flawed. The objective is to revise only the indicated components of the theory based on labeled training examples, such that the resulting theory correctly classifies all the training examples.",4,"Modeling Belief in Dynamic Systems, Part II: Revision and Update"
theory patching,logical domain theories,"Our concern in this paper is to determine for which classes of logical domain theories, the theory patching problem is tractable.",4,"Modeling Belief in Dynamic Systems, Part II: Revision and Update"
propositional and first-order domain theories,theory patching,We consider both propositional and first-order domain theories for the theory patching problem.,4,"Modeling Belief in Dynamic Systems, Part II: Revision and Update"
logical domain theories,stability,"Determining stability is tractable if the input theory satisfies two conditions: that revisions to each theory component have monotonic effects on the classification of examples, and that theory components act independently in the classification of examples in the theory.",4,"Modeling Belief in Dynamic Systems, Part II: Revision and Update"
theory patching,soundness and completeness,We also show how the concepts introduced can be used to determine the soundness and completeness of particular theory patching algorithms.,4,"Modeling Belief in Dynamic Systems, Part II: Revision and Update"
